{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PHD08 데이터 한글 인식기:\n",
    "1. 데이터 url:http://www.iapr-tc11.org/mediawiki/index.php/KAIST_Scene_Text_Database\n",
    "1. 압축을 다 풀고 'kaist_dataset'아래에 이미지 데이터와 xml 파일을 두면\n",
    "1. 각 xml 파일에서 글자하나하나 위치정보를 읽어 원본 이미지에서 글자를 별도의 이미지 파일로 저장하는 작업을 수행한다.\n",
    "1. 결과물은 char_data 아래에 각 글자명으로 폴더를 만들고 그 아래에 원본파일명.글자명.idx.jpg로 저장\n",
    "    - char_data/{character}/{img_filename}.{character}.{idx}.jpg\n",
    "    - character가 .(dot)인 경우에는 {character}값을 dot으로 대체하여 처리\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'가': 0,\n",
       " '각': 1,\n",
       " '간': 2,\n",
       " '갇': 3,\n",
       " '갈': 4,\n",
       " '갉': 5,\n",
       " '갊': 6,\n",
       " '감': 7,\n",
       " '갑': 8,\n",
       " '값': 9,\n",
       " '갓': 10,\n",
       " '갔': 11,\n",
       " '강': 12,\n",
       " '갖': 13,\n",
       " '갗': 14,\n",
       " '같': 15,\n",
       " '갚': 16,\n",
       " '갛': 17,\n",
       " '개': 18,\n",
       " '객': 19}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "from os import listdir, path, makedirs\n",
    "from os.path import isfile, isdir, join, basename\n",
    "\n",
    "base_path = 'phd08_output'\n",
    "\n",
    "def read_charlist(base_path):\n",
    "    data_filenames = [path.splitext(f)[0] for f in listdir(base_path) if isfile(join(base_path, f)) and f.lower().endswith('.csv')]        \n",
    "    \n",
    "    return data_filenames\n",
    "        \n",
    "data_filenames = read_charlist(base_path)\n",
    "data_filenames = data_filenames[:20]\n",
    "\n",
    "label_idx = {x:idx for idx, x in enumerate(sorted(data_filenames))}\n",
    "\n",
    "label_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "FLAGS = tf.app.flags.FLAGS\n",
    "tf.app.flags.DEFINE_string('train_dir', '/tmp/phd08_train',\n",
    "                           \"\"\"Directory where to write event logs \"\"\"\n",
    "                           \"\"\"and checkpoint.\"\"\")\n",
    "tf.app.flags.DEFINE_integer('max_steps', 100000,\n",
    "                            \"\"\"Number of batches to run.\"\"\")\n",
    "tf.app.flags.DEFINE_boolean('log_device_placement', False,\n",
    "                            \"\"\"Whether to log device placement.\"\"\")\n",
    "tf.app.flags.DEFINE_integer('log_frequency', 10,\n",
    "                            \"\"\"How often to log results to the console.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAGS.batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[''],\n",
       " [''],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [''],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " ...]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record_defaults = [\n",
    "        [''], # FO\n",
    "        [''], # FS\n",
    "        [0],  # CP\n",
    "        [0],  # RE\n",
    "        [0],  # TH\n",
    "        [0],  # SL\n",
    "        [0],  # HE\n",
    "        [0],  # WD\n",
    "        [''],  # Kor char.\n",
    "    ] + [[0]] * (56*56) + [['xx', 0]]\n",
    "\n",
    "record_defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'batch:0' shape=(128, 56, 56, 3) dtype=float32>,\n",
       " <tf.Tensor 'Reshape_1:0' shape=(128,) dtype=int32>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_inputs():\n",
    "    # Create a queue that produces the filenames to read.\n",
    "    filenames = [join(base_path, '.'.join([char, 'csv'])) for char in data_filenames]\n",
    "    filename_queue = tf.train.string_input_producer(filenames)\n",
    "    line_reader = tf.TextLineReader()\n",
    "    # Read a whole file from the queue, the first returned value in the tuple is the\n",
    "    # filename which we are ignoring.\n",
    "    _, csv_row = line_reader.read(filename_queue)\n",
    "    \n",
    "    '''\n",
    "        Columns:\n",
    "        FO(1): Font type (B:바다, D:돋움, G:고딕, H1:한양해서, H2:헤드라인, M:명조, N:나무, S:샘물, Y:엽서)\n",
    "        FS(1): Font size (0:12, 1:13: 2:14)\n",
    "        CP(1): The number of copies (0:0, 1:1, 2:2)\n",
    "        RE(1): Resolution (0:200, 1:240, 2:280)\n",
    "        TH(1): Threshold (0:140, 1:180, 2:220)\n",
    "        SL(1): Slope(Rotate) (0:-3deg, 1:0deg, 2:3deg)\n",
    "        HE(1): Height(pixels)\n",
    "        WD(1): Width(pixels)\n",
    "        Korean Character(1) (가, 각, 간, ...)\n",
    "        Image data(The number of columns = Rows X Cols)\n",
    "        Label(1): (0:가, 1:각, 2:간 ...)\n",
    "\n",
    "    '''\n",
    "    record_defaults = [\n",
    "        [''], # FO\n",
    "        [''], # FS\n",
    "        [0],  # CP\n",
    "        [0],  # RE\n",
    "        [0],  # TH\n",
    "        [0],  # SL\n",
    "        [0],  # HE\n",
    "        [0],  # WD\n",
    "        [''],  # Kor char.\n",
    "    ] + [[0]] * (56*56) + [[0]]\n",
    "\n",
    "    columns = tf.decode_csv(csv_row, record_defaults=record_defaults)\n",
    "    character = columns[8]\n",
    "    image = tf.reshape(tf.stack(columns[9:-1]), [56, 56, 1])\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = tf.image.grayscale_to_rgb(image)\n",
    "    image = tf.image.per_image_standardization(image)\n",
    "    label = columns[-1]\n",
    "    \n",
    "    '''\n",
    "    To check valid input\n",
    "    '''\n",
    "#     with tf.Session() as sess:\n",
    "#         coord = tf.train.Coordinator()\n",
    "#         threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "#         fig = plt.figure(figsize=(40,250))\n",
    "#         for i in range(10):\n",
    "#             char_value, l_value, image_value = sess.run([character, label, image])\n",
    "#             print(str(char_value))\n",
    "#             print(l_value)\n",
    "#             print(image_value)\n",
    "#             subplot = fig.add_subplot(50,10,i+1)\n",
    "#             subplot.set_xlabel(l_value)\n",
    "#             plt.imshow(image_value)\n",
    "#         plt.show()            \n",
    "#         coord.request_stop()\n",
    "#         coord.join(threads)             \n",
    "\n",
    "#     print('image', image)\n",
    "#     print('label', label)\n",
    "    \n",
    "    num_preprocess_threads = 1\n",
    "    min_queue_examples = 256\n",
    "\n",
    "    images, label_batch = tf.train.batch(\n",
    "        [image, label],\n",
    "        batch_size=FLAGS.batch_size,\n",
    "        num_threads=num_preprocess_threads,\n",
    "        capacity=min_queue_examples + 3 * FLAGS.batch_size)\n",
    "\n",
    "#     tf.summary.image('images', images)\n",
    "#     tf.summary.histogram('label_batch', label_batch)\n",
    "    return images, tf.reshape(label_batch, [FLAGS.batch_size])\n",
    "\n",
    "get_inputs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_CLASSES = len(label_idx)\n",
    "NUM_CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels.get_shape() (128,)\n",
      "local3 Tensor(\"local3/local3:0\", shape=(128, 384), dtype=float32)\n",
      "local4 Tensor(\"local4/local4:0\", shape=(128, 192), dtype=float32)\n",
      "weights <tf.Variable 'softmax_linear/weights:0' shape=(192, 20) dtype=float32_ref>\n",
      "biases <tf.Variable 'softmax_linear/biases:0' shape=(20,) dtype=float32_ref>\n",
      "softmax_linear Tensor(\"softmax_linear/softmax_linear:0\", shape=(128, 20), dtype=float32)\n",
      "images, logits, labels Tensor(\"batch:0\", shape=(128, 56, 56, 3), dtype=float32) Tensor(\"softmax_linear/softmax_linear:0\", shape=(128, 20), dtype=float32) Tensor(\"Reshape_1:0\", shape=(128,), dtype=int32)\n",
      "INFO:tensorflow:Summary name conv1/weight_loss (raw) is illegal; using conv1/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name conv1-1/weight_loss (raw) is illegal; using conv1-1/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name conv1-2/weight_loss (raw) is illegal; using conv1-2/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name conv2/weight_loss (raw) is illegal; using conv2/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name conv2-1/weight_loss (raw) is illegal; using conv2-1/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name conv2-2/weight_loss (raw) is illegal; using conv2-2/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name local3/weight_loss (raw) is illegal; using local3/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name local4/weight_loss (raw) is illegal; using local4/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name softmax_linear/weight_loss (raw) is illegal; using softmax_linear/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name cross_entropy (raw) is illegal; using cross_entropy__raw_ instead.\n",
      "INFO:tensorflow:Summary name total_loss (raw) is illegal; using total_loss__raw_ instead.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/phd08_train/model.ckpt-1\n",
      "INFO:tensorflow:Saving checkpoints for 2 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-28 19:10:45.098321: step 0, loss = 15.68 (61.9 examples/sec; 2.069 sec/batch)\n",
      "2017-09-28 19:11:20.784603: step 10, loss = 11.99 (35.9 examples/sec; 3.569 sec/batch)\n",
      "2017-09-28 19:11:55.414221: step 20, loss = 12.05 (37.0 examples/sec; 3.463 sec/batch)\n",
      "2017-09-28 19:12:30.165890: step 30, loss = 11.95 (36.8 examples/sec; 3.475 sec/batch)\n",
      "2017-09-28 19:13:04.958502: step 40, loss = 408.78 (36.8 examples/sec; 3.479 sec/batch)\n",
      "2017-09-28 19:13:39.399535: step 50, loss = 405.52 (37.2 examples/sec; 3.444 sec/batch)\n",
      "2017-09-28 19:14:13.089082: step 60, loss = 1554384.25 (38.0 examples/sec; 3.369 sec/batch)\n",
      "2017-09-28 19:14:46.235566: step 70, loss = 1847440.62 (38.6 examples/sec; 3.315 sec/batch)\n",
      "2017-09-28 19:15:20.049673: step 80, loss = 1832717.00 (37.9 examples/sec; 3.381 sec/batch)\n",
      "2017-09-28 19:15:53.849345: step 90, loss = 1818329.38 (37.9 examples/sec; 3.380 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.288368\n",
      "2017-09-28 19:16:28.006322: step 100, loss = 1803837.62 (37.5 examples/sec; 3.416 sec/batch)\n",
      "2017-09-28 19:16:59.433958: step 110, loss = 1789461.75 (40.7 examples/sec; 3.143 sec/batch)\n",
      "2017-09-28 19:17:32.129730: step 120, loss = 1775200.12 (39.1 examples/sec; 3.270 sec/batch)\n",
      "2017-09-28 19:18:06.020010: step 130, loss = 1761052.50 (37.8 examples/sec; 3.389 sec/batch)\n",
      "2017-09-28 19:18:39.684367: step 140, loss = 1747020.12 (38.0 examples/sec; 3.366 sec/batch)\n",
      "2017-09-28 19:19:13.308729: step 150, loss = 1733094.25 (38.1 examples/sec; 3.362 sec/batch)\n",
      "2017-09-28 19:19:47.034107: step 160, loss = 1719282.12 (38.0 examples/sec; 3.373 sec/batch)\n",
      "2017-09-28 19:20:20.765522: step 170, loss = 1705582.12 (37.9 examples/sec; 3.373 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 179 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-28 19:20:57.953406: step 180, loss = 1691986.50 (34.4 examples/sec; 3.719 sec/batch)\n",
      "2017-09-28 19:21:31.910039: step 190, loss = 1678505.25 (37.7 examples/sec; 3.396 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.296038\n",
      "2017-09-28 19:22:05.800401: step 200, loss = 1665127.25 (37.8 examples/sec; 3.389 sec/batch)\n",
      "2017-09-28 19:22:39.804359: step 210, loss = 1651857.88 (37.6 examples/sec; 3.400 sec/batch)\n",
      "2017-09-28 19:23:13.565880: step 220, loss = 1638691.88 (37.9 examples/sec; 3.376 sec/batch)\n",
      "2017-09-28 19:23:47.016063: step 230, loss = 1625632.50 (38.3 examples/sec; 3.345 sec/batch)\n",
      "2017-09-28 19:24:20.622340: step 240, loss = 1612678.00 (38.1 examples/sec; 3.361 sec/batch)\n",
      "2017-09-28 19:24:54.145537: step 250, loss = 1599824.62 (38.2 examples/sec; 3.352 sec/batch)\n",
      "2017-09-28 19:25:27.886386: step 260, loss = 1587075.38 (37.9 examples/sec; 3.374 sec/batch)\n",
      "2017-09-28 19:26:01.718664: step 270, loss = 1574426.00 (37.8 examples/sec; 3.383 sec/batch)\n",
      "2017-09-28 19:26:35.172016: step 280, loss = 1561879.00 (38.3 examples/sec; 3.345 sec/batch)\n",
      "2017-09-28 19:27:08.892754: step 290, loss = 1549431.38 (38.0 examples/sec; 3.372 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.296767\n",
      "2017-09-28 19:27:42.766833: step 300, loss = 1537083.00 (37.8 examples/sec; 3.387 sec/batch)\n",
      "2017-09-28 19:28:16.544020: step 310, loss = 1524833.50 (37.9 examples/sec; 3.378 sec/batch)\n",
      "2017-09-28 19:28:50.286931: step 320, loss = 1512680.12 (37.9 examples/sec; 3.374 sec/batch)\n",
      "2017-09-28 19:29:24.021442: step 330, loss = 1500624.88 (37.9 examples/sec; 3.373 sec/batch)\n",
      "2017-09-28 19:29:57.593484: step 340, loss = 1488665.12 (38.1 examples/sec; 3.357 sec/batch)\n",
      "2017-09-28 19:30:31.307219: step 350, loss = 1476801.50 (38.0 examples/sec; 3.371 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 356 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-28 19:31:08.871491: step 360, loss = 1465032.38 (34.1 examples/sec; 3.756 sec/batch)\n",
      "2017-09-28 19:31:42.480446: step 370, loss = 1453355.38 (38.1 examples/sec; 3.361 sec/batch)\n",
      "2017-09-28 19:32:16.083508: step 380, loss = 1441772.50 (38.1 examples/sec; 3.360 sec/batch)\n",
      "2017-09-28 19:32:49.538118: step 390, loss = 1430281.38 (38.3 examples/sec; 3.345 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.293356\n",
      "2017-09-28 19:33:23.650619: step 400, loss = 1418884.00 (37.5 examples/sec; 3.411 sec/batch)\n",
      "2017-09-28 19:33:57.364788: step 410, loss = 1407575.88 (38.0 examples/sec; 3.371 sec/batch)\n",
      "2017-09-28 19:34:30.986740: step 420, loss = 1396357.12 (38.1 examples/sec; 3.362 sec/batch)\n",
      "2017-09-28 19:35:04.740114: step 430, loss = 1385229.38 (37.9 examples/sec; 3.375 sec/batch)\n",
      "2017-09-28 19:35:38.398204: step 440, loss = 1374188.38 (38.0 examples/sec; 3.366 sec/batch)\n",
      "2017-09-28 19:36:12.145130: step 450, loss = 1363238.38 (37.9 examples/sec; 3.375 sec/batch)\n",
      "2017-09-28 19:36:45.619700: step 460, loss = 1352372.62 (38.2 examples/sec; 3.347 sec/batch)\n",
      "2017-09-28 19:37:19.088436: step 470, loss = 1341595.50 (38.2 examples/sec; 3.347 sec/batch)\n",
      "2017-09-28 19:37:51.095550: step 480, loss = 1330904.00 (40.0 examples/sec; 3.201 sec/batch)\n",
      "2017-09-28 19:38:24.789315: step 490, loss = 1320296.00 (38.0 examples/sec; 3.369 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.298358\n",
      "2017-09-28 19:38:58.817035: step 500, loss = 1309774.00 (37.6 examples/sec; 3.403 sec/batch)\n",
      "2017-09-28 19:39:32.621329: step 510, loss = 1299334.62 (37.9 examples/sec; 3.380 sec/batch)\n",
      "2017-09-28 19:40:06.269735: step 520, loss = 1288980.88 (38.0 examples/sec; 3.365 sec/batch)\n",
      "2017-09-28 19:40:39.759166: step 530, loss = 1278708.50 (38.2 examples/sec; 3.349 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 534 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-28 19:41:13.304091: step 540, loss = 1268516.38 (38.2 examples/sec; 3.354 sec/batch)\n",
      "2017-09-28 19:41:45.700316: step 550, loss = 1258407.50 (39.5 examples/sec; 3.240 sec/batch)\n",
      "2017-09-28 19:42:19.287010: step 560, loss = 1248377.50 (38.1 examples/sec; 3.359 sec/batch)\n",
      "2017-09-28 19:42:52.925373: step 570, loss = 1238429.75 (38.1 examples/sec; 3.364 sec/batch)\n",
      "2017-09-28 19:43:26.736795: step 580, loss = 1228558.75 (37.9 examples/sec; 3.381 sec/batch)\n",
      "2017-09-28 19:44:00.498531: step 590, loss = 1218767.62 (37.9 examples/sec; 3.376 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.297812\n",
      "2017-09-28 19:44:34.598535: step 600, loss = 1209055.88 (37.5 examples/sec; 3.410 sec/batch)\n",
      "2017-09-28 19:45:07.605057: step 610, loss = 1199419.00 (38.8 examples/sec; 3.301 sec/batch)\n",
      "2017-09-28 19:45:40.995089: step 620, loss = 1189860.75 (38.3 examples/sec; 3.339 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-09-28 19:46:15.002998: step 630, loss = 1180374.25 (37.6 examples/sec; 3.401 sec/batch)\n",
      "2017-09-28 19:46:48.707596: step 640, loss = 1170970.00 (38.0 examples/sec; 3.370 sec/batch)\n",
      "2017-09-28 19:47:22.539389: step 650, loss = 1161638.50 (37.8 examples/sec; 3.383 sec/batch)\n",
      "2017-09-28 19:47:56.216070: step 660, loss = 1152380.12 (38.0 examples/sec; 3.368 sec/batch)\n",
      "2017-09-28 19:48:29.946240: step 670, loss = 1143196.00 (37.9 examples/sec; 3.373 sec/batch)\n",
      "2017-09-28 19:49:01.685390: step 680, loss = 1134084.62 (40.3 examples/sec; 3.174 sec/batch)\n",
      "2017-09-28 19:49:35.167191: step 690, loss = 1125046.25 (38.2 examples/sec; 3.348 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.298608\n",
      "2017-09-28 19:50:09.487324: step 700, loss = 1116079.50 (37.3 examples/sec; 3.432 sec/batch)\n",
      "2017-09-28 19:50:43.356222: step 710, loss = 1107184.25 (37.8 examples/sec; 3.387 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 713 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-28 19:51:20.829785: step 720, loss = 1098362.12 (34.2 examples/sec; 3.747 sec/batch)\n",
      "2017-09-28 19:51:54.396596: step 730, loss = 1089607.62 (38.1 examples/sec; 3.357 sec/batch)\n",
      "2017-09-28 19:52:28.024209: step 740, loss = 1080924.62 (38.1 examples/sec; 3.363 sec/batch)\n",
      "2017-09-28 19:53:01.871897: step 750, loss = 1072309.25 (37.8 examples/sec; 3.385 sec/batch)\n",
      "2017-09-28 19:53:35.524679: step 760, loss = 1063764.12 (38.0 examples/sec; 3.365 sec/batch)\n",
      "2017-09-28 19:54:09.263621: step 770, loss = 1055287.25 (37.9 examples/sec; 3.374 sec/batch)\n",
      "2017-09-28 19:54:42.871633: step 780, loss = 1046875.94 (38.1 examples/sec; 3.361 sec/batch)\n",
      "2017-09-28 19:55:16.933920: step 790, loss = 1038533.00 (37.6 examples/sec; 3.406 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.292736\n",
      "2017-09-28 19:55:51.090127: step 800, loss = 1030255.69 (37.5 examples/sec; 3.416 sec/batch)\n",
      "2017-09-28 19:56:25.103112: step 810, loss = 1022045.50 (37.6 examples/sec; 3.401 sec/batch)\n",
      "2017-09-28 19:56:58.837640: step 820, loss = 1013900.50 (37.9 examples/sec; 3.373 sec/batch)\n",
      "2017-09-28 19:57:32.490157: step 830, loss = 1005819.31 (38.0 examples/sec; 3.365 sec/batch)\n",
      "2017-09-28 19:58:06.120993: step 840, loss = 997803.88 (38.1 examples/sec; 3.363 sec/batch)\n",
      "2017-09-28 19:58:39.690892: step 850, loss = 989850.81 (38.1 examples/sec; 3.357 sec/batch)\n",
      "2017-09-28 19:59:13.737619: step 860, loss = 981962.44 (37.6 examples/sec; 3.405 sec/batch)\n",
      "2017-09-28 19:59:47.422434: step 870, loss = 974135.62 (38.0 examples/sec; 3.368 sec/batch)\n",
      "2017-09-28 20:00:21.290873: step 880, loss = 966372.94 (37.8 examples/sec; 3.387 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 890 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-28 20:00:58.814127: step 890, loss = 958672.06 (34.1 examples/sec; 3.752 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.292139\n",
      "2017-09-28 20:01:33.392577: step 900, loss = 951030.94 (37.0 examples/sec; 3.458 sec/batch)\n",
      "2017-09-28 20:02:07.105235: step 910, loss = 943452.00 (38.0 examples/sec; 3.371 sec/batch)\n",
      "2017-09-28 20:02:40.756081: step 920, loss = 935931.94 (38.0 examples/sec; 3.365 sec/batch)\n",
      "2017-09-28 20:03:14.439063: step 930, loss = 928473.69 (38.0 examples/sec; 3.368 sec/batch)\n",
      "2017-09-28 20:03:48.198595: step 940, loss = 921074.81 (37.9 examples/sec; 3.376 sec/batch)\n",
      "2017-09-28 20:04:21.816010: step 950, loss = 913733.19 (38.1 examples/sec; 3.362 sec/batch)\n",
      "2017-09-28 20:04:55.938838: step 960, loss = 906452.00 (37.5 examples/sec; 3.412 sec/batch)\n",
      "2017-09-28 20:05:29.888623: step 970, loss = 899226.81 (37.7 examples/sec; 3.395 sec/batch)\n",
      "2017-09-28 20:06:03.767377: step 980, loss = 892060.94 (37.8 examples/sec; 3.388 sec/batch)\n",
      "2017-09-28 20:06:37.621286: step 990, loss = 884950.25 (37.8 examples/sec; 3.385 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.297149\n",
      "2017-09-28 20:07:09.925376: step 1000, loss = 877898.69 (39.6 examples/sec; 3.230 sec/batch)\n",
      "2017-09-28 20:07:43.581580: step 1010, loss = 870902.88 (38.0 examples/sec; 3.366 sec/batch)\n",
      "2017-09-28 20:08:17.022436: step 1020, loss = 863961.19 (38.3 examples/sec; 3.344 sec/batch)\n",
      "2017-09-28 20:08:50.469817: step 1030, loss = 857075.75 (38.3 examples/sec; 3.345 sec/batch)\n",
      "2017-09-28 20:09:24.097636: step 1040, loss = 850243.94 (38.1 examples/sec; 3.363 sec/batch)\n",
      "2017-09-28 20:09:58.069757: step 1050, loss = 843467.69 (37.7 examples/sec; 3.397 sec/batch)\n",
      "2017-09-28 20:10:31.996275: step 1060, loss = 836747.31 (37.7 examples/sec; 3.393 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 1067 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-28 20:11:09.051285: step 1070, loss = 830077.62 (34.5 examples/sec; 3.706 sec/batch)\n",
      "2017-09-28 20:11:42.723359: step 1080, loss = 823462.81 (38.0 examples/sec; 3.367 sec/batch)\n",
      "2017-09-28 20:12:16.502122: step 1090, loss = 816899.00 (37.9 examples/sec; 3.378 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.293602\n",
      "2017-09-28 20:12:50.521218: step 1100, loss = 810389.25 (37.6 examples/sec; 3.402 sec/batch)\n",
      "2017-09-28 20:13:24.220935: step 1110, loss = 803930.69 (38.0 examples/sec; 3.370 sec/batch)\n",
      "2017-09-28 20:13:55.629719: step 1120, loss = 797523.69 (40.8 examples/sec; 3.141 sec/batch)\n",
      "2017-09-28 20:14:29.154491: step 1130, loss = 791168.62 (38.2 examples/sec; 3.352 sec/batch)\n",
      "2017-09-28 20:15:03.040013: step 1140, loss = 784862.50 (37.8 examples/sec; 3.389 sec/batch)\n",
      "2017-09-28 20:15:36.697525: step 1150, loss = 778607.56 (38.0 examples/sec; 3.366 sec/batch)\n",
      "2017-09-28 20:16:09.642897: step 1160, loss = 772401.44 (38.9 examples/sec; 3.295 sec/batch)\n",
      "2017-09-28 20:16:43.392359: step 1170, loss = 766246.94 (37.9 examples/sec; 3.375 sec/batch)\n",
      "2017-09-28 20:17:15.766447: step 1180, loss = 760140.94 (39.5 examples/sec; 3.237 sec/batch)\n",
      "2017-09-28 20:17:49.612669: step 1190, loss = 754081.88 (37.8 examples/sec; 3.385 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.299962\n",
      "2017-09-28 20:18:23.898766: step 1200, loss = 748072.75 (37.3 examples/sec; 3.429 sec/batch)\n",
      "2017-09-28 20:18:57.448555: step 1210, loss = 742109.88 (38.2 examples/sec; 3.355 sec/batch)\n",
      "2017-09-28 20:19:31.213136: step 1220, loss = 736196.12 (37.9 examples/sec; 3.376 sec/batch)\n",
      "2017-09-28 20:20:03.628714: step 1230, loss = 730328.88 (39.5 examples/sec; 3.242 sec/batch)\n",
      "2017-09-28 20:20:37.431495: step 1240, loss = 724507.81 (37.9 examples/sec; 3.380 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 1246 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-28 20:21:15.041254: step 1250, loss = 718734.88 (34.0 examples/sec; 3.761 sec/batch)\n",
      "2017-09-28 20:21:48.903021: step 1260, loss = 713005.81 (37.8 examples/sec; 3.386 sec/batch)\n",
      "2017-09-28 20:22:22.803170: step 1270, loss = 707323.94 (37.8 examples/sec; 3.390 sec/batch)\n",
      "2017-09-28 20:22:55.820913: step 1280, loss = 701685.62 (38.8 examples/sec; 3.302 sec/batch)\n",
      "2017-09-28 20:23:30.077815: step 1290, loss = 696094.25 (37.4 examples/sec; 3.426 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.293716\n",
      "2017-09-28 20:24:04.362062: step 1300, loss = 690547.81 (37.3 examples/sec; 3.428 sec/batch)\n",
      "2017-09-28 20:24:37.836519: step 1310, loss = 685043.31 (38.2 examples/sec; 3.347 sec/batch)\n",
      "2017-09-28 20:25:11.648328: step 1320, loss = 679584.75 (37.9 examples/sec; 3.381 sec/batch)\n",
      "2017-09-28 20:25:45.263146: step 1330, loss = 674167.38 (38.1 examples/sec; 3.361 sec/batch)\n",
      "2017-09-28 20:26:19.133009: step 1340, loss = 668795.12 (37.8 examples/sec; 3.387 sec/batch)\n",
      "2017-09-28 20:26:53.126675: step 1350, loss = 663465.69 (37.7 examples/sec; 3.399 sec/batch)\n",
      "2017-09-28 20:27:26.583810: step 1360, loss = 658177.06 (38.3 examples/sec; 3.346 sec/batch)\n",
      "2017-09-28 20:28:00.076063: step 1370, loss = 652931.44 (38.2 examples/sec; 3.349 sec/batch)\n",
      "2017-09-28 20:28:33.906841: step 1380, loss = 647727.00 (37.8 examples/sec; 3.383 sec/batch)\n",
      "2017-09-28 20:29:06.575739: step 1390, loss = 642566.25 (39.2 examples/sec; 3.267 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.29695\n",
      "2017-09-28 20:29:41.119301: step 1400, loss = 637444.38 (37.1 examples/sec; 3.454 sec/batch)\n",
      "2017-09-28 20:30:14.734759: step 1410, loss = 632364.19 (38.1 examples/sec; 3.362 sec/batch)\n",
      "2017-09-28 20:30:48.890463: step 1420, loss = 627325.94 (37.5 examples/sec; 3.416 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 1423 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-28 20:31:26.304945: step 1430, loss = 622325.50 (34.2 examples/sec; 3.741 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-09-28 20:32:00.149524: step 1440, loss = 617365.94 (37.8 examples/sec; 3.384 sec/batch)\n",
      "2017-09-28 20:32:33.575342: step 1450, loss = 612444.69 (38.3 examples/sec; 3.343 sec/batch)\n",
      "2017-09-28 20:33:07.342816: step 1460, loss = 607564.12 (37.9 examples/sec; 3.377 sec/batch)\n",
      "2017-09-28 20:33:41.286833: step 1470, loss = 602723.50 (37.7 examples/sec; 3.394 sec/batch)\n",
      "2017-09-28 20:34:13.513978: step 1480, loss = 597918.88 (39.7 examples/sec; 3.223 sec/batch)\n",
      "2017-09-28 20:34:45.848985: step 1490, loss = 593154.50 (39.6 examples/sec; 3.234 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.295016\n",
      "2017-09-28 20:35:20.084139: step 1500, loss = 588426.44 (37.4 examples/sec; 3.424 sec/batch)\n",
      "2017-09-28 20:35:53.922074: step 1510, loss = 583737.50 (37.8 examples/sec; 3.384 sec/batch)\n",
      "2017-09-28 20:36:27.582086: step 1520, loss = 579084.69 (38.0 examples/sec; 3.366 sec/batch)\n",
      "2017-09-28 20:37:01.271221: step 1530, loss = 574469.56 (38.0 examples/sec; 3.369 sec/batch)\n",
      "2017-09-28 20:37:34.823472: step 1540, loss = 569892.25 (38.1 examples/sec; 3.355 sec/batch)\n",
      "2017-09-28 20:38:08.568908: step 1550, loss = 565349.44 (37.9 examples/sec; 3.375 sec/batch)\n",
      "2017-09-28 20:38:42.409349: step 1560, loss = 560844.56 (37.8 examples/sec; 3.384 sec/batch)\n",
      "2017-09-28 20:39:16.023337: step 1570, loss = 556373.94 (38.1 examples/sec; 3.361 sec/batch)\n",
      "2017-09-28 20:39:49.177627: step 1580, loss = 551940.75 (38.6 examples/sec; 3.315 sec/batch)\n",
      "2017-09-28 20:40:23.446713: step 1590, loss = 547542.44 (37.4 examples/sec; 3.427 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 1601 into /tmp/phd08_train/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.292585\n",
      "2017-09-28 20:41:01.865792: step 1600, loss = 543177.75 (33.3 examples/sec; 3.842 sec/batch)\n",
      "2017-09-28 20:41:35.591061: step 1610, loss = 538849.62 (38.0 examples/sec; 3.373 sec/batch)\n",
      "2017-09-28 20:42:08.668499: step 1620, loss = 534554.25 (38.7 examples/sec; 3.308 sec/batch)\n",
      "2017-09-28 20:42:42.247436: step 1630, loss = 530294.88 (38.1 examples/sec; 3.358 sec/batch)\n",
      "2017-09-28 20:43:15.926293: step 1640, loss = 526068.81 (38.0 examples/sec; 3.368 sec/batch)\n",
      "2017-09-28 20:43:49.447451: step 1650, loss = 521875.72 (38.2 examples/sec; 3.352 sec/batch)\n",
      "2017-09-28 20:44:23.817627: step 1660, loss = 517717.22 (37.2 examples/sec; 3.437 sec/batch)\n",
      "2017-09-28 20:44:57.984328: step 1670, loss = 513590.28 (37.5 examples/sec; 3.417 sec/batch)\n",
      "2017-09-28 20:45:32.310756: step 1680, loss = 509497.88 (37.3 examples/sec; 3.433 sec/batch)\n",
      "2017-09-28 20:46:06.482933: step 1690, loss = 505436.38 (37.5 examples/sec; 3.417 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.296266\n",
      "2017-09-28 20:46:39.402281: step 1700, loss = 501408.50 (38.9 examples/sec; 3.292 sec/batch)\n",
      "2017-09-28 20:47:13.047256: step 1710, loss = 497412.62 (38.0 examples/sec; 3.364 sec/batch)\n",
      "2017-09-28 20:47:46.815009: step 1720, loss = 493447.47 (37.9 examples/sec; 3.377 sec/batch)\n",
      "2017-09-28 20:48:18.867117: step 1730, loss = 489515.69 (39.9 examples/sec; 3.205 sec/batch)\n",
      "2017-09-28 20:48:52.580466: step 1740, loss = 485613.62 (38.0 examples/sec; 3.371 sec/batch)\n",
      "2017-09-28 20:49:26.536364: step 1750, loss = 481744.09 (37.7 examples/sec; 3.396 sec/batch)\n",
      "2017-09-28 20:50:00.260783: step 1760, loss = 477905.88 (38.0 examples/sec; 3.372 sec/batch)\n",
      "2017-09-28 20:50:34.159975: step 1770, loss = 474096.09 (37.8 examples/sec; 3.390 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 1778 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-28 20:51:11.913742: step 1780, loss = 470317.81 (33.9 examples/sec; 3.775 sec/batch)\n",
      "2017-09-28 20:51:46.508688: step 1790, loss = 466568.50 (37.0 examples/sec; 3.459 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.293147\n",
      "2017-09-28 20:52:20.524180: step 1800, loss = 462851.44 (37.6 examples/sec; 3.402 sec/batch)\n",
      "2017-09-28 20:52:54.226918: step 1810, loss = 459161.81 (38.0 examples/sec; 3.370 sec/batch)\n",
      "2017-09-28 20:53:26.934153: step 1820, loss = 455502.91 (39.1 examples/sec; 3.271 sec/batch)\n",
      "2017-09-28 20:54:00.459972: step 1830, loss = 451873.59 (38.2 examples/sec; 3.353 sec/batch)\n",
      "2017-09-28 20:54:33.952269: step 1840, loss = 448271.31 (38.2 examples/sec; 3.349 sec/batch)\n",
      "2017-09-28 20:55:07.694758: step 1850, loss = 444699.69 (37.9 examples/sec; 3.374 sec/batch)\n",
      "2017-09-28 20:55:41.723854: step 1860, loss = 441154.44 (37.6 examples/sec; 3.403 sec/batch)\n",
      "2017-09-28 20:56:16.042992: step 1870, loss = 437638.94 (37.3 examples/sec; 3.432 sec/batch)\n",
      "2017-09-28 20:56:49.711700: step 1880, loss = 434152.41 (38.0 examples/sec; 3.367 sec/batch)\n",
      "2017-09-28 20:57:23.572568: step 1890, loss = 430691.47 (37.8 examples/sec; 3.386 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.296362\n",
      "2017-09-28 20:57:57.952200: step 1900, loss = 427259.50 (37.2 examples/sec; 3.438 sec/batch)\n",
      "2017-09-28 20:58:34.017913: step 1910, loss = 423853.38 (35.5 examples/sec; 3.607 sec/batch)\n",
      "2017-09-28 20:59:07.166759: step 1920, loss = 420476.41 (38.6 examples/sec; 3.315 sec/batch)\n",
      "2017-09-28 20:59:40.257766: step 1930, loss = 417438.56 (38.7 examples/sec; 3.309 sec/batch)\n",
      "2017-09-28 21:00:13.162366: step 1940, loss = 414109.16 (38.9 examples/sec; 3.290 sec/batch)\n",
      "2017-09-28 21:00:46.574848: step 1950, loss = 410809.88 (38.3 examples/sec; 3.341 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 1955 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-28 21:01:23.605301: step 1960, loss = 407534.62 (34.6 examples/sec; 3.703 sec/batch)\n",
      "2017-09-28 21:01:57.829245: step 1970, loss = 404286.81 (37.4 examples/sec; 3.422 sec/batch)\n",
      "2017-09-28 21:02:31.560735: step 1980, loss = 401064.72 (37.9 examples/sec; 3.373 sec/batch)\n",
      "2017-09-28 21:03:04.824713: step 1990, loss = 397868.47 (38.5 examples/sec; 3.326 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.292978\n",
      "2017-09-28 21:03:39.281669: step 2000, loss = 394699.47 (37.1 examples/sec; 3.446 sec/batch)\n",
      "2017-09-28 21:04:11.975342: step 2010, loss = 391551.94 (39.2 examples/sec; 3.269 sec/batch)\n",
      "2017-09-28 21:04:44.904777: step 2020, loss = 388431.50 (38.9 examples/sec; 3.293 sec/batch)\n",
      "2017-09-28 21:05:18.743850: step 2030, loss = 385335.72 (37.8 examples/sec; 3.384 sec/batch)\n",
      "2017-09-28 21:05:52.495439: step 2040, loss = 382264.81 (37.9 examples/sec; 3.375 sec/batch)\n",
      "2017-09-28 21:06:26.267470: step 2050, loss = 379223.72 (37.9 examples/sec; 3.377 sec/batch)\n",
      "2017-09-28 21:07:00.338821: step 2060, loss = 376196.03 (37.6 examples/sec; 3.407 sec/batch)\n",
      "2017-09-28 21:07:34.533672: step 2070, loss = 373198.03 (37.4 examples/sec; 3.419 sec/batch)\n",
      "2017-09-28 21:08:08.412696: step 2080, loss = 370223.47 (37.8 examples/sec; 3.388 sec/batch)\n",
      "2017-09-28 21:08:42.251907: step 2090, loss = 367273.41 (37.8 examples/sec; 3.384 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.296769\n",
      "2017-09-28 21:09:16.243312: step 2100, loss = 364346.00 (37.7 examples/sec; 3.399 sec/batch)\n",
      "2017-09-28 21:09:50.155657: step 2110, loss = 361442.22 (37.7 examples/sec; 3.391 sec/batch)\n",
      "2017-09-28 21:10:24.034263: step 2120, loss = 358564.16 (37.8 examples/sec; 3.388 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 2132 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-28 21:11:01.438799: step 2130, loss = 355703.97 (34.2 examples/sec; 3.740 sec/batch)\n",
      "2017-09-28 21:11:35.246310: step 2140, loss = 352869.25 (37.9 examples/sec; 3.381 sec/batch)\n",
      "2017-09-28 21:12:09.026542: step 2150, loss = 350056.75 (37.9 examples/sec; 3.378 sec/batch)\n",
      "2017-09-28 21:12:42.682163: step 2160, loss = 347267.06 (38.0 examples/sec; 3.366 sec/batch)\n",
      "2017-09-28 21:13:16.328344: step 2170, loss = 344507.31 (38.0 examples/sec; 3.365 sec/batch)\n",
      "2017-09-28 21:13:49.878635: step 2180, loss = 341753.91 (38.2 examples/sec; 3.355 sec/batch)\n",
      "2017-09-28 21:14:23.572193: step 2190, loss = 339031.59 (38.0 examples/sec; 3.369 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.292762\n",
      "2017-09-28 21:14:57.822022: step 2200, loss = 336328.22 (37.4 examples/sec; 3.425 sec/batch)\n",
      "2017-09-28 21:15:31.566212: step 2210, loss = 333647.91 (37.9 examples/sec; 3.374 sec/batch)\n",
      "2017-09-28 21:16:05.392249: step 2220, loss = 330988.84 (37.8 examples/sec; 3.383 sec/batch)\n",
      "2017-09-28 21:16:39.681366: step 2230, loss = 328350.91 (37.3 examples/sec; 3.429 sec/batch)\n",
      "2017-09-28 21:17:13.418403: step 2240, loss = 325736.06 (37.9 examples/sec; 3.374 sec/batch)\n",
      "2017-09-28 21:17:47.518499: step 2250, loss = 323138.09 (37.5 examples/sec; 3.410 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-09-28 21:18:21.554696: step 2260, loss = 320563.44 (37.6 examples/sec; 3.404 sec/batch)\n",
      "2017-09-28 21:18:55.425818: step 2270, loss = 318008.12 (37.8 examples/sec; 3.387 sec/batch)\n",
      "2017-09-28 21:19:29.465988: step 2280, loss = 315473.69 (37.6 examples/sec; 3.404 sec/batch)\n",
      "2017-09-28 21:20:03.273233: step 2290, loss = 312964.56 (37.9 examples/sec; 3.381 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.293653\n",
      "2017-09-28 21:20:38.360029: step 2300, loss = 310465.25 (36.5 examples/sec; 3.509 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 2309 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-28 21:21:13.730175: step 2310, loss = 307991.94 (36.2 examples/sec; 3.537 sec/batch)\n",
      "2017-09-28 21:21:47.515022: step 2320, loss = 305536.31 (37.9 examples/sec; 3.378 sec/batch)\n",
      "2017-09-28 21:22:20.360491: step 2330, loss = 303101.41 (39.0 examples/sec; 3.285 sec/batch)\n",
      "2017-09-28 21:22:53.792458: step 2340, loss = 300687.44 (38.3 examples/sec; 3.343 sec/batch)\n",
      "2017-09-28 21:23:27.784378: step 2350, loss = 298289.31 (37.7 examples/sec; 3.399 sec/batch)\n",
      "2017-09-28 21:24:01.341550: step 2360, loss = 295913.69 (38.1 examples/sec; 3.356 sec/batch)\n",
      "2017-09-28 21:24:31.267728: step 2370, loss = 293553.66 (42.8 examples/sec; 2.993 sec/batch)\n",
      "2017-09-28 21:25:04.657285: step 2380, loss = 291214.22 (38.3 examples/sec; 3.339 sec/batch)\n",
      "2017-09-28 21:25:38.419769: step 2390, loss = 288893.25 (37.9 examples/sec; 3.376 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.299279\n",
      "2017-09-28 21:26:12.492287: step 2400, loss = 286590.91 (37.6 examples/sec; 3.407 sec/batch)\n",
      "2017-09-28 21:26:45.732411: step 2410, loss = 284309.62 (38.5 examples/sec; 3.324 sec/batch)\n",
      "2017-09-28 21:27:18.836122: step 2420, loss = 282041.12 (38.7 examples/sec; 3.310 sec/batch)\n",
      "2017-09-28 21:27:51.745300: step 2430, loss = 279793.78 (38.9 examples/sec; 3.291 sec/batch)\n",
      "2017-09-28 21:28:25.565348: step 2440, loss = 277563.38 (37.8 examples/sec; 3.382 sec/batch)\n",
      "2017-09-28 21:28:59.415087: step 2450, loss = 275351.84 (37.8 examples/sec; 3.385 sec/batch)\n",
      "2017-09-28 21:29:33.211889: step 2460, loss = 273161.66 (37.9 examples/sec; 3.380 sec/batch)\n",
      "2017-09-28 21:30:07.069925: step 2470, loss = 270980.00 (37.8 examples/sec; 3.386 sec/batch)\n",
      "2017-09-28 21:30:40.935401: step 2480, loss = 268822.03 (37.8 examples/sec; 3.387 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 2488 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-28 21:31:18.653092: step 2490, loss = 266677.97 (33.9 examples/sec; 3.772 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.293911\n",
      "2017-09-28 21:31:52.730803: step 2500, loss = 264552.81 (37.6 examples/sec; 3.408 sec/batch)\n",
      "2017-09-28 21:32:26.478285: step 2510, loss = 262444.25 (37.9 examples/sec; 3.375 sec/batch)\n",
      "2017-09-28 21:32:59.640519: step 2520, loss = 260352.55 (38.6 examples/sec; 3.316 sec/batch)\n",
      "2017-09-28 21:33:33.332569: step 2530, loss = 258280.19 (38.0 examples/sec; 3.369 sec/batch)\n",
      "2017-09-28 21:34:07.315269: step 2540, loss = 256219.34 (37.7 examples/sec; 3.398 sec/batch)\n",
      "2017-09-28 21:34:40.962083: step 2550, loss = 254178.17 (38.0 examples/sec; 3.365 sec/batch)\n",
      "2017-09-28 21:35:15.000761: step 2560, loss = 252151.53 (37.6 examples/sec; 3.404 sec/batch)\n",
      "2017-09-28 21:35:48.986285: step 2570, loss = 250142.12 (37.7 examples/sec; 3.399 sec/batch)\n",
      "2017-09-28 21:36:22.789366: step 2580, loss = 248156.06 (37.9 examples/sec; 3.380 sec/batch)\n",
      "2017-09-28 21:36:56.357823: step 2590, loss = 246170.75 (38.1 examples/sec; 3.357 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.295981\n",
      "2017-09-28 21:37:30.591746: step 2600, loss = 244210.02 (37.4 examples/sec; 3.423 sec/batch)\n",
      "2017-09-28 21:38:04.505662: step 2610, loss = 242262.55 (37.7 examples/sec; 3.391 sec/batch)\n",
      "2017-09-28 21:38:36.833159: step 2620, loss = 240332.17 (39.6 examples/sec; 3.233 sec/batch)\n",
      "2017-09-28 21:39:10.395166: step 2630, loss = 238416.47 (38.1 examples/sec; 3.356 sec/batch)\n",
      "2017-09-28 21:39:45.088071: step 2640, loss = 236516.42 (36.9 examples/sec; 3.469 sec/batch)\n",
      "2017-09-28 21:40:18.962421: step 2650, loss = 234633.88 (37.8 examples/sec; 3.387 sec/batch)\n",
      "2017-09-28 21:40:52.659744: step 2660, loss = 232761.50 (38.0 examples/sec; 3.370 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 2665 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-28 21:41:30.635556: step 2670, loss = 230907.41 (33.7 examples/sec; 3.798 sec/batch)\n",
      "2017-09-28 21:42:04.329324: step 2680, loss = 229066.17 (38.0 examples/sec; 3.369 sec/batch)\n",
      "2017-09-28 21:42:38.020220: step 2690, loss = 227240.72 (38.0 examples/sec; 3.369 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.292735\n",
      "2017-09-28 21:43:12.198148: step 2700, loss = 225434.47 (37.5 examples/sec; 3.418 sec/batch)\n",
      "2017-09-28 21:43:46.223881: step 2710, loss = 223633.02 (37.6 examples/sec; 3.403 sec/batch)\n",
      "2017-09-28 21:44:20.103042: step 2720, loss = 221852.02 (37.8 examples/sec; 3.388 sec/batch)\n",
      "2017-09-28 21:44:53.893367: step 2730, loss = 220082.56 (37.9 examples/sec; 3.379 sec/batch)\n",
      "2017-09-28 21:45:27.705835: step 2740, loss = 218328.84 (37.9 examples/sec; 3.381 sec/batch)\n",
      "2017-09-28 21:46:01.847968: step 2750, loss = 216589.81 (37.5 examples/sec; 3.414 sec/batch)\n",
      "2017-09-28 21:46:35.742972: step 2760, loss = 214862.59 (37.8 examples/sec; 3.390 sec/batch)\n",
      "2017-09-28 21:47:09.839550: step 2770, loss = 213152.45 (37.5 examples/sec; 3.410 sec/batch)\n",
      "2017-09-28 21:47:43.746019: step 2780, loss = 211451.31 (37.8 examples/sec; 3.391 sec/batch)\n",
      "2017-09-28 21:48:17.497264: step 2790, loss = 209767.30 (37.9 examples/sec; 3.375 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.294281\n",
      "2017-09-28 21:48:52.007732: step 2800, loss = 208094.36 (37.1 examples/sec; 3.451 sec/batch)\n",
      "2017-09-28 21:49:25.824177: step 2810, loss = 206436.11 (37.9 examples/sec; 3.382 sec/batch)\n",
      "2017-09-28 21:49:59.637361: step 2820, loss = 204794.38 (37.9 examples/sec; 3.381 sec/batch)\n",
      "2017-09-28 21:50:33.470816: step 2830, loss = 203158.59 (37.8 examples/sec; 3.383 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 2841 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-28 21:51:10.074319: step 2840, loss = 201541.09 (35.0 examples/sec; 3.660 sec/batch)\n",
      "2017-09-28 21:51:44.448266: step 2850, loss = 199933.30 (37.2 examples/sec; 3.437 sec/batch)\n",
      "2017-09-28 21:52:18.886711: step 2860, loss = 198340.16 (37.2 examples/sec; 3.444 sec/batch)\n",
      "2017-09-28 21:52:53.118751: step 2870, loss = 196763.20 (37.4 examples/sec; 3.423 sec/batch)\n",
      "2017-09-28 21:53:27.653750: step 2880, loss = 195191.12 (37.1 examples/sec; 3.453 sec/batch)\n",
      "2017-09-28 21:54:01.587810: step 2890, loss = 193637.97 (37.7 examples/sec; 3.393 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.29161\n",
      "2017-09-28 21:54:34.925229: step 2900, loss = 192092.27 (38.4 examples/sec; 3.334 sec/batch)\n",
      "2017-09-28 21:55:08.316357: step 2910, loss = 190561.44 (38.3 examples/sec; 3.339 sec/batch)\n",
      "2017-09-28 21:55:41.536893: step 2920, loss = 189042.58 (38.5 examples/sec; 3.322 sec/batch)\n",
      "2017-09-28 21:56:15.432782: step 2930, loss = 187536.12 (37.8 examples/sec; 3.390 sec/batch)\n",
      "2017-09-28 21:56:50.259404: step 2940, loss = 186044.34 (36.8 examples/sec; 3.483 sec/batch)\n",
      "2017-09-28 21:57:24.077090: step 2950, loss = 184558.80 (37.9 examples/sec; 3.382 sec/batch)\n",
      "2017-09-28 21:57:57.897467: step 2960, loss = 183089.17 (37.8 examples/sec; 3.382 sec/batch)\n",
      "2017-09-28 21:58:31.683243: step 2970, loss = 181628.69 (37.9 examples/sec; 3.379 sec/batch)\n",
      "2017-09-28 21:59:05.082656: step 2980, loss = 180181.70 (38.3 examples/sec; 3.340 sec/batch)\n",
      "2017-09-28 21:59:38.860397: step 2990, loss = 178752.97 (37.9 examples/sec; 3.378 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.295945\n",
      "2017-09-28 22:00:12.835172: step 3000, loss = 177321.64 (37.7 examples/sec; 3.397 sec/batch)\n",
      "2017-09-28 22:00:46.751376: step 3010, loss = 175910.16 (37.7 examples/sec; 3.392 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 3017 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-28 22:01:24.462239: step 3020, loss = 174505.55 (33.9 examples/sec; 3.771 sec/batch)\n",
      "2017-09-28 22:01:58.293406: step 3030, loss = 173115.23 (37.8 examples/sec; 3.383 sec/batch)\n",
      "2017-09-28 22:02:31.908735: step 3040, loss = 171735.08 (38.1 examples/sec; 3.362 sec/batch)\n",
      "2017-09-28 22:03:05.622085: step 3050, loss = 170366.48 (38.0 examples/sec; 3.371 sec/batch)\n",
      "2017-09-28 22:03:39.827708: step 3060, loss = 169010.81 (37.4 examples/sec; 3.421 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-09-28 22:04:11.850716: step 3070, loss = 167661.73 (40.0 examples/sec; 3.202 sec/batch)\n",
      "2017-09-28 22:04:44.455217: step 3080, loss = 166326.53 (39.3 examples/sec; 3.260 sec/batch)\n",
      "2017-09-28 22:05:18.072254: step 3090, loss = 164999.97 (38.1 examples/sec; 3.362 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.294901\n",
      "2017-09-28 22:05:51.924323: step 3100, loss = 163684.94 (37.8 examples/sec; 3.385 sec/batch)\n",
      "2017-09-28 22:06:25.293038: step 3110, loss = 162384.88 (38.4 examples/sec; 3.337 sec/batch)\n",
      "2017-09-28 22:06:58.820670: step 3120, loss = 161086.36 (38.2 examples/sec; 3.353 sec/batch)\n",
      "2017-09-28 22:07:32.987057: step 3130, loss = 159804.30 (37.5 examples/sec; 3.417 sec/batch)\n",
      "2017-09-28 22:08:06.320645: step 3140, loss = 158529.02 (38.4 examples/sec; 3.333 sec/batch)\n",
      "2017-09-28 22:08:40.204746: step 3150, loss = 157266.61 (37.8 examples/sec; 3.388 sec/batch)\n",
      "2017-09-28 22:09:14.182322: step 3160, loss = 156012.84 (37.7 examples/sec; 3.398 sec/batch)\n",
      "2017-09-28 22:09:47.496238: step 3170, loss = 154769.02 (38.4 examples/sec; 3.331 sec/batch)\n",
      "2017-09-28 22:10:20.083421: step 3180, loss = 153538.27 (39.3 examples/sec; 3.259 sec/batch)\n",
      "2017-09-28 22:10:53.820236: step 3190, loss = 152311.89 (37.9 examples/sec; 3.374 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 3195 into /tmp/phd08_train/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.292731\n",
      "2017-09-28 22:11:33.540964: step 3200, loss = 151098.77 (32.2 examples/sec; 3.972 sec/batch)\n",
      "2017-09-28 22:12:06.703421: step 3210, loss = 149893.70 (38.6 examples/sec; 3.316 sec/batch)\n",
      "2017-09-28 22:12:40.312076: step 3220, loss = 148699.72 (38.1 examples/sec; 3.361 sec/batch)\n",
      "2017-09-28 22:13:14.006589: step 3230, loss = 147517.80 (38.0 examples/sec; 3.369 sec/batch)\n",
      "2017-09-28 22:13:47.830037: step 3240, loss = 146338.39 (37.8 examples/sec; 3.382 sec/batch)\n",
      "2017-09-28 22:14:21.552870: step 3250, loss = 145173.08 (38.0 examples/sec; 3.372 sec/batch)\n",
      "2017-09-28 22:14:55.783326: step 3260, loss = 144015.08 (37.4 examples/sec; 3.423 sec/batch)\n",
      "2017-09-28 22:15:29.568414: step 3270, loss = 142867.53 (37.9 examples/sec; 3.379 sec/batch)\n",
      "2017-09-28 22:16:03.347701: step 3280, loss = 141732.80 (37.9 examples/sec; 3.378 sec/batch)\n",
      "2017-09-28 22:16:37.245085: step 3290, loss = 140599.50 (37.8 examples/sec; 3.390 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.295748\n",
      "2017-09-28 22:17:11.667224: step 3300, loss = 139478.61 (37.2 examples/sec; 3.442 sec/batch)\n",
      "2017-09-28 22:17:45.277380: step 3310, loss = 138367.03 (38.1 examples/sec; 3.361 sec/batch)\n",
      "2017-09-28 22:18:18.599072: step 3320, loss = 137265.61 (38.4 examples/sec; 3.332 sec/batch)\n",
      "2017-09-28 22:18:52.310780: step 3330, loss = 136170.41 (38.0 examples/sec; 3.371 sec/batch)\n",
      "2017-09-28 22:19:25.968540: step 3340, loss = 135085.70 (38.0 examples/sec; 3.366 sec/batch)\n",
      "2017-09-28 22:19:59.413837: step 3350, loss = 134012.42 (38.3 examples/sec; 3.345 sec/batch)\n",
      "2017-09-28 22:20:32.857229: step 3360, loss = 132940.78 (38.3 examples/sec; 3.344 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 3372 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-28 22:21:09.940832: step 3370, loss = 131882.42 (34.5 examples/sec; 3.708 sec/batch)\n",
      "2017-09-28 22:21:43.539623: step 3380, loss = 130830.09 (38.1 examples/sec; 3.360 sec/batch)\n",
      "2017-09-28 22:22:17.357630: step 3390, loss = 129787.92 (37.8 examples/sec; 3.382 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.294383\n",
      "2017-09-28 22:22:51.361002: step 3400, loss = 128759.20 (37.6 examples/sec; 3.400 sec/batch)\n",
      "2017-09-28 22:23:25.169156: step 3410, loss = 127727.04 (37.9 examples/sec; 3.381 sec/batch)\n",
      "2017-09-28 22:23:58.942444: step 3420, loss = 126710.79 (37.9 examples/sec; 3.377 sec/batch)\n",
      "2017-09-28 22:24:32.654014: step 3430, loss = 125699.14 (38.0 examples/sec; 3.371 sec/batch)\n",
      "2017-09-28 22:25:06.467659: step 3440, loss = 124698.64 (37.9 examples/sec; 3.381 sec/batch)\n",
      "2017-09-28 22:25:40.392054: step 3450, loss = 123703.59 (37.7 examples/sec; 3.392 sec/batch)\n",
      "2017-09-28 22:26:16.076361: step 3460, loss = 122717.98 (35.9 examples/sec; 3.568 sec/batch)\n",
      "2017-09-28 22:26:50.076547: step 3470, loss = 121743.04 (37.6 examples/sec; 3.400 sec/batch)\n",
      "2017-09-28 22:27:23.906640: step 3480, loss = 120769.53 (37.8 examples/sec; 3.383 sec/batch)\n",
      "2017-09-28 22:27:57.753610: step 3490, loss = 119808.91 (37.8 examples/sec; 3.385 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.293716\n",
      "2017-09-28 22:28:31.826210: step 3500, loss = 118852.18 (37.6 examples/sec; 3.407 sec/batch)\n",
      "2017-09-28 22:29:05.752768: step 3510, loss = 117905.54 (37.7 examples/sec; 3.393 sec/batch)\n",
      "2017-09-28 22:29:39.545502: step 3520, loss = 116970.61 (37.9 examples/sec; 3.379 sec/batch)\n",
      "2017-09-28 22:30:13.253341: step 3530, loss = 116033.11 (38.0 examples/sec; 3.371 sec/batch)\n",
      "2017-09-28 22:30:46.926806: step 3540, loss = 115111.35 (38.0 examples/sec; 3.367 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 3548 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-28 22:31:22.705244: step 3550, loss = 114191.04 (35.8 examples/sec; 3.578 sec/batch)\n",
      "2017-09-28 22:31:56.166875: step 3560, loss = 113282.06 (38.3 examples/sec; 3.346 sec/batch)\n",
      "2017-09-28 22:32:30.193400: step 3570, loss = 112378.31 (37.6 examples/sec; 3.403 sec/batch)\n",
      "2017-09-28 22:33:04.233436: step 3580, loss = 111483.06 (37.6 examples/sec; 3.404 sec/batch)\n",
      "2017-09-28 22:33:38.248128: step 3590, loss = 110596.87 (37.6 examples/sec; 3.401 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.293851\n",
      "2017-09-28 22:34:12.133750: step 3600, loss = 109712.79 (37.8 examples/sec; 3.389 sec/batch)\n",
      "2017-09-28 22:34:45.799747: step 3610, loss = 108839.95 (38.0 examples/sec; 3.367 sec/batch)\n",
      "2017-09-28 22:35:19.326818: step 3620, loss = 107970.81 (38.2 examples/sec; 3.353 sec/batch)\n",
      "2017-09-28 22:35:53.818494: step 3630, loss = 107110.89 (37.1 examples/sec; 3.449 sec/batch)\n",
      "2017-09-28 22:36:28.159524: step 3640, loss = 106261.47 (37.3 examples/sec; 3.434 sec/batch)\n",
      "2017-09-28 22:37:01.699773: step 3650, loss = 105409.99 (38.2 examples/sec; 3.354 sec/batch)\n",
      "2017-09-28 22:37:35.997162: step 3660, loss = 104570.65 (37.3 examples/sec; 3.430 sec/batch)\n",
      "2017-09-28 22:38:10.353039: step 3670, loss = 103736.35 (37.3 examples/sec; 3.436 sec/batch)\n",
      "2017-09-28 22:38:43.158195: step 3680, loss = 102910.30 (39.0 examples/sec; 3.281 sec/batch)\n",
      "2017-09-28 22:39:15.149149: step 3690, loss = 102092.62 (40.0 examples/sec; 3.199 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.296752\n",
      "2017-09-28 22:39:49.118731: step 3700, loss = 101276.03 (37.7 examples/sec; 3.397 sec/batch)\n",
      "2017-09-28 22:40:22.172343: step 3710, loss = 100471.31 (38.7 examples/sec; 3.305 sec/batch)\n",
      "2017-09-28 22:40:55.953434: step 3720, loss = 99668.11 (37.9 examples/sec; 3.378 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 3726 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-28 22:41:33.807365: step 3730, loss = 98874.98 (33.8 examples/sec; 3.785 sec/batch)\n",
      "2017-09-28 22:42:07.673358: step 3740, loss = 98085.74 (37.8 examples/sec; 3.387 sec/batch)\n",
      "2017-09-28 22:42:41.508961: step 3750, loss = 97304.80 (37.8 examples/sec; 3.384 sec/batch)\n",
      "2017-09-28 22:43:15.708346: step 3760, loss = 96532.30 (37.4 examples/sec; 3.420 sec/batch)\n",
      "2017-09-28 22:43:49.412703: step 3770, loss = 95759.59 (38.0 examples/sec; 3.370 sec/batch)\n",
      "2017-09-28 22:44:23.211306: step 3780, loss = 94998.52 (37.9 examples/sec; 3.380 sec/batch)\n",
      "2017-09-28 22:44:57.594342: step 3790, loss = 94239.16 (37.2 examples/sec; 3.438 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.291141\n",
      "2017-09-28 22:45:32.594404: step 3800, loss = 93488.89 (36.6 examples/sec; 3.500 sec/batch)\n",
      "2017-09-28 22:46:05.548300: step 3810, loss = 92748.63 (38.8 examples/sec; 3.295 sec/batch)\n",
      "2017-09-28 22:46:39.252545: step 3820, loss = 92004.25 (38.0 examples/sec; 3.370 sec/batch)\n",
      "2017-09-28 22:47:12.748668: step 3830, loss = 91273.55 (38.2 examples/sec; 3.350 sec/batch)\n",
      "2017-09-28 22:47:46.615103: step 3840, loss = 90543.11 (37.8 examples/sec; 3.387 sec/batch)\n",
      "2017-09-28 22:48:20.567529: step 3850, loss = 89821.41 (37.7 examples/sec; 3.395 sec/batch)\n",
      "2017-09-28 22:48:54.254139: step 3860, loss = 89105.53 (38.0 examples/sec; 3.369 sec/batch)\n",
      "2017-09-28 22:49:28.047418: step 3870, loss = 88396.05 (37.9 examples/sec; 3.379 sec/batch)\n",
      "2017-09-28 22:50:02.007658: step 3880, loss = 87694.24 (37.7 examples/sec; 3.396 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-09-28 22:50:36.429286: step 3890, loss = 86992.32 (37.2 examples/sec; 3.442 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.296219\n",
      "INFO:tensorflow:Saving checkpoints for 3902 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-28 22:51:13.594176: step 3900, loss = 86300.12 (34.4 examples/sec; 3.716 sec/batch)\n",
      "2017-09-28 22:51:47.379012: step 3910, loss = 85611.21 (37.9 examples/sec; 3.378 sec/batch)\n",
      "2017-09-28 22:52:20.994367: step 3920, loss = 84929.55 (38.1 examples/sec; 3.362 sec/batch)\n",
      "2017-09-28 22:52:54.832679: step 3930, loss = 84257.14 (37.8 examples/sec; 3.384 sec/batch)\n",
      "2017-09-28 22:53:28.818068: step 3940, loss = 83580.62 (37.7 examples/sec; 3.399 sec/batch)\n",
      "2017-09-28 22:54:02.721855: step 3950, loss = 82916.23 (37.8 examples/sec; 3.390 sec/batch)\n",
      "2017-09-28 22:54:36.672036: step 3960, loss = 82253.58 (37.7 examples/sec; 3.395 sec/batch)\n",
      "2017-09-28 22:55:10.624859: step 3970, loss = 81599.36 (37.7 examples/sec; 3.395 sec/batch)\n",
      "2017-09-28 22:55:44.607097: step 3980, loss = 80947.78 (37.7 examples/sec; 3.398 sec/batch)\n",
      "2017-09-28 22:56:18.629337: step 3990, loss = 80303.20 (37.6 examples/sec; 3.402 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.291622\n",
      "2017-09-28 22:56:53.090010: step 4000, loss = 79666.61 (37.1 examples/sec; 3.446 sec/batch)\n",
      "2017-09-28 22:57:27.072175: step 4010, loss = 79027.78 (37.7 examples/sec; 3.398 sec/batch)\n",
      "2017-09-28 22:58:01.782433: step 4020, loss = 78399.47 (36.9 examples/sec; 3.471 sec/batch)\n",
      "2017-09-28 22:58:37.771641: step 4030, loss = 77773.14 (35.6 examples/sec; 3.599 sec/batch)\n",
      "2017-09-28 22:59:11.577193: step 4040, loss = 77154.00 (37.9 examples/sec; 3.381 sec/batch)\n",
      "2017-09-28 22:59:45.882778: step 4050, loss = 76543.66 (37.3 examples/sec; 3.431 sec/batch)\n",
      "2017-09-28 23:00:18.906425: step 4060, loss = 75928.80 (38.8 examples/sec; 3.302 sec/batch)\n",
      "2017-09-28 23:00:51.871141: step 4070, loss = 75325.63 (38.8 examples/sec; 3.296 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 4078 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-28 23:01:29.794976: step 4080, loss = 74723.11 (33.8 examples/sec; 3.792 sec/batch)\n",
      "2017-09-28 23:02:03.720104: step 4090, loss = 74129.06 (37.7 examples/sec; 3.393 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.290637\n",
      "2017-09-28 23:02:37.163853: step 4100, loss = 73538.27 (38.3 examples/sec; 3.344 sec/batch)\n",
      "2017-09-28 23:03:13.004183: step 4110, loss = 72950.70 (35.7 examples/sec; 3.584 sec/batch)\n",
      "2017-09-28 23:03:46.912502: step 4120, loss = 72372.28 (37.7 examples/sec; 3.391 sec/batch)\n",
      "2017-09-28 23:04:20.880086: step 4130, loss = 71792.59 (37.7 examples/sec; 3.397 sec/batch)\n",
      "2017-09-28 23:04:54.669505: step 4140, loss = 71221.99 (37.9 examples/sec; 3.379 sec/batch)\n",
      "2017-09-28 23:05:28.539253: step 4150, loss = 70652.78 (37.8 examples/sec; 3.387 sec/batch)\n",
      "2017-09-28 23:06:02.531359: step 4160, loss = 70090.73 (37.7 examples/sec; 3.399 sec/batch)\n",
      "2017-09-28 23:06:36.102958: step 4170, loss = 69534.95 (38.1 examples/sec; 3.357 sec/batch)\n",
      "2017-09-28 23:07:09.878115: step 4180, loss = 68977.05 (37.9 examples/sec; 3.378 sec/batch)\n",
      "2017-09-28 23:07:44.225112: step 4190, loss = 68429.31 (37.3 examples/sec; 3.435 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.292558\n",
      "2017-09-28 23:08:18.974448: step 4200, loss = 67881.86 (36.8 examples/sec; 3.475 sec/batch)\n",
      "2017-09-28 23:08:52.422124: step 4210, loss = 67341.75 (38.3 examples/sec; 3.345 sec/batch)\n",
      "2017-09-28 23:09:26.336959: step 4220, loss = 66808.92 (37.7 examples/sec; 3.391 sec/batch)\n",
      "2017-09-28 23:10:00.491253: step 4230, loss = 66272.08 (37.5 examples/sec; 3.415 sec/batch)\n",
      "2017-09-28 23:10:35.027887: step 4240, loss = 65747.09 (37.1 examples/sec; 3.454 sec/batch)\n",
      "2017-09-28 23:11:09.086335: step 4250, loss = 65219.86 (37.6 examples/sec; 3.406 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 4253 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-28 23:11:47.585308: step 4260, loss = 64701.24 (33.2 examples/sec; 3.850 sec/batch)\n",
      "2017-09-28 23:12:21.807952: step 4270, loss = 64184.34 (37.4 examples/sec; 3.422 sec/batch)\n",
      "2017-09-28 23:12:55.831836: step 4280, loss = 63674.20 (37.6 examples/sec; 3.402 sec/batch)\n",
      "2017-09-28 23:13:29.252520: step 4290, loss = 63169.04 (38.3 examples/sec; 3.342 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.289846\n",
      "2017-09-28 23:14:03.984831: step 4300, loss = 62662.11 (36.9 examples/sec; 3.473 sec/batch)\n",
      "2017-09-28 23:14:38.033965: step 4310, loss = 62164.71 (37.6 examples/sec; 3.405 sec/batch)\n",
      "2017-09-28 23:15:11.855497: step 4320, loss = 61667.00 (37.8 examples/sec; 3.382 sec/batch)\n",
      "2017-09-28 23:15:46.022490: step 4330, loss = 61176.25 (37.5 examples/sec; 3.417 sec/batch)\n",
      "2017-09-28 23:16:19.370518: step 4340, loss = 60694.34 (38.4 examples/sec; 3.335 sec/batch)\n",
      "2017-09-28 23:16:53.281391: step 4350, loss = 60204.50 (37.7 examples/sec; 3.391 sec/batch)\n",
      "2017-09-28 23:17:28.695578: step 4360, loss = 59727.41 (36.1 examples/sec; 3.541 sec/batch)\n",
      "2017-09-28 23:18:02.572816: step 4370, loss = 59248.54 (37.8 examples/sec; 3.388 sec/batch)\n",
      "2017-09-28 23:18:35.334284: step 4380, loss = 58777.55 (39.1 examples/sec; 3.276 sec/batch)\n",
      "2017-09-28 23:19:09.323067: step 4390, loss = 58307.92 (37.7 examples/sec; 3.399 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.294391\n",
      "2017-09-28 23:19:43.668533: step 4400, loss = 57843.95 (37.3 examples/sec; 3.435 sec/batch)\n",
      "2017-09-28 23:20:17.779753: step 4410, loss = 57386.61 (37.5 examples/sec; 3.411 sec/batch)\n",
      "2017-09-28 23:20:51.640987: step 4420, loss = 56925.05 (37.8 examples/sec; 3.386 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 4429 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-28 23:21:29.802003: step 4430, loss = 56472.96 (33.5 examples/sec; 3.816 sec/batch)\n",
      "2017-09-28 23:22:03.686897: step 4440, loss = 56021.18 (37.8 examples/sec; 3.388 sec/batch)\n",
      "2017-09-28 23:22:37.547922: step 4450, loss = 55575.01 (37.8 examples/sec; 3.386 sec/batch)\n",
      "2017-09-28 23:23:11.985201: step 4460, loss = 55137.19 (37.2 examples/sec; 3.444 sec/batch)\n",
      "2017-09-28 23:23:46.018430: step 4470, loss = 54692.59 (37.6 examples/sec; 3.403 sec/batch)\n",
      "2017-09-28 23:24:19.957981: step 4480, loss = 54258.42 (37.7 examples/sec; 3.394 sec/batch)\n",
      "2017-09-28 23:24:53.902466: step 4490, loss = 53824.19 (37.7 examples/sec; 3.394 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.290184\n",
      "2017-09-28 23:25:28.277590: step 4500, loss = 53395.96 (37.2 examples/sec; 3.438 sec/batch)\n",
      "2017-09-28 23:26:02.729619: step 4510, loss = 52971.28 (37.2 examples/sec; 3.445 sec/batch)\n",
      "2017-09-28 23:26:36.647432: step 4520, loss = 52547.50 (37.7 examples/sec; 3.392 sec/batch)\n",
      "2017-09-28 23:27:10.824958: step 4530, loss = 52131.77 (37.5 examples/sec; 3.418 sec/batch)\n",
      "2017-09-28 23:27:44.732061: step 4540, loss = 51713.52 (37.8 examples/sec; 3.391 sec/batch)\n",
      "2017-09-28 23:28:18.418021: step 4550, loss = 51302.33 (38.0 examples/sec; 3.369 sec/batch)\n",
      "2017-09-28 23:28:49.428502: step 4560, loss = 50892.25 (41.3 examples/sec; 3.101 sec/batch)\n",
      "2017-09-28 23:29:21.894292: step 4570, loss = 50487.63 (39.4 examples/sec; 3.247 sec/batch)\n",
      "2017-09-28 23:29:55.205511: step 4580, loss = 50088.69 (38.4 examples/sec; 3.331 sec/batch)\n",
      "2017-09-28 23:30:29.707261: step 4590, loss = 49685.37 (37.1 examples/sec; 3.450 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.297939\n",
      "2017-09-28 23:31:03.920513: step 4600, loss = 49291.06 (37.4 examples/sec; 3.421 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 4606 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-28 23:31:41.663904: step 4610, loss = 48896.41 (33.9 examples/sec; 3.774 sec/batch)\n",
      "2017-09-28 23:32:15.773511: step 4620, loss = 48508.10 (37.5 examples/sec; 3.411 sec/batch)\n",
      "2017-09-28 23:32:49.289476: step 4630, loss = 48124.12 (38.2 examples/sec; 3.352 sec/batch)\n",
      "2017-09-28 23:33:23.733601: step 4640, loss = 47737.42 (37.2 examples/sec; 3.444 sec/batch)\n",
      "2017-09-28 23:33:58.041908: step 4650, loss = 47359.07 (37.3 examples/sec; 3.431 sec/batch)\n",
      "2017-09-28 23:34:31.486252: step 4660, loss = 46978.80 (38.3 examples/sec; 3.344 sec/batch)\n",
      "2017-09-28 23:35:05.712310: step 4670, loss = 46605.61 (37.4 examples/sec; 3.423 sec/batch)\n",
      "2017-09-28 23:35:39.777604: step 4680, loss = 46232.92 (37.6 examples/sec; 3.407 sec/batch)\n",
      "2017-09-28 23:36:14.472240: step 4690, loss = 45865.05 (36.9 examples/sec; 3.469 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.289536\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-09-28 23:36:49.300923: step 4700, loss = 45503.32 (36.8 examples/sec; 3.483 sec/batch)\n",
      "2017-09-28 23:37:22.367361: step 4710, loss = 45136.43 (38.7 examples/sec; 3.307 sec/batch)\n",
      "2017-09-28 23:37:55.800268: step 4720, loss = 44778.70 (38.3 examples/sec; 3.343 sec/batch)\n",
      "2017-09-28 23:38:29.329663: step 4730, loss = 44419.75 (38.2 examples/sec; 3.353 sec/batch)\n",
      "2017-09-28 23:39:03.320067: step 4740, loss = 44066.76 (37.7 examples/sec; 3.399 sec/batch)\n",
      "2017-09-28 23:39:37.640487: step 4750, loss = 43720.46 (37.3 examples/sec; 3.432 sec/batch)\n",
      "2017-09-28 23:40:12.080459: step 4760, loss = 43366.80 (37.2 examples/sec; 3.444 sec/batch)\n",
      "2017-09-28 23:40:47.467938: step 4770, loss = 43022.93 (36.2 examples/sec; 3.539 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 4781 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-28 23:41:25.103742: step 4780, loss = 42677.74 (34.0 examples/sec; 3.764 sec/batch)\n",
      "2017-09-28 23:41:58.844524: step 4790, loss = 42339.09 (37.9 examples/sec; 3.374 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.29078\n",
      "2017-09-28 23:42:33.200106: step 4800, loss = 42000.19 (37.3 examples/sec; 3.436 sec/batch)\n",
      "2017-09-28 23:43:07.287669: step 4810, loss = 41665.44 (37.6 examples/sec; 3.409 sec/batch)\n",
      "2017-09-28 23:43:41.069768: step 4820, loss = 41335.52 (37.9 examples/sec; 3.378 sec/batch)\n",
      "2017-09-28 23:44:15.141600: step 4830, loss = 41003.88 (37.6 examples/sec; 3.407 sec/batch)\n",
      "2017-09-28 23:44:49.200461: step 4840, loss = 40678.20 (37.6 examples/sec; 3.406 sec/batch)\n",
      "2017-09-28 23:45:23.888393: step 4850, loss = 40352.97 (36.9 examples/sec; 3.469 sec/batch)\n",
      "2017-09-28 23:45:57.170307: step 4860, loss = 40032.06 (38.5 examples/sec; 3.328 sec/batch)\n",
      "2017-09-28 23:46:31.799633: step 4870, loss = 39717.15 (37.0 examples/sec; 3.463 sec/batch)\n",
      "2017-09-28 23:47:06.025622: step 4880, loss = 39395.84 (37.4 examples/sec; 3.423 sec/batch)\n",
      "2017-09-28 23:47:40.330379: step 4890, loss = 39083.39 (37.3 examples/sec; 3.430 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.292334\n",
      "2017-09-28 23:48:15.275170: step 4900, loss = 38770.51 (36.6 examples/sec; 3.494 sec/batch)\n",
      "2017-09-28 23:48:49.790891: step 4910, loss = 38462.54 (37.1 examples/sec; 3.452 sec/batch)\n",
      "2017-09-28 23:49:24.029387: step 4920, loss = 38156.42 (37.4 examples/sec; 3.424 sec/batch)\n",
      "2017-09-28 23:49:57.212035: step 4930, loss = 37851.34 (38.6 examples/sec; 3.318 sec/batch)\n",
      "2017-09-28 23:50:31.271653: step 4940, loss = 37552.23 (37.6 examples/sec; 3.406 sec/batch)\n",
      "2017-09-28 23:51:05.282878: step 4950, loss = 37249.99 (37.6 examples/sec; 3.401 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 4956 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-28 23:51:43.766841: step 4960, loss = 36954.23 (33.3 examples/sec; 3.848 sec/batch)\n",
      "2017-09-28 23:52:17.829802: step 4970, loss = 36658.56 (37.6 examples/sec; 3.406 sec/batch)\n",
      "2017-09-28 23:52:51.708597: step 4980, loss = 36366.77 (37.8 examples/sec; 3.388 sec/batch)\n",
      "2017-09-28 23:53:25.867850: step 4990, loss = 36081.57 (37.5 examples/sec; 3.416 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.289221\n",
      "2017-09-28 23:54:01.032722: step 5000, loss = 35789.23 (36.4 examples/sec; 3.516 sec/batch)\n",
      "2017-09-28 23:54:35.148775: step 5010, loss = 35505.18 (37.5 examples/sec; 3.412 sec/batch)\n",
      "2017-09-28 23:55:09.254531: step 5020, loss = 35220.84 (37.5 examples/sec; 3.411 sec/batch)\n",
      "2017-09-28 23:55:43.975553: step 5030, loss = 34941.29 (36.9 examples/sec; 3.472 sec/batch)\n",
      "2017-09-28 23:56:18.797307: step 5040, loss = 34665.38 (36.8 examples/sec; 3.482 sec/batch)\n",
      "2017-09-28 23:56:55.420447: step 5050, loss = 34385.62 (35.0 examples/sec; 3.662 sec/batch)\n",
      "2017-09-28 23:57:29.562091: step 5060, loss = 34113.64 (37.5 examples/sec; 3.414 sec/batch)\n",
      "2017-09-28 23:58:03.432717: step 5070, loss = 33839.54 (37.8 examples/sec; 3.387 sec/batch)\n",
      "2017-09-28 23:58:37.451096: step 5080, loss = 33571.06 (37.6 examples/sec; 3.402 sec/batch)\n",
      "2017-09-28 23:59:11.489026: step 5090, loss = 33302.38 (37.6 examples/sec; 3.404 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.289658\n",
      "2017-09-28 23:59:46.274725: step 5100, loss = 33037.51 (36.8 examples/sec; 3.479 sec/batch)\n",
      "2017-09-29 00:00:20.923790: step 5110, loss = 32777.29 (36.9 examples/sec; 3.465 sec/batch)\n",
      "2017-09-29 00:00:55.326322: step 5120, loss = 32512.51 (37.2 examples/sec; 3.440 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 5129 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-29 00:01:33.228671: step 5130, loss = 32255.31 (33.8 examples/sec; 3.790 sec/batch)\n",
      "2017-09-29 00:02:07.995809: step 5140, loss = 31996.42 (36.8 examples/sec; 3.477 sec/batch)\n",
      "2017-09-29 00:02:42.048474: step 5150, loss = 31742.85 (37.6 examples/sec; 3.405 sec/batch)\n",
      "2017-09-29 00:03:15.811303: step 5160, loss = 31492.85 (37.9 examples/sec; 3.376 sec/batch)\n",
      "2017-09-29 00:03:50.984982: step 5170, loss = 31237.80 (36.4 examples/sec; 3.517 sec/batch)\n",
      "2017-09-29 00:04:24.877309: step 5180, loss = 30991.54 (37.8 examples/sec; 3.389 sec/batch)\n",
      "2017-09-29 00:04:59.367850: step 5190, loss = 30741.62 (37.1 examples/sec; 3.449 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.287134\n",
      "2017-09-29 00:05:34.536109: step 5200, loss = 30497.69 (36.4 examples/sec; 3.517 sec/batch)\n",
      "2017-09-29 00:06:08.946271: step 5210, loss = 30253.41 (37.2 examples/sec; 3.441 sec/batch)\n",
      "2017-09-29 00:06:43.310817: step 5220, loss = 30012.28 (37.2 examples/sec; 3.436 sec/batch)\n",
      "2017-09-29 00:07:19.690956: step 5230, loss = 29776.30 (35.2 examples/sec; 3.638 sec/batch)\n",
      "2017-09-29 00:07:53.692338: step 5240, loss = 29536.08 (37.6 examples/sec; 3.400 sec/batch)\n",
      "2017-09-29 00:08:28.786569: step 5250, loss = 29302.52 (36.5 examples/sec; 3.509 sec/batch)\n",
      "2017-09-29 00:09:03.256757: step 5260, loss = 29067.48 (37.1 examples/sec; 3.447 sec/batch)\n",
      "2017-09-29 00:09:37.508076: step 5270, loss = 28836.61 (37.4 examples/sec; 3.425 sec/batch)\n",
      "2017-09-29 00:10:12.386248: step 5280, loss = 28611.17 (36.7 examples/sec; 3.488 sec/batch)\n",
      "2017-09-29 00:10:47.158236: step 5290, loss = 28378.49 (36.8 examples/sec; 3.477 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.286875\n",
      "INFO:tensorflow:Saving checkpoints for 5302 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-29 00:11:26.892069: step 5300, loss = 28153.65 (32.2 examples/sec; 3.973 sec/batch)\n",
      "2017-09-29 00:12:04.612856: step 5310, loss = 27927.04 (33.9 examples/sec; 3.772 sec/batch)\n",
      "2017-09-29 00:12:42.062943: step 5320, loss = 27705.69 (34.2 examples/sec; 3.745 sec/batch)\n",
      "2017-09-29 00:13:19.553469: step 5330, loss = 27484.62 (34.1 examples/sec; 3.749 sec/batch)\n",
      "2017-09-29 00:13:56.854962: step 5340, loss = 27264.65 (34.3 examples/sec; 3.730 sec/batch)\n",
      "2017-09-29 00:14:35.188806: step 5350, loss = 27050.09 (33.4 examples/sec; 3.833 sec/batch)\n",
      "2017-09-29 00:15:13.162198: step 5360, loss = 26831.75 (33.7 examples/sec; 3.797 sec/batch)\n",
      "2017-09-29 00:15:50.658696: step 5370, loss = 26619.10 (34.1 examples/sec; 3.750 sec/batch)\n",
      "2017-09-29 00:16:28.133596: step 5380, loss = 26405.70 (34.2 examples/sec; 3.747 sec/batch)\n",
      "2017-09-29 00:17:04.251317: step 5390, loss = 26195.91 (35.4 examples/sec; 3.612 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.263476\n",
      "2017-09-29 00:17:42.663755: step 5400, loss = 25991.49 (33.3 examples/sec; 3.841 sec/batch)\n",
      "2017-09-29 00:18:19.178154: step 5410, loss = 25779.96 (35.1 examples/sec; 3.651 sec/batch)\n",
      "2017-09-29 00:18:56.736273: step 5420, loss = 25576.52 (34.1 examples/sec; 3.756 sec/batch)\n",
      "2017-09-29 00:19:33.340709: step 5430, loss = 25370.25 (35.0 examples/sec; 3.660 sec/batch)\n",
      "2017-09-29 00:20:11.416371: step 5440, loss = 25169.20 (33.6 examples/sec; 3.808 sec/batch)\n",
      "2017-09-29 00:20:49.009563: step 5450, loss = 24971.30 (34.0 examples/sec; 3.759 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 5462 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-29 00:21:31.203121: step 5460, loss = 24769.68 (30.3 examples/sec; 4.219 sec/batch)\n",
      "2017-09-29 00:22:09.392607: step 5470, loss = 24572.82 (33.5 examples/sec; 3.819 sec/batch)\n",
      "2017-09-29 00:22:47.353739: step 5480, loss = 24375.24 (33.7 examples/sec; 3.796 sec/batch)\n",
      "2017-09-29 00:23:25.648290: step 5490, loss = 24182.87 (33.4 examples/sec; 3.829 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.262482\n",
      "2017-09-29 00:24:03.640614: step 5500, loss = 23988.44 (33.7 examples/sec; 3.799 sec/batch)\n",
      "2017-09-29 00:24:41.270180: step 5510, loss = 23797.53 (34.0 examples/sec; 3.763 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-09-29 00:25:19.293085: step 5520, loss = 23610.30 (33.7 examples/sec; 3.802 sec/batch)\n",
      "2017-09-29 00:25:56.470438: step 5530, loss = 23419.37 (34.4 examples/sec; 3.718 sec/batch)\n",
      "2017-09-29 00:26:32.094613: step 5540, loss = 23235.28 (35.9 examples/sec; 3.562 sec/batch)\n",
      "2017-09-29 00:27:09.972677: step 5550, loss = 23048.12 (33.8 examples/sec; 3.788 sec/batch)\n",
      "2017-09-29 00:27:47.696110: step 5560, loss = 22865.73 (33.9 examples/sec; 3.772 sec/batch)\n",
      "2017-09-29 00:28:25.771018: step 5570, loss = 22687.38 (33.6 examples/sec; 3.807 sec/batch)\n",
      "2017-09-29 00:29:03.672442: step 5580, loss = 22501.67 (33.8 examples/sec; 3.790 sec/batch)\n",
      "2017-09-29 00:29:41.093354: step 5590, loss = 22324.48 (34.2 examples/sec; 3.742 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.266116\n",
      "2017-09-29 00:30:19.415986: step 5600, loss = 22143.86 (33.4 examples/sec; 3.832 sec/batch)\n",
      "2017-09-29 00:30:54.935181: step 5610, loss = 21968.19 (36.0 examples/sec; 3.552 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 5621 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-29 00:31:36.525322: step 5620, loss = 21792.02 (30.8 examples/sec; 4.159 sec/batch)\n",
      "2017-09-29 00:32:13.335419: step 5630, loss = 21618.78 (34.8 examples/sec; 3.681 sec/batch)\n",
      "2017-09-29 00:32:50.027030: step 5640, loss = 21450.23 (34.9 examples/sec; 3.669 sec/batch)\n",
      "2017-09-29 00:33:27.909003: step 5650, loss = 21275.29 (33.8 examples/sec; 3.788 sec/batch)\n",
      "2017-09-29 00:34:05.664202: step 5660, loss = 21106.82 (33.9 examples/sec; 3.776 sec/batch)\n",
      "2017-09-29 00:34:40.964805: step 5670, loss = 20937.45 (36.3 examples/sec; 3.530 sec/batch)\n",
      "2017-09-29 00:35:19.186440: step 5680, loss = 20770.86 (33.5 examples/sec; 3.822 sec/batch)\n",
      "2017-09-29 00:35:56.153337: step 5690, loss = 20611.81 (34.6 examples/sec; 3.697 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.266806\n",
      "2017-09-29 00:36:34.224814: step 5700, loss = 20441.04 (33.6 examples/sec; 3.807 sec/batch)\n",
      "2017-09-29 00:37:11.484424: step 5710, loss = 20280.18 (34.4 examples/sec; 3.726 sec/batch)\n",
      "2017-09-29 00:37:48.155324: step 5720, loss = 20116.37 (34.9 examples/sec; 3.667 sec/batch)\n",
      "2017-09-29 00:38:25.815859: step 5730, loss = 19957.40 (34.0 examples/sec; 3.766 sec/batch)\n",
      "2017-09-29 00:39:03.337601: step 5740, loss = 19797.66 (34.1 examples/sec; 3.752 sec/batch)\n",
      "2017-09-29 00:39:41.104285: step 5750, loss = 19639.90 (33.9 examples/sec; 3.777 sec/batch)\n",
      "2017-09-29 00:40:18.654552: step 5760, loss = 19486.36 (34.1 examples/sec; 3.755 sec/batch)\n",
      "2017-09-29 00:40:56.240805: step 5770, loss = 19327.70 (34.1 examples/sec; 3.759 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 5781 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-29 00:41:37.779850: step 5780, loss = 19176.22 (30.8 examples/sec; 4.154 sec/batch)\n",
      "2017-09-29 00:42:16.154396: step 5790, loss = 19020.56 (33.4 examples/sec; 3.837 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.263149\n",
      "2017-09-29 00:42:54.235022: step 5800, loss = 18869.69 (33.6 examples/sec; 3.808 sec/batch)\n",
      "2017-09-29 00:43:28.878856: step 5810, loss = 18723.88 (36.9 examples/sec; 3.464 sec/batch)\n",
      "2017-09-29 00:44:05.009880: step 5820, loss = 18570.10 (35.4 examples/sec; 3.613 sec/batch)\n",
      "2017-09-29 00:44:42.637328: step 5830, loss = 18423.89 (34.0 examples/sec; 3.763 sec/batch)\n",
      "2017-09-29 00:45:20.091489: step 5840, loss = 18274.66 (34.2 examples/sec; 3.745 sec/batch)\n",
      "2017-09-29 00:45:57.369893: step 5850, loss = 18130.28 (34.3 examples/sec; 3.728 sec/batch)\n",
      "2017-09-29 00:46:34.773083: step 5860, loss = 17987.67 (34.2 examples/sec; 3.740 sec/batch)\n",
      "2017-09-29 00:47:11.979678: step 5870, loss = 17841.87 (34.4 examples/sec; 3.721 sec/batch)\n",
      "2017-09-29 00:47:49.460116: step 5880, loss = 17701.79 (34.2 examples/sec; 3.748 sec/batch)\n",
      "2017-09-29 00:48:26.854101: step 5890, loss = 17557.97 (34.2 examples/sec; 3.739 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.269754\n",
      "2017-09-29 00:49:04.943457: step 5900, loss = 17418.70 (33.6 examples/sec; 3.809 sec/batch)\n",
      "2017-09-29 00:49:41.526315: step 5910, loss = 17279.10 (35.0 examples/sec; 3.658 sec/batch)\n",
      "2017-09-29 00:50:19.119194: step 5920, loss = 17142.16 (34.0 examples/sec; 3.759 sec/batch)\n",
      "2017-09-29 00:50:54.921818: step 5930, loss = 17008.78 (35.8 examples/sec; 3.580 sec/batch)\n",
      "2017-09-29 00:51:28.010531: step 5940, loss = 16869.60 (38.7 examples/sec; 3.309 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 5943 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-29 00:52:04.958536: step 5950, loss = 16737.38 (34.6 examples/sec; 3.695 sec/batch)\n",
      "2017-09-29 00:52:38.311425: step 5960, loss = 16601.86 (38.4 examples/sec; 3.335 sec/batch)\n",
      "2017-09-29 00:53:11.747926: step 5970, loss = 16471.29 (38.3 examples/sec; 3.344 sec/batch)\n",
      "2017-09-29 00:53:45.117848: step 5980, loss = 16343.54 (38.4 examples/sec; 3.337 sec/batch)\n",
      "2017-09-29 00:54:18.615800: step 5990, loss = 16208.08 (38.2 examples/sec; 3.350 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.287687\n",
      "2017-09-29 00:54:52.540013: step 6000, loss = 16081.62 (37.7 examples/sec; 3.392 sec/batch)\n",
      "2017-09-29 00:55:26.109863: step 6010, loss = 15950.98 (38.1 examples/sec; 3.357 sec/batch)\n",
      "2017-09-29 00:55:59.850911: step 6020, loss = 15824.99 (37.9 examples/sec; 3.374 sec/batch)\n",
      "2017-09-29 00:56:33.562022: step 6030, loss = 15697.24 (38.0 examples/sec; 3.371 sec/batch)\n",
      "2017-09-29 00:57:07.194359: step 6040, loss = 15572.72 (38.1 examples/sec; 3.363 sec/batch)\n",
      "2017-09-29 00:57:40.585225: step 6050, loss = 15451.59 (38.3 examples/sec; 3.339 sec/batch)\n",
      "2017-09-29 00:58:15.902671: step 6060, loss = 15324.93 (36.2 examples/sec; 3.532 sec/batch)\n",
      "2017-09-29 00:58:50.184093: step 6070, loss = 15204.30 (37.3 examples/sec; 3.428 sec/batch)\n",
      "2017-09-29 00:59:23.899696: step 6080, loss = 15081.53 (38.0 examples/sec; 3.372 sec/batch)\n",
      "2017-09-29 00:59:57.533508: step 6090, loss = 14962.00 (38.1 examples/sec; 3.363 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.295091\n",
      "2017-09-29 01:00:31.421407: step 6100, loss = 14848.38 (37.8 examples/sec; 3.389 sec/batch)\n",
      "2017-09-29 01:01:04.801068: step 6110, loss = 14724.26 (38.3 examples/sec; 3.338 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 6120 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-29 01:01:41.536485: step 6120, loss = 14609.40 (34.8 examples/sec; 3.674 sec/batch)\n",
      "2017-09-29 01:02:12.512974: step 6130, loss = 14490.21 (41.3 examples/sec; 3.098 sec/batch)\n",
      "2017-09-29 01:02:46.125031: step 6140, loss = 14375.86 (38.1 examples/sec; 3.361 sec/batch)\n",
      "2017-09-29 01:03:19.617756: step 6150, loss = 14260.46 (38.2 examples/sec; 3.349 sec/batch)\n",
      "2017-09-29 01:03:53.286171: step 6160, loss = 14146.83 (38.0 examples/sec; 3.367 sec/batch)\n",
      "2017-09-29 01:04:26.861262: step 6170, loss = 14036.81 (38.1 examples/sec; 3.358 sec/batch)\n",
      "2017-09-29 01:05:00.613235: step 6180, loss = 13921.89 (37.9 examples/sec; 3.375 sec/batch)\n",
      "2017-09-29 01:05:34.186636: step 6190, loss = 13811.96 (38.1 examples/sec; 3.357 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.297061\n",
      "2017-09-29 01:06:08.050186: step 6200, loss = 13700.83 (37.8 examples/sec; 3.386 sec/batch)\n",
      "2017-09-29 01:06:41.734883: step 6210, loss = 13591.69 (38.0 examples/sec; 3.368 sec/batch)\n",
      "2017-09-29 01:07:15.324548: step 6220, loss = 13488.86 (38.1 examples/sec; 3.359 sec/batch)\n",
      "2017-09-29 01:07:48.749410: step 6230, loss = 13376.19 (38.3 examples/sec; 3.342 sec/batch)\n",
      "2017-09-29 01:08:22.281149: step 6240, loss = 13271.63 (38.2 examples/sec; 3.353 sec/batch)\n",
      "2017-09-29 01:08:55.926553: step 6250, loss = 13163.55 (38.0 examples/sec; 3.365 sec/batch)\n",
      "2017-09-29 01:09:29.253371: step 6260, loss = 13059.91 (38.4 examples/sec; 3.333 sec/batch)\n",
      "2017-09-29 01:10:02.897152: step 6270, loss = 12957.32 (38.0 examples/sec; 3.364 sec/batch)\n",
      "2017-09-29 01:10:36.674878: step 6280, loss = 12851.85 (37.9 examples/sec; 3.378 sec/batch)\n",
      "2017-09-29 01:11:10.263835: step 6290, loss = 12752.06 (38.1 examples/sec; 3.359 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 6299 into /tmp/phd08_train/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.293811\n",
      "2017-09-29 01:11:48.407003: step 6300, loss = 12647.38 (33.6 examples/sec; 3.814 sec/batch)\n",
      "2017-09-29 01:12:22.017642: step 6310, loss = 12548.79 (38.1 examples/sec; 3.361 sec/batch)\n",
      "2017-09-29 01:12:55.437197: step 6320, loss = 12446.91 (38.3 examples/sec; 3.342 sec/batch)\n",
      "2017-09-29 01:13:28.892302: step 6330, loss = 12348.84 (38.3 examples/sec; 3.346 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-09-29 01:14:02.484412: step 6340, loss = 12252.17 (38.1 examples/sec; 3.359 sec/batch)\n",
      "2017-09-29 01:14:35.833004: step 6350, loss = 12152.78 (38.4 examples/sec; 3.335 sec/batch)\n",
      "2017-09-29 01:15:05.596670: step 6360, loss = 12057.17 (43.0 examples/sec; 2.976 sec/batch)\n",
      "2017-09-29 01:15:34.489616: step 6370, loss = 11958.69 (44.3 examples/sec; 2.889 sec/batch)\n",
      "2017-09-29 01:16:03.540656: step 6380, loss = 11864.60 (44.1 examples/sec; 2.905 sec/batch)\n",
      "2017-09-29 01:16:32.697217: step 6390, loss = 11774.48 (43.9 examples/sec; 2.916 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.314589\n",
      "2017-09-29 01:17:06.280972: step 6400, loss = 11674.85 (38.1 examples/sec; 3.358 sec/batch)\n",
      "2017-09-29 01:17:39.927714: step 6410, loss = 11584.05 (38.0 examples/sec; 3.365 sec/batch)\n",
      "2017-09-29 01:18:13.557868: step 6420, loss = 11489.37 (38.1 examples/sec; 3.363 sec/batch)\n",
      "2017-09-29 01:18:47.197979: step 6430, loss = 11399.31 (38.0 examples/sec; 3.364 sec/batch)\n",
      "2017-09-29 01:19:19.908136: step 6440, loss = 11306.91 (39.1 examples/sec; 3.271 sec/batch)\n",
      "2017-09-29 01:19:52.974502: step 6450, loss = 11217.08 (38.7 examples/sec; 3.307 sec/batch)\n",
      "2017-09-29 01:20:26.352084: step 6460, loss = 11130.65 (38.3 examples/sec; 3.338 sec/batch)\n",
      "2017-09-29 01:20:59.817239: step 6470, loss = 11038.85 (38.2 examples/sec; 3.347 sec/batch)\n",
      "2017-09-29 01:21:33.252011: step 6480, loss = 10952.82 (38.3 examples/sec; 3.343 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 6483 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-29 01:22:10.040527: step 6490, loss = 10863.53 (34.8 examples/sec; 3.679 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.296126\n",
      "2017-09-29 01:22:43.974521: step 6500, loss = 10776.98 (37.7 examples/sec; 3.393 sec/batch)\n",
      "2017-09-29 01:23:17.490345: step 6510, loss = 10696.85 (38.2 examples/sec; 3.352 sec/batch)\n",
      "2017-09-29 01:23:50.990118: step 6520, loss = 10605.92 (38.2 examples/sec; 3.350 sec/batch)\n",
      "2017-09-29 01:24:24.605428: step 6530, loss = 10523.29 (38.1 examples/sec; 3.362 sec/batch)\n",
      "2017-09-29 01:24:58.120969: step 6540, loss = 10437.56 (38.2 examples/sec; 3.352 sec/batch)\n",
      "2017-09-29 01:25:31.821767: step 6550, loss = 10355.62 (38.0 examples/sec; 3.370 sec/batch)\n",
      "2017-09-29 01:26:05.267337: step 6560, loss = 10272.04 (38.3 examples/sec; 3.345 sec/batch)\n",
      "2017-09-29 01:26:38.552444: step 6570, loss = 10191.05 (38.5 examples/sec; 3.329 sec/batch)\n",
      "2017-09-29 01:27:12.228652: step 6580, loss = 10112.26 (38.0 examples/sec; 3.368 sec/batch)\n",
      "2017-09-29 01:27:45.713757: step 6590, loss = 10028.04 (38.2 examples/sec; 3.349 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.297936\n",
      "2017-09-29 01:28:19.616988: step 6600, loss = 9948.16 (37.8 examples/sec; 3.390 sec/batch)\n",
      "2017-09-29 01:28:53.059904: step 6610, loss = 9868.87 (38.3 examples/sec; 3.344 sec/batch)\n",
      "2017-09-29 01:29:26.559446: step 6620, loss = 9790.22 (38.2 examples/sec; 3.350 sec/batch)\n",
      "2017-09-29 01:30:00.030545: step 6630, loss = 9712.56 (38.2 examples/sec; 3.347 sec/batch)\n",
      "2017-09-29 01:30:33.541447: step 6640, loss = 9634.79 (38.2 examples/sec; 3.351 sec/batch)\n",
      "2017-09-29 01:31:06.913321: step 6650, loss = 9558.02 (38.4 examples/sec; 3.337 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 6661 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-29 01:31:44.383843: step 6660, loss = 9481.83 (34.2 examples/sec; 3.747 sec/batch)\n",
      "2017-09-29 01:32:17.892446: step 6670, loss = 9406.27 (38.2 examples/sec; 3.351 sec/batch)\n",
      "2017-09-29 01:32:51.469308: step 6680, loss = 9334.74 (38.1 examples/sec; 3.358 sec/batch)\n",
      "2017-09-29 01:33:25.060935: step 6690, loss = 9256.94 (38.1 examples/sec; 3.359 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.294757\n",
      "2017-09-29 01:33:58.873044: step 6700, loss = 9186.38 (37.9 examples/sec; 3.381 sec/batch)\n",
      "2017-09-29 01:34:32.516936: step 6710, loss = 9112.24 (38.0 examples/sec; 3.364 sec/batch)\n",
      "2017-09-29 01:35:06.346524: step 6720, loss = 9040.85 (37.8 examples/sec; 3.383 sec/batch)\n",
      "2017-09-29 01:35:39.833167: step 6730, loss = 8967.85 (38.2 examples/sec; 3.349 sec/batch)\n",
      "2017-09-29 01:36:12.889324: step 6740, loss = 8896.83 (38.7 examples/sec; 3.306 sec/batch)\n",
      "2017-09-29 01:36:46.405785: step 6750, loss = 8826.78 (38.2 examples/sec; 3.352 sec/batch)\n",
      "2017-09-29 01:37:20.140012: step 6760, loss = 8755.48 (37.9 examples/sec; 3.373 sec/batch)\n",
      "2017-09-29 01:37:53.862889: step 6770, loss = 8685.85 (38.0 examples/sec; 3.372 sec/batch)\n",
      "2017-09-29 01:38:27.415092: step 6780, loss = 8615.76 (38.1 examples/sec; 3.355 sec/batch)\n",
      "2017-09-29 01:39:00.823674: step 6790, loss = 8547.68 (38.3 examples/sec; 3.341 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.297702\n",
      "2017-09-29 01:39:34.778966: step 6800, loss = 8480.04 (37.7 examples/sec; 3.396 sec/batch)\n",
      "2017-09-29 01:40:08.197747: step 6810, loss = 8411.88 (38.3 examples/sec; 3.342 sec/batch)\n",
      "2017-09-29 01:40:41.586920: step 6820, loss = 8345.94 (38.3 examples/sec; 3.339 sec/batch)\n",
      "2017-09-29 01:41:14.961889: step 6830, loss = 8278.48 (38.4 examples/sec; 3.337 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 6839 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-29 01:41:51.992240: step 6840, loss = 8213.12 (34.6 examples/sec; 3.703 sec/batch)\n",
      "2017-09-29 01:42:25.623708: step 6850, loss = 8146.76 (38.1 examples/sec; 3.363 sec/batch)\n",
      "2017-09-29 01:42:59.072812: step 6860, loss = 8081.84 (38.3 examples/sec; 3.345 sec/batch)\n",
      "2017-09-29 01:43:32.705121: step 6870, loss = 8017.66 (38.1 examples/sec; 3.363 sec/batch)\n",
      "2017-09-29 01:44:06.335310: step 6880, loss = 7952.97 (38.1 examples/sec; 3.363 sec/batch)\n",
      "2017-09-29 01:44:39.715779: step 6890, loss = 7891.53 (38.3 examples/sec; 3.338 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.295187\n",
      "2017-09-29 01:45:13.896707: step 6900, loss = 7827.66 (37.4 examples/sec; 3.418 sec/batch)\n",
      "2017-09-29 01:45:47.523944: step 6910, loss = 7765.29 (38.1 examples/sec; 3.363 sec/batch)\n",
      "2017-09-29 01:46:21.158787: step 6920, loss = 7704.22 (38.1 examples/sec; 3.363 sec/batch)\n",
      "2017-09-29 01:46:54.689279: step 6930, loss = 7641.88 (38.2 examples/sec; 3.353 sec/batch)\n",
      "2017-09-29 01:47:28.335183: step 6940, loss = 7581.47 (38.0 examples/sec; 3.365 sec/batch)\n",
      "2017-09-29 01:48:01.964128: step 6950, loss = 7520.18 (38.1 examples/sec; 3.363 sec/batch)\n",
      "2017-09-29 01:48:35.401008: step 6960, loss = 7461.94 (38.3 examples/sec; 3.344 sec/batch)\n",
      "2017-09-29 01:49:08.840819: step 6970, loss = 7401.50 (38.3 examples/sec; 3.344 sec/batch)\n",
      "2017-09-29 01:49:42.150939: step 6980, loss = 7343.24 (38.4 examples/sec; 3.331 sec/batch)\n",
      "2017-09-29 01:50:15.926728: step 6990, loss = 7285.17 (37.9 examples/sec; 3.378 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.297151\n",
      "2017-09-29 01:50:50.076856: step 7000, loss = 7226.15 (37.5 examples/sec; 3.415 sec/batch)\n",
      "2017-09-29 01:51:23.599063: step 7010, loss = 7168.55 (38.2 examples/sec; 3.352 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 7017 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-29 01:52:00.568690: step 7020, loss = 7110.58 (34.6 examples/sec; 3.697 sec/batch)\n",
      "2017-09-29 01:52:34.211787: step 7030, loss = 7055.36 (38.0 examples/sec; 3.364 sec/batch)\n",
      "2017-09-29 01:53:07.704791: step 7040, loss = 7000.01 (38.2 examples/sec; 3.349 sec/batch)\n",
      "2017-09-29 01:53:41.434347: step 7050, loss = 6943.25 (37.9 examples/sec; 3.373 sec/batch)\n",
      "2017-09-29 01:54:14.903185: step 7060, loss = 6884.81 (38.2 examples/sec; 3.347 sec/batch)\n",
      "2017-09-29 01:54:48.464285: step 7070, loss = 6829.92 (38.1 examples/sec; 3.356 sec/batch)\n",
      "2017-09-29 01:55:22.275479: step 7080, loss = 6775.49 (37.9 examples/sec; 3.381 sec/batch)\n",
      "2017-09-29 01:55:55.863142: step 7090, loss = 6725.19 (38.1 examples/sec; 3.359 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.294392\n",
      "2017-09-29 01:56:29.768533: step 7100, loss = 6667.92 (37.8 examples/sec; 3.391 sec/batch)\n",
      "2017-09-29 01:57:03.546218: step 7110, loss = 6616.55 (37.9 examples/sec; 3.378 sec/batch)\n",
      "2017-09-29 01:57:37.059769: step 7120, loss = 6562.06 (38.2 examples/sec; 3.351 sec/batch)\n",
      "2017-09-29 01:58:10.476552: step 7130, loss = 6509.77 (38.3 examples/sec; 3.342 sec/batch)\n",
      "2017-09-29 01:58:44.104960: step 7140, loss = 6457.88 (38.1 examples/sec; 3.363 sec/batch)\n",
      "2017-09-29 01:59:17.823075: step 7150, loss = 6406.41 (38.0 examples/sec; 3.372 sec/batch)\n",
      "2017-09-29 01:59:51.258744: step 7160, loss = 6358.58 (38.3 examples/sec; 3.344 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-09-29 02:00:24.784817: step 7170, loss = 6304.70 (38.2 examples/sec; 3.353 sec/batch)\n",
      "2017-09-29 02:00:58.419832: step 7180, loss = 6254.49 (38.1 examples/sec; 3.364 sec/batch)\n",
      "2017-09-29 02:01:31.807913: step 7190, loss = 6204.61 (38.3 examples/sec; 3.339 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 7195 into /tmp/phd08_train/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.29419\n",
      "2017-09-29 02:02:09.683080: step 7200, loss = 6155.17 (33.8 examples/sec; 3.788 sec/batch)\n",
      "2017-09-29 02:02:43.335035: step 7210, loss = 6111.69 (38.0 examples/sec; 3.365 sec/batch)\n",
      "2017-09-29 02:03:16.910392: step 7220, loss = 6057.45 (38.1 examples/sec; 3.358 sec/batch)\n",
      "2017-09-29 02:03:50.596426: step 7230, loss = 6009.29 (38.0 examples/sec; 3.369 sec/batch)\n",
      "2017-09-29 02:04:24.171725: step 7240, loss = 5961.28 (38.1 examples/sec; 3.358 sec/batch)\n",
      "2017-09-29 02:04:57.801757: step 7250, loss = 5913.79 (38.1 examples/sec; 3.363 sec/batch)\n",
      "2017-09-29 02:05:31.375654: step 7260, loss = 5866.64 (38.1 examples/sec; 3.357 sec/batch)\n",
      "2017-09-29 02:06:04.705847: step 7270, loss = 5819.89 (38.4 examples/sec; 3.333 sec/batch)\n",
      "2017-09-29 02:06:38.294886: step 7280, loss = 5775.18 (38.1 examples/sec; 3.359 sec/batch)\n",
      "2017-09-29 02:07:11.908891: step 7290, loss = 5727.49 (38.1 examples/sec; 3.361 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.297563\n",
      "2017-09-29 02:07:45.749313: step 7300, loss = 5681.89 (37.8 examples/sec; 3.384 sec/batch)\n",
      "2017-09-29 02:08:17.091326: step 7310, loss = 5636.56 (40.8 examples/sec; 3.134 sec/batch)\n",
      "2017-09-29 02:08:50.704786: step 7320, loss = 5591.65 (38.1 examples/sec; 3.361 sec/batch)\n",
      "2017-09-29 02:09:24.424556: step 7330, loss = 5553.17 (38.0 examples/sec; 3.372 sec/batch)\n",
      "2017-09-29 02:09:58.110015: step 7340, loss = 5502.86 (38.0 examples/sec; 3.369 sec/batch)\n",
      "2017-09-29 02:10:31.775344: step 7350, loss = 5461.44 (38.0 examples/sec; 3.367 sec/batch)\n",
      "2017-09-29 02:11:05.250565: step 7360, loss = 5417.14 (38.2 examples/sec; 3.348 sec/batch)\n",
      "2017-09-29 02:11:38.913203: step 7370, loss = 5375.20 (38.0 examples/sec; 3.366 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 7373 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-29 02:12:16.565533: step 7380, loss = 5331.48 (34.0 examples/sec; 3.765 sec/batch)\n",
      "2017-09-29 02:12:50.144431: step 7390, loss = 5289.67 (38.1 examples/sec; 3.358 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.295575\n",
      "2017-09-29 02:13:24.062168: step 7400, loss = 5247.49 (37.7 examples/sec; 3.392 sec/batch)\n",
      "2017-09-29 02:13:57.425831: step 7410, loss = 5204.85 (38.4 examples/sec; 3.336 sec/batch)\n",
      "2017-09-29 02:14:31.100901: step 7420, loss = 5164.99 (38.0 examples/sec; 3.368 sec/batch)\n",
      "2017-09-29 02:15:04.614095: step 7430, loss = 5122.88 (38.2 examples/sec; 3.351 sec/batch)\n",
      "2017-09-29 02:15:38.124617: step 7440, loss = 5082.84 (38.2 examples/sec; 3.351 sec/batch)\n",
      "2017-09-29 02:16:11.655506: step 7450, loss = 5043.04 (38.2 examples/sec; 3.353 sec/batch)\n",
      "2017-09-29 02:16:45.277994: step 7460, loss = 5001.88 (38.1 examples/sec; 3.362 sec/batch)\n",
      "2017-09-29 02:17:18.891210: step 7470, loss = 4963.15 (38.1 examples/sec; 3.361 sec/batch)\n",
      "2017-09-29 02:17:52.323610: step 7480, loss = 4922.63 (38.3 examples/sec; 3.343 sec/batch)\n",
      "2017-09-29 02:18:25.606701: step 7490, loss = 4883.42 (38.5 examples/sec; 3.328 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.298292\n",
      "2017-09-29 02:18:59.303668: step 7500, loss = 4844.04 (38.0 examples/sec; 3.370 sec/batch)\n",
      "2017-09-29 02:19:32.733416: step 7510, loss = 4805.64 (38.3 examples/sec; 3.343 sec/batch)\n",
      "2017-09-29 02:20:06.440873: step 7520, loss = 4766.51 (38.0 examples/sec; 3.371 sec/batch)\n",
      "2017-09-29 02:20:40.094078: step 7530, loss = 4727.91 (38.0 examples/sec; 3.365 sec/batch)\n",
      "2017-09-29 02:21:13.548069: step 7540, loss = 4692.39 (38.3 examples/sec; 3.345 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 7551 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-29 02:21:50.404972: step 7550, loss = 4654.02 (34.7 examples/sec; 3.686 sec/batch)\n",
      "2017-09-29 02:22:23.952418: step 7560, loss = 4617.61 (38.2 examples/sec; 3.355 sec/batch)\n",
      "2017-09-29 02:22:57.716482: step 7570, loss = 4581.38 (37.9 examples/sec; 3.376 sec/batch)\n",
      "2017-09-29 02:23:31.077417: step 7580, loss = 4543.91 (38.4 examples/sec; 3.336 sec/batch)\n",
      "2017-09-29 02:24:04.762507: step 7590, loss = 4507.96 (38.0 examples/sec; 3.369 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.294735\n",
      "2017-09-29 02:24:38.592577: step 7600, loss = 4471.18 (37.8 examples/sec; 3.383 sec/batch)\n",
      "2017-09-29 02:25:12.121542: step 7610, loss = 4435.96 (38.2 examples/sec; 3.353 sec/batch)\n",
      "2017-09-29 02:25:45.570650: step 7620, loss = 4401.47 (38.3 examples/sec; 3.345 sec/batch)\n",
      "2017-09-29 02:26:19.138449: step 7630, loss = 4366.22 (38.1 examples/sec; 3.357 sec/batch)\n",
      "2017-09-29 02:26:52.949948: step 7640, loss = 4331.57 (37.9 examples/sec; 3.381 sec/batch)\n",
      "2017-09-29 02:27:26.508598: step 7650, loss = 4296.14 (38.1 examples/sec; 3.356 sec/batch)\n",
      "2017-09-29 02:27:59.865337: step 7660, loss = 4262.76 (38.4 examples/sec; 3.336 sec/batch)\n",
      "2017-09-29 02:28:33.407432: step 7670, loss = 4227.90 (38.2 examples/sec; 3.354 sec/batch)\n",
      "2017-09-29 02:29:07.097261: step 7680, loss = 4194.94 (38.0 examples/sec; 3.369 sec/batch)\n",
      "2017-09-29 02:29:40.580110: step 7690, loss = 4162.91 (38.2 examples/sec; 3.348 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.297642\n",
      "2017-09-29 02:30:14.567889: step 7700, loss = 4128.75 (37.7 examples/sec; 3.399 sec/batch)\n",
      "2017-09-29 02:30:47.963447: step 7710, loss = 4096.87 (38.3 examples/sec; 3.340 sec/batch)\n",
      "2017-09-29 02:31:21.513418: step 7720, loss = 4063.24 (38.2 examples/sec; 3.355 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 7729 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-29 02:31:59.230121: step 7730, loss = 4030.64 (33.9 examples/sec; 3.772 sec/batch)\n",
      "2017-09-29 02:32:32.835311: step 7740, loss = 3999.68 (38.1 examples/sec; 3.361 sec/batch)\n",
      "2017-09-29 02:33:06.449222: step 7750, loss = 3966.83 (38.1 examples/sec; 3.361 sec/batch)\n",
      "2017-09-29 02:33:39.824552: step 7760, loss = 3935.83 (38.4 examples/sec; 3.338 sec/batch)\n",
      "2017-09-29 02:34:13.555439: step 7770, loss = 3903.52 (37.9 examples/sec; 3.373 sec/batch)\n",
      "2017-09-29 02:34:47.026455: step 7780, loss = 3873.23 (38.2 examples/sec; 3.347 sec/batch)\n",
      "2017-09-29 02:35:20.483424: step 7790, loss = 3841.43 (38.3 examples/sec; 3.346 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.294368\n",
      "2017-09-29 02:35:54.278384: step 7800, loss = 3811.47 (37.9 examples/sec; 3.379 sec/batch)\n",
      "2017-09-29 02:36:28.001097: step 7810, loss = 3781.51 (38.0 examples/sec; 3.372 sec/batch)\n",
      "2017-09-29 02:37:01.705539: step 7820, loss = 3750.45 (38.0 examples/sec; 3.370 sec/batch)\n",
      "2017-09-29 02:37:35.333871: step 7830, loss = 3721.23 (38.1 examples/sec; 3.363 sec/batch)\n",
      "2017-09-29 02:38:08.928468: step 7840, loss = 3690.67 (38.1 examples/sec; 3.359 sec/batch)\n",
      "2017-09-29 02:38:42.578455: step 7850, loss = 3662.05 (38.0 examples/sec; 3.365 sec/batch)\n",
      "2017-09-29 02:39:16.179615: step 7860, loss = 3632.66 (38.1 examples/sec; 3.360 sec/batch)\n",
      "2017-09-29 02:39:49.797965: step 7870, loss = 3602.86 (38.1 examples/sec; 3.362 sec/batch)\n",
      "2017-09-29 02:40:23.411722: step 7880, loss = 3575.46 (38.1 examples/sec; 3.361 sec/batch)\n",
      "2017-09-29 02:40:56.830059: step 7890, loss = 3546.04 (38.3 examples/sec; 3.342 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.2971\n",
      "2017-09-29 02:41:30.865084: step 7900, loss = 3518.42 (37.6 examples/sec; 3.404 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 7907 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-29 02:42:08.290291: step 7910, loss = 3489.80 (34.2 examples/sec; 3.743 sec/batch)\n",
      "2017-09-29 02:42:41.738967: step 7920, loss = 3462.23 (38.3 examples/sec; 3.345 sec/batch)\n",
      "2017-09-29 02:43:15.376801: step 7930, loss = 3434.79 (38.1 examples/sec; 3.364 sec/batch)\n",
      "2017-09-29 02:43:48.656392: step 7940, loss = 3406.57 (38.5 examples/sec; 3.328 sec/batch)\n",
      "2017-09-29 02:44:22.008567: step 7950, loss = 3380.80 (38.4 examples/sec; 3.335 sec/batch)\n",
      "2017-09-29 02:44:55.551331: step 7960, loss = 3352.94 (38.2 examples/sec; 3.354 sec/batch)\n",
      "2017-09-29 02:45:29.258535: step 7970, loss = 3327.01 (38.0 examples/sec; 3.371 sec/batch)\n",
      "2017-09-29 02:46:02.694678: step 7980, loss = 3301.09 (38.3 examples/sec; 3.344 sec/batch)\n",
      "2017-09-29 02:46:36.268751: step 7990, loss = 3273.84 (38.1 examples/sec; 3.357 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.294429\n",
      "2017-09-29 02:47:10.504724: step 8000, loss = 3248.31 (37.4 examples/sec; 3.424 sec/batch)\n",
      "2017-09-29 02:47:44.150516: step 8010, loss = 3221.51 (38.0 examples/sec; 3.365 sec/batch)\n",
      "2017-09-29 02:48:17.493533: step 8020, loss = 3196.34 (38.4 examples/sec; 3.334 sec/batch)\n",
      "2017-09-29 02:48:50.944610: step 8030, loss = 3171.09 (38.3 examples/sec; 3.345 sec/batch)\n",
      "2017-09-29 02:49:24.624267: step 8040, loss = 3145.58 (38.0 examples/sec; 3.368 sec/batch)\n",
      "2017-09-29 02:49:58.282205: step 8050, loss = 3121.69 (38.0 examples/sec; 3.366 sec/batch)\n",
      "2017-09-29 02:50:31.759363: step 8060, loss = 3095.85 (38.2 examples/sec; 3.348 sec/batch)\n",
      "2017-09-29 02:51:05.447710: step 8070, loss = 3071.75 (38.0 examples/sec; 3.369 sec/batch)\n",
      "2017-09-29 02:51:38.964534: step 8080, loss = 3046.34 (38.2 examples/sec; 3.352 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 8085 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-29 02:52:15.946426: step 8090, loss = 3022.78 (34.6 examples/sec; 3.698 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.294865\n",
      "2017-09-29 02:52:49.645900: step 8100, loss = 2999.28 (38.0 examples/sec; 3.370 sec/batch)\n",
      "2017-09-29 02:53:23.286758: step 8110, loss = 2974.43 (38.0 examples/sec; 3.364 sec/batch)\n",
      "2017-09-29 02:53:56.827177: step 8120, loss = 2951.16 (38.2 examples/sec; 3.354 sec/batch)\n",
      "2017-09-29 02:54:30.489201: step 8130, loss = 2926.75 (38.0 examples/sec; 3.366 sec/batch)\n",
      "2017-09-29 02:55:04.056630: step 8140, loss = 2904.47 (38.1 examples/sec; 3.357 sec/batch)\n",
      "2017-09-29 02:55:37.526004: step 8150, loss = 2882.23 (38.2 examples/sec; 3.347 sec/batch)\n",
      "2017-09-29 02:56:11.142038: step 8160, loss = 2858.28 (38.1 examples/sec; 3.362 sec/batch)\n",
      "2017-09-29 02:56:44.886520: step 8170, loss = 2836.01 (37.9 examples/sec; 3.374 sec/batch)\n",
      "2017-09-29 02:57:18.453803: step 8180, loss = 2812.47 (38.1 examples/sec; 3.357 sec/batch)\n",
      "2017-09-29 02:57:52.810454: step 8190, loss = 2791.05 (37.3 examples/sec; 3.436 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.294721\n",
      "2017-09-29 02:58:28.948247: step 8200, loss = 2767.87 (35.4 examples/sec; 3.614 sec/batch)\n",
      "2017-09-29 02:59:00.840988: step 8210, loss = 2744.90 (40.1 examples/sec; 3.189 sec/batch)\n",
      "2017-09-29 02:59:34.297429: step 8220, loss = 2724.40 (38.3 examples/sec; 3.346 sec/batch)\n",
      "2017-09-29 03:00:08.232763: step 8230, loss = 2701.76 (37.7 examples/sec; 3.394 sec/batch)\n",
      "2017-09-29 03:00:41.790329: step 8240, loss = 2681.37 (38.1 examples/sec; 3.356 sec/batch)\n",
      "2017-09-29 03:01:15.362602: step 8250, loss = 2659.08 (38.1 examples/sec; 3.357 sec/batch)\n",
      "2017-09-29 03:01:48.829975: step 8260, loss = 2638.37 (38.2 examples/sec; 3.347 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 8263 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-29 03:02:26.290336: step 8270, loss = 2617.74 (34.2 examples/sec; 3.746 sec/batch)\n",
      "2017-09-29 03:03:00.006762: step 8280, loss = 2595.98 (38.0 examples/sec; 3.372 sec/batch)\n",
      "2017-09-29 03:03:31.060880: step 8290, loss = 2576.32 (41.2 examples/sec; 3.105 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.298058\n",
      "2017-09-29 03:04:04.461020: step 8300, loss = 2554.85 (38.3 examples/sec; 3.340 sec/batch)\n",
      "2017-09-29 03:04:37.964246: step 8310, loss = 2532.28 (38.2 examples/sec; 3.350 sec/batch)\n",
      "2017-09-29 03:05:11.671229: step 8320, loss = 2513.25 (38.0 examples/sec; 3.371 sec/batch)\n",
      "2017-09-29 03:05:45.482305: step 8330, loss = 2492.07 (37.9 examples/sec; 3.381 sec/batch)\n",
      "2017-09-29 03:06:19.082875: step 8340, loss = 2475.52 (38.1 examples/sec; 3.360 sec/batch)\n",
      "2017-09-29 03:06:53.000576: step 8350, loss = 2454.87 (37.7 examples/sec; 3.392 sec/batch)\n",
      "2017-09-29 03:07:26.577160: step 8360, loss = 2436.27 (38.1 examples/sec; 3.358 sec/batch)\n",
      "2017-09-29 03:08:00.328824: step 8370, loss = 2415.93 (37.9 examples/sec; 3.375 sec/batch)\n",
      "2017-09-29 03:08:33.814259: step 8380, loss = 2396.92 (38.2 examples/sec; 3.349 sec/batch)\n",
      "2017-09-29 03:09:07.354655: step 8390, loss = 2379.20 (38.2 examples/sec; 3.354 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.296989\n",
      "2017-09-29 03:09:41.165070: step 8400, loss = 2359.26 (37.9 examples/sec; 3.381 sec/batch)\n",
      "2017-09-29 03:10:14.862367: step 8410, loss = 2340.67 (38.0 examples/sec; 3.370 sec/batch)\n",
      "2017-09-29 03:10:48.274883: step 8420, loss = 2321.11 (38.3 examples/sec; 3.341 sec/batch)\n",
      "2017-09-29 03:11:21.917438: step 8430, loss = 2303.63 (38.0 examples/sec; 3.364 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 8441 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-29 03:11:59.409851: step 8440, loss = 2285.28 (34.1 examples/sec; 3.749 sec/batch)\n",
      "2017-09-29 03:12:32.910916: step 8450, loss = 2266.89 (38.2 examples/sec; 3.350 sec/batch)\n",
      "2017-09-29 03:13:01.942571: step 8460, loss = 2249.40 (44.1 examples/sec; 2.903 sec/batch)\n",
      "2017-09-29 03:13:30.964910: step 8470, loss = 2230.53 (44.1 examples/sec; 2.902 sec/batch)\n",
      "2017-09-29 03:14:00.056828: step 8480, loss = 2213.75 (44.0 examples/sec; 2.909 sec/batch)\n",
      "2017-09-29 03:14:29.045258: step 8490, loss = 2195.17 (44.2 examples/sec; 2.899 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.314995\n",
      "2017-09-29 03:14:58.624970: step 8500, loss = 2178.24 (43.3 examples/sec; 2.958 sec/batch)\n",
      "2017-09-29 03:15:27.677938: step 8510, loss = 2161.55 (44.1 examples/sec; 2.905 sec/batch)\n",
      "2017-09-29 03:15:56.685350: step 8520, loss = 2143.38 (44.1 examples/sec; 2.901 sec/batch)\n",
      "2017-09-29 03:16:25.686105: step 8530, loss = 2127.22 (44.1 examples/sec; 2.900 sec/batch)\n",
      "2017-09-29 03:16:56.767817: step 8540, loss = 2109.32 (41.2 examples/sec; 3.108 sec/batch)\n",
      "2017-09-29 03:17:30.135482: step 8550, loss = 2092.15 (38.4 examples/sec; 3.337 sec/batch)\n",
      "2017-09-29 03:18:03.980479: step 8560, loss = 2076.04 (37.8 examples/sec; 3.384 sec/batch)\n",
      "2017-09-29 03:18:37.491192: step 8570, loss = 2058.69 (38.2 examples/sec; 3.351 sec/batch)\n",
      "2017-09-29 03:19:11.110236: step 8580, loss = 2043.60 (38.1 examples/sec; 3.362 sec/batch)\n",
      "2017-09-29 03:19:44.567694: step 8590, loss = 2026.37 (38.3 examples/sec; 3.346 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.312578\n",
      "2017-09-29 03:20:18.554257: step 8600, loss = 2010.21 (37.7 examples/sec; 3.399 sec/batch)\n",
      "2017-09-29 03:20:52.086983: step 8610, loss = 1992.74 (38.2 examples/sec; 3.353 sec/batch)\n",
      "2017-09-29 03:21:25.674856: step 8620, loss = 1975.99 (38.1 examples/sec; 3.359 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 8630 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-29 03:22:03.332062: step 8630, loss = 1962.42 (34.0 examples/sec; 3.766 sec/batch)\n",
      "2017-09-29 03:22:36.905584: step 8640, loss = 1944.62 (38.1 examples/sec; 3.357 sec/batch)\n",
      "2017-09-29 03:23:10.521189: step 8650, loss = 1929.16 (38.1 examples/sec; 3.362 sec/batch)\n",
      "2017-09-29 03:23:44.398291: step 8660, loss = 1913.74 (37.8 examples/sec; 3.388 sec/batch)\n",
      "2017-09-29 03:24:18.057744: step 8670, loss = 1898.51 (38.0 examples/sec; 3.366 sec/batch)\n",
      "2017-09-29 03:24:51.553523: step 8680, loss = 1887.61 (38.2 examples/sec; 3.350 sec/batch)\n",
      "2017-09-29 03:25:25.385360: step 8690, loss = 1868.36 (37.8 examples/sec; 3.383 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.293379\n",
      "2017-09-29 03:25:59.416165: step 8700, loss = 1854.02 (37.6 examples/sec; 3.403 sec/batch)\n",
      "2017-09-29 03:26:33.131021: step 8710, loss = 1838.69 (38.0 examples/sec; 3.371 sec/batch)\n",
      "2017-09-29 03:27:06.964008: step 8720, loss = 1824.05 (37.8 examples/sec; 3.383 sec/batch)\n",
      "2017-09-29 03:27:40.439005: step 8730, loss = 1810.21 (38.2 examples/sec; 3.347 sec/batch)\n",
      "2017-09-29 03:28:14.179664: step 8740, loss = 1795.08 (37.9 examples/sec; 3.374 sec/batch)\n",
      "2017-09-29 03:28:47.716525: step 8750, loss = 1781.43 (38.2 examples/sec; 3.354 sec/batch)\n",
      "2017-09-29 03:29:21.184543: step 8760, loss = 1766.58 (38.2 examples/sec; 3.347 sec/batch)\n",
      "2017-09-29 03:29:54.953815: step 8770, loss = 1752.53 (37.9 examples/sec; 3.377 sec/batch)\n",
      "2017-09-29 03:30:28.519529: step 8780, loss = 1738.53 (38.1 examples/sec; 3.357 sec/batch)\n",
      "2017-09-29 03:31:02.119921: step 8790, loss = 1724.69 (38.1 examples/sec; 3.360 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.296834\n",
      "2017-09-29 03:31:36.304562: step 8800, loss = 1713.47 (37.4 examples/sec; 3.418 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 8807 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-29 03:32:13.539638: step 8810, loss = 1697.31 (34.4 examples/sec; 3.724 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-09-29 03:32:47.069927: step 8820, loss = 1684.21 (38.2 examples/sec; 3.353 sec/batch)\n",
      "2017-09-29 03:33:20.670906: step 8830, loss = 1670.35 (38.1 examples/sec; 3.360 sec/batch)\n",
      "2017-09-29 03:33:54.289309: step 8840, loss = 1657.07 (38.1 examples/sec; 3.362 sec/batch)\n",
      "2017-09-29 03:34:27.950383: step 8850, loss = 1648.84 (38.0 examples/sec; 3.366 sec/batch)\n",
      "2017-09-29 03:35:01.553514: step 8860, loss = 1630.74 (38.1 examples/sec; 3.360 sec/batch)\n",
      "2017-09-29 03:35:35.452048: step 8870, loss = 1617.85 (37.8 examples/sec; 3.390 sec/batch)\n",
      "2017-09-29 03:36:09.031849: step 8880, loss = 1604.84 (38.1 examples/sec; 3.358 sec/batch)\n",
      "2017-09-29 03:36:42.424806: step 8890, loss = 1592.08 (38.3 examples/sec; 3.339 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.293921\n",
      "2017-09-29 03:37:16.530177: step 8900, loss = 1579.37 (37.5 examples/sec; 3.411 sec/batch)\n",
      "2017-09-29 03:37:50.081467: step 8910, loss = 1566.79 (38.2 examples/sec; 3.355 sec/batch)\n",
      "2017-09-29 03:38:23.759217: step 8920, loss = 1556.65 (38.0 examples/sec; 3.368 sec/batch)\n",
      "2017-09-29 03:38:57.490046: step 8930, loss = 1541.91 (37.9 examples/sec; 3.373 sec/batch)\n",
      "2017-09-29 03:39:31.166008: step 8940, loss = 1529.69 (38.0 examples/sec; 3.368 sec/batch)\n",
      "2017-09-29 03:40:04.773194: step 8950, loss = 1517.43 (38.1 examples/sec; 3.361 sec/batch)\n",
      "2017-09-29 03:40:38.381016: step 8960, loss = 1505.35 (38.1 examples/sec; 3.361 sec/batch)\n",
      "2017-09-29 03:41:12.209764: step 8970, loss = 1501.47 (37.8 examples/sec; 3.383 sec/batch)\n",
      "2017-09-29 03:41:43.815884: step 8980, loss = 1481.44 (40.5 examples/sec; 3.161 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 8985 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-29 03:42:21.232242: step 8990, loss = 1470.66 (34.2 examples/sec; 3.742 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.295262\n",
      "2017-09-29 03:42:55.213281: step 9000, loss = 1457.92 (37.7 examples/sec; 3.398 sec/batch)\n",
      "2017-09-29 03:43:28.868919: step 9010, loss = 1446.33 (38.0 examples/sec; 3.366 sec/batch)\n",
      "2017-09-29 03:44:02.381154: step 9020, loss = 1434.77 (38.2 examples/sec; 3.351 sec/batch)\n",
      "2017-09-29 03:44:35.836002: step 9030, loss = 1423.37 (38.3 examples/sec; 3.345 sec/batch)\n",
      "2017-09-29 03:45:09.472775: step 9040, loss = 1414.60 (38.1 examples/sec; 3.364 sec/batch)\n",
      "2017-09-29 03:45:42.970044: step 9050, loss = 1400.74 (38.2 examples/sec; 3.350 sec/batch)\n",
      "2017-09-29 03:46:16.555387: step 9060, loss = 1389.62 (38.1 examples/sec; 3.359 sec/batch)\n",
      "2017-09-29 03:46:49.902854: step 9070, loss = 1378.50 (38.4 examples/sec; 3.335 sec/batch)\n",
      "2017-09-29 03:47:23.877218: step 9080, loss = 1367.53 (37.7 examples/sec; 3.397 sec/batch)\n",
      "2017-09-29 03:47:57.571214: step 9090, loss = 1362.01 (38.0 examples/sec; 3.369 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.297192\n",
      "2017-09-29 03:48:31.696571: step 9100, loss = 1345.81 (37.5 examples/sec; 3.413 sec/batch)\n",
      "2017-09-29 03:49:05.568097: step 9110, loss = 1335.32 (37.8 examples/sec; 3.387 sec/batch)\n",
      "2017-09-29 03:49:39.121160: step 9120, loss = 1324.44 (38.1 examples/sec; 3.355 sec/batch)\n",
      "2017-09-29 03:50:12.780153: step 9130, loss = 1313.92 (38.0 examples/sec; 3.366 sec/batch)\n",
      "2017-09-29 03:50:46.437360: step 9140, loss = 1303.62 (38.0 examples/sec; 3.366 sec/batch)\n",
      "2017-09-29 03:51:19.953864: step 9150, loss = 1293.04 (38.2 examples/sec; 3.352 sec/batch)\n",
      "2017-09-29 03:51:53.490386: step 9160, loss = 1284.52 (38.2 examples/sec; 3.354 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 9163 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-29 03:52:30.540163: step 9170, loss = 1272.50 (34.5 examples/sec; 3.705 sec/batch)\n",
      "2017-09-29 03:53:04.080374: step 9180, loss = 1262.75 (38.2 examples/sec; 3.354 sec/batch)\n",
      "2017-09-29 03:53:37.822074: step 9190, loss = 1252.31 (37.9 examples/sec; 3.374 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.293945\n",
      "2017-09-29 03:54:11.896946: step 9200, loss = 1242.35 (37.6 examples/sec; 3.407 sec/batch)\n",
      "2017-09-29 03:54:45.536026: step 9210, loss = 1235.10 (38.1 examples/sec; 3.364 sec/batch)\n",
      "2017-09-29 03:55:19.211847: step 9220, loss = 1222.62 (38.0 examples/sec; 3.368 sec/batch)\n",
      "2017-09-29 03:55:52.797617: step 9230, loss = 1213.07 (38.1 examples/sec; 3.359 sec/batch)\n",
      "2017-09-29 03:56:26.377596: step 9240, loss = 1203.19 (38.1 examples/sec; 3.358 sec/batch)\n",
      "2017-09-29 03:56:59.920045: step 9250, loss = 1193.62 (38.2 examples/sec; 3.354 sec/batch)\n",
      "2017-09-29 03:57:33.610428: step 9260, loss = 1188.09 (38.0 examples/sec; 3.369 sec/batch)\n",
      "2017-09-29 03:58:07.428780: step 9270, loss = 1174.67 (37.8 examples/sec; 3.382 sec/batch)\n",
      "2017-09-29 03:58:41.112836: step 9280, loss = 1167.89 (38.0 examples/sec; 3.368 sec/batch)\n",
      "2017-09-29 03:59:14.860939: step 9290, loss = 1156.02 (37.9 examples/sec; 3.375 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.296837\n",
      "2017-09-29 03:59:48.784557: step 9300, loss = 1147.99 (37.7 examples/sec; 3.392 sec/batch)\n",
      "2017-09-29 04:00:22.315148: step 9310, loss = 1137.66 (38.2 examples/sec; 3.353 sec/batch)\n",
      "2017-09-29 04:00:55.943718: step 9320, loss = 1128.60 (38.1 examples/sec; 3.363 sec/batch)\n",
      "2017-09-29 04:01:29.450719: step 9330, loss = 1122.83 (38.2 examples/sec; 3.351 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 9341 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-29 04:02:07.265876: step 9340, loss = 1110.67 (33.8 examples/sec; 3.782 sec/batch)\n",
      "2017-09-29 04:02:40.927060: step 9350, loss = 1101.95 (38.0 examples/sec; 3.366 sec/batch)\n",
      "2017-09-29 04:03:14.586016: step 9360, loss = 1093.03 (38.0 examples/sec; 3.366 sec/batch)\n",
      "2017-09-29 04:03:48.116981: step 9370, loss = 1084.34 (38.2 examples/sec; 3.353 sec/batch)\n",
      "2017-09-29 04:04:21.516929: step 9380, loss = 1082.75 (38.3 examples/sec; 3.340 sec/batch)\n",
      "2017-09-29 04:04:55.196808: step 9390, loss = 1067.12 (38.0 examples/sec; 3.368 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.294071\n",
      "2017-09-29 04:05:28.836889: step 9400, loss = 1059.51 (38.0 examples/sec; 3.364 sec/batch)\n",
      "2017-09-29 04:06:02.533079: step 9410, loss = 1050.17 (38.0 examples/sec; 3.370 sec/batch)\n",
      "2017-09-29 04:06:35.962914: step 9420, loss = 1041.87 (38.3 examples/sec; 3.343 sec/batch)\n",
      "2017-09-29 04:07:09.636219: step 9430, loss = 1033.50 (38.0 examples/sec; 3.367 sec/batch)\n",
      "2017-09-29 04:07:43.304934: step 9440, loss = 1027.17 (38.0 examples/sec; 3.367 sec/batch)\n",
      "2017-09-29 04:08:16.900082: step 9450, loss = 1019.50 (38.1 examples/sec; 3.360 sec/batch)\n",
      "2017-09-29 04:08:50.519474: step 9460, loss = 1010.57 (38.1 examples/sec; 3.362 sec/batch)\n",
      "2017-09-29 04:09:23.958896: step 9470, loss = 1004.32 (38.3 examples/sec; 3.344 sec/batch)\n",
      "2017-09-29 04:09:57.563656: step 9480, loss = 995.35 (38.1 examples/sec; 3.360 sec/batch)\n",
      "2017-09-29 04:10:30.975481: step 9490, loss = 988.04 (38.3 examples/sec; 3.341 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.297336\n",
      "2017-09-29 04:11:05.148334: step 9500, loss = 979.96 (37.5 examples/sec; 3.417 sec/batch)\n",
      "2017-09-29 04:11:38.668184: step 9510, loss = 971.29 (38.2 examples/sec; 3.352 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 9519 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-29 04:12:14.238160: step 9520, loss = 965.32 (36.0 examples/sec; 3.557 sec/batch)\n",
      "2017-09-29 04:12:43.096241: step 9530, loss = 956.66 (44.4 examples/sec; 2.886 sec/batch)\n",
      "2017-09-29 04:13:12.154902: step 9540, loss = 949.38 (44.0 examples/sec; 2.906 sec/batch)\n",
      "2017-09-29 04:13:41.151627: step 9550, loss = 940.92 (44.1 examples/sec; 2.900 sec/batch)\n",
      "2017-09-29 04:14:13.009512: step 9560, loss = 933.80 (40.2 examples/sec; 3.186 sec/batch)\n",
      "2017-09-29 04:14:46.695470: step 9570, loss = 926.52 (38.0 examples/sec; 3.369 sec/batch)\n",
      "2017-09-29 04:15:20.142082: step 9580, loss = 918.32 (38.3 examples/sec; 3.345 sec/batch)\n",
      "2017-09-29 04:15:53.737453: step 9590, loss = 911.34 (38.1 examples/sec; 3.360 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.310015\n",
      "2017-09-29 04:16:27.713206: step 9600, loss = 903.37 (37.7 examples/sec; 3.398 sec/batch)\n",
      "2017-09-29 04:17:01.329356: step 9610, loss = 896.59 (38.1 examples/sec; 3.362 sec/batch)\n",
      "2017-09-29 04:17:35.097911: step 9620, loss = 891.61 (37.9 examples/sec; 3.377 sec/batch)\n",
      "2017-09-29 04:18:08.816010: step 9630, loss = 883.47 (38.0 examples/sec; 3.372 sec/batch)\n",
      "2017-09-29 04:18:41.921447: step 9640, loss = 876.18 (38.7 examples/sec; 3.311 sec/batch)\n",
      "2017-09-29 04:19:15.561457: step 9650, loss = 868.36 (38.0 examples/sec; 3.364 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-09-29 04:19:49.165540: step 9660, loss = 862.53 (38.1 examples/sec; 3.360 sec/batch)\n",
      "2017-09-29 04:20:22.930960: step 9670, loss = 855.55 (37.9 examples/sec; 3.377 sec/batch)\n",
      "2017-09-29 04:20:56.381812: step 9680, loss = 849.16 (38.3 examples/sec; 3.345 sec/batch)\n",
      "2017-09-29 04:21:29.836797: step 9690, loss = 843.18 (38.3 examples/sec; 3.345 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.297572\n",
      "INFO:tensorflow:Saving checkpoints for 9702 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-29 04:22:07.550307: step 9700, loss = 835.48 (33.9 examples/sec; 3.771 sec/batch)\n",
      "2017-09-29 04:22:40.954016: step 9710, loss = 829.43 (38.3 examples/sec; 3.340 sec/batch)\n",
      "2017-09-29 04:23:14.645740: step 9720, loss = 821.88 (38.0 examples/sec; 3.369 sec/batch)\n",
      "2017-09-29 04:23:48.152212: step 9730, loss = 816.16 (38.2 examples/sec; 3.351 sec/batch)\n",
      "2017-09-29 04:24:21.695305: step 9740, loss = 809.68 (38.2 examples/sec; 3.354 sec/batch)\n",
      "2017-09-29 04:24:55.207117: step 9750, loss = 802.32 (38.2 examples/sec; 3.351 sec/batch)\n",
      "2017-09-29 04:25:28.669833: step 9760, loss = 797.55 (38.3 examples/sec; 3.346 sec/batch)\n",
      "2017-09-29 04:26:02.280446: step 9770, loss = 790.22 (38.1 examples/sec; 3.361 sec/batch)\n",
      "2017-09-29 04:26:35.656443: step 9780, loss = 784.32 (38.4 examples/sec; 3.338 sec/batch)\n",
      "2017-09-29 04:27:09.080945: step 9790, loss = 778.05 (38.3 examples/sec; 3.342 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.294711\n",
      "2017-09-29 04:27:43.080489: step 9800, loss = 771.22 (37.6 examples/sec; 3.400 sec/batch)\n",
      "2017-09-29 04:28:16.675441: step 9810, loss = 766.52 (38.1 examples/sec; 3.359 sec/batch)\n",
      "2017-09-29 04:28:50.252818: step 9820, loss = 756.68 (38.1 examples/sec; 3.358 sec/batch)\n",
      "2017-09-29 04:29:24.076923: step 9830, loss = 750.48 (37.8 examples/sec; 3.382 sec/batch)\n",
      "2017-09-29 04:29:57.111125: step 9840, loss = 744.45 (38.7 examples/sec; 3.303 sec/batch)\n",
      "2017-09-29 04:30:30.459232: step 9850, loss = 738.53 (38.4 examples/sec; 3.335 sec/batch)\n",
      "2017-09-29 04:31:04.129575: step 9860, loss = 734.40 (38.0 examples/sec; 3.367 sec/batch)\n",
      "2017-09-29 04:31:37.829017: step 9870, loss = 726.79 (38.0 examples/sec; 3.370 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 9880 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-29 04:32:15.630995: step 9880, loss = 721.11 (33.9 examples/sec; 3.780 sec/batch)\n",
      "2017-09-29 04:32:49.338525: step 9890, loss = 715.25 (38.0 examples/sec; 3.371 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.293902\n",
      "2017-09-29 04:33:23.336079: step 9900, loss = 709.58 (37.6 examples/sec; 3.400 sec/batch)\n",
      "2017-09-29 04:33:57.133263: step 9910, loss = 711.09 (37.9 examples/sec; 3.380 sec/batch)\n",
      "2017-09-29 04:34:30.899688: step 9920, loss = 698.31 (37.9 examples/sec; 3.377 sec/batch)\n",
      "2017-09-29 04:35:04.637036: step 9930, loss = 694.59 (37.9 examples/sec; 3.374 sec/batch)\n",
      "2017-09-29 04:35:38.341046: step 9940, loss = 687.22 (38.0 examples/sec; 3.370 sec/batch)\n",
      "2017-09-29 04:36:12.099103: step 9950, loss = 681.76 (37.9 examples/sec; 3.376 sec/batch)\n",
      "2017-09-29 04:36:45.857349: step 9960, loss = 676.29 (37.9 examples/sec; 3.376 sec/batch)\n",
      "2017-09-29 04:37:19.470438: step 9970, loss = 670.95 (38.1 examples/sec; 3.361 sec/batch)\n",
      "2017-09-29 04:37:53.188832: step 9980, loss = 667.18 (38.0 examples/sec; 3.372 sec/batch)\n",
      "2017-09-29 04:38:27.058974: step 9990, loss = 660.28 (37.8 examples/sec; 3.387 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.296005\n",
      "2017-09-29 04:39:01.171908: step 10000, loss = 655.16 (37.5 examples/sec; 3.411 sec/batch)\n",
      "2017-09-29 04:39:34.558798: step 10010, loss = 649.77 (38.3 examples/sec; 3.339 sec/batch)\n",
      "2017-09-29 04:40:08.178208: step 10020, loss = 644.62 (38.1 examples/sec; 3.362 sec/batch)\n",
      "2017-09-29 04:40:41.847450: step 10030, loss = 643.04 (38.0 examples/sec; 3.367 sec/batch)\n",
      "2017-09-29 04:41:15.697663: step 10040, loss = 634.37 (37.8 examples/sec; 3.385 sec/batch)\n",
      "2017-09-29 04:41:49.462510: step 10050, loss = 629.94 (37.9 examples/sec; 3.376 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 10057 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-29 04:42:26.715494: step 10060, loss = 624.30 (34.4 examples/sec; 3.725 sec/batch)\n",
      "2017-09-29 04:43:00.259348: step 10070, loss = 619.34 (38.2 examples/sec; 3.354 sec/batch)\n",
      "2017-09-29 04:43:33.804280: step 10080, loss = 616.92 (38.2 examples/sec; 3.354 sec/batch)\n",
      "2017-09-29 04:44:07.386721: step 10090, loss = 609.51 (38.1 examples/sec; 3.358 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.293755\n",
      "2017-09-29 04:44:41.592012: step 10100, loss = 606.10 (37.4 examples/sec; 3.421 sec/batch)\n",
      "2017-09-29 04:45:15.201838: step 10110, loss = 599.82 (38.1 examples/sec; 3.361 sec/batch)\n",
      "2017-09-29 04:45:48.807925: step 10120, loss = 595.17 (38.1 examples/sec; 3.361 sec/batch)\n",
      "2017-09-29 04:46:22.100535: step 10130, loss = 590.29 (38.4 examples/sec; 3.329 sec/batch)\n",
      "2017-09-29 04:46:55.858011: step 10140, loss = 585.62 (37.9 examples/sec; 3.376 sec/batch)\n",
      "2017-09-29 04:47:29.508699: step 10150, loss = 584.35 (38.0 examples/sec; 3.365 sec/batch)\n",
      "2017-09-29 04:48:03.333991: step 10160, loss = 576.30 (37.8 examples/sec; 3.383 sec/batch)\n",
      "2017-09-29 04:48:36.926955: step 10170, loss = 572.29 (38.1 examples/sec; 3.359 sec/batch)\n",
      "2017-09-29 04:49:10.549261: step 10180, loss = 567.14 (38.1 examples/sec; 3.362 sec/batch)\n",
      "2017-09-29 04:49:44.350212: step 10190, loss = 562.79 (37.9 examples/sec; 3.380 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.296935\n",
      "2017-09-29 04:50:18.366273: step 10200, loss = 563.98 (37.6 examples/sec; 3.402 sec/batch)\n",
      "2017-09-29 04:50:52.074786: step 10210, loss = 553.71 (38.0 examples/sec; 3.371 sec/batch)\n",
      "2017-09-29 04:51:25.743138: step 10220, loss = 550.85 (38.0 examples/sec; 3.367 sec/batch)\n",
      "2017-09-29 04:51:59.186719: step 10230, loss = 544.91 (38.3 examples/sec; 3.344 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 10235 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-29 04:52:37.074409: step 10240, loss = 540.83 (33.8 examples/sec; 3.789 sec/batch)\n",
      "2017-09-29 04:53:10.647183: step 10250, loss = 536.25 (38.1 examples/sec; 3.357 sec/batch)\n",
      "2017-09-29 04:53:44.447902: step 10260, loss = 532.02 (37.9 examples/sec; 3.380 sec/batch)\n",
      "2017-09-29 04:54:17.929980: step 10270, loss = 528.36 (38.2 examples/sec; 3.348 sec/batch)\n",
      "2017-09-29 04:54:51.533382: step 10280, loss = 523.53 (38.1 examples/sec; 3.360 sec/batch)\n",
      "2017-09-29 04:55:25.423040: step 10290, loss = 519.77 (37.8 examples/sec; 3.389 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.293113\n",
      "2017-09-29 04:55:59.529433: step 10300, loss = 515.23 (37.5 examples/sec; 3.411 sec/batch)\n",
      "2017-09-29 04:56:33.164619: step 10310, loss = 511.19 (38.1 examples/sec; 3.364 sec/batch)\n",
      "2017-09-29 04:57:06.837740: step 10320, loss = 514.04 (38.0 examples/sec; 3.367 sec/batch)\n",
      "2017-09-29 04:57:39.711301: step 10330, loss = 503.03 (38.9 examples/sec; 3.287 sec/batch)\n",
      "2017-09-29 04:58:14.009660: step 10340, loss = 500.13 (37.3 examples/sec; 3.430 sec/batch)\n",
      "2017-09-29 04:58:48.048520: step 10350, loss = 495.02 (37.6 examples/sec; 3.404 sec/batch)\n",
      "2017-09-29 04:59:21.464924: step 10360, loss = 491.35 (38.3 examples/sec; 3.342 sec/batch)\n",
      "2017-09-29 04:59:55.340349: step 10370, loss = 487.16 (37.8 examples/sec; 3.388 sec/batch)\n",
      "2017-09-29 05:00:28.755340: step 10380, loss = 483.32 (38.3 examples/sec; 3.341 sec/batch)\n",
      "2017-09-29 05:01:02.252148: step 10390, loss = 481.80 (38.2 examples/sec; 3.350 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.296913\n",
      "2017-09-29 05:01:36.329239: step 10400, loss = 475.64 (37.6 examples/sec; 3.408 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 10412 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-29 05:02:13.882335: step 10410, loss = 472.24 (34.1 examples/sec; 3.755 sec/batch)\n",
      "2017-09-29 05:02:47.771782: step 10420, loss = 468.06 (37.8 examples/sec; 3.389 sec/batch)\n",
      "2017-09-29 05:03:21.410422: step 10430, loss = 464.39 (38.1 examples/sec; 3.364 sec/batch)\n",
      "2017-09-29 05:03:54.975539: step 10440, loss = 465.47 (38.1 examples/sec; 3.357 sec/batch)\n",
      "2017-09-29 05:04:28.534191: step 10450, loss = 456.98 (38.1 examples/sec; 3.356 sec/batch)\n",
      "2017-09-29 05:05:02.381937: step 10460, loss = 454.49 (37.8 examples/sec; 3.385 sec/batch)\n",
      "2017-09-29 05:05:35.811220: step 10470, loss = 449.71 (38.3 examples/sec; 3.343 sec/batch)\n",
      "2017-09-29 05:06:09.512120: step 10480, loss = 446.26 (38.0 examples/sec; 3.370 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-09-29 05:06:42.998236: step 10490, loss = 444.63 (38.2 examples/sec; 3.349 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.293418\n",
      "2017-09-29 05:07:17.141843: step 10500, loss = 439.07 (37.5 examples/sec; 3.414 sec/batch)\n",
      "2017-09-29 05:07:50.602524: step 10510, loss = 438.06 (38.3 examples/sec; 3.346 sec/batch)\n",
      "2017-09-29 05:08:24.243478: step 10520, loss = 432.07 (38.0 examples/sec; 3.364 sec/batch)\n",
      "2017-09-29 05:08:57.878145: step 10530, loss = 428.77 (38.1 examples/sec; 3.363 sec/batch)\n",
      "2017-09-29 05:09:31.312220: step 10540, loss = 425.20 (38.3 examples/sec; 3.343 sec/batch)\n",
      "2017-09-29 05:10:04.805050: step 10550, loss = 421.96 (38.2 examples/sec; 3.349 sec/batch)\n",
      "2017-09-29 05:10:38.508789: step 10560, loss = 422.72 (38.0 examples/sec; 3.370 sec/batch)\n",
      "2017-09-29 05:11:12.078019: step 10570, loss = 415.22 (38.1 examples/sec; 3.357 sec/batch)\n",
      "2017-09-29 05:11:45.717752: step 10580, loss = 413.49 (38.1 examples/sec; 3.364 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 10590 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-29 05:12:19.212663: step 10590, loss = 408.57 (38.2 examples/sec; 3.349 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.301767\n",
      "2017-09-29 05:12:48.512699: step 10600, loss = 406.67 (43.7 examples/sec; 2.930 sec/batch)\n",
      "2017-09-29 05:13:18.881367: step 10610, loss = 405.73 (42.1 examples/sec; 3.037 sec/batch)\n",
      "2017-09-29 05:13:52.440175: step 10620, loss = 398.87 (38.1 examples/sec; 3.356 sec/batch)\n",
      "2017-09-29 05:14:26.134378: step 10630, loss = 397.60 (38.0 examples/sec; 3.369 sec/batch)\n",
      "2017-09-29 05:14:59.729211: step 10640, loss = 392.57 (38.1 examples/sec; 3.359 sec/batch)\n",
      "2017-09-29 05:15:33.410712: step 10650, loss = 389.55 (38.0 examples/sec; 3.368 sec/batch)\n",
      "2017-09-29 05:16:06.987888: step 10660, loss = 386.28 (38.1 examples/sec; 3.358 sec/batch)\n",
      "2017-09-29 05:16:40.631159: step 10670, loss = 383.28 (38.0 examples/sec; 3.364 sec/batch)\n",
      "2017-09-29 05:17:14.316860: step 10680, loss = 383.43 (38.0 examples/sec; 3.369 sec/batch)\n",
      "2017-09-29 05:17:48.110551: step 10690, loss = 377.20 (37.9 examples/sec; 3.379 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.299684\n",
      "2017-09-29 05:18:22.206204: step 10700, loss = 375.92 (37.5 examples/sec; 3.410 sec/batch)\n",
      "2017-09-29 05:18:54.569349: step 10710, loss = 371.15 (39.6 examples/sec; 3.236 sec/batch)\n",
      "2017-09-29 05:19:25.423265: step 10720, loss = 368.42 (41.5 examples/sec; 3.085 sec/batch)\n",
      "2017-09-29 05:19:56.578528: step 10730, loss = 373.05 (41.1 examples/sec; 3.116 sec/batch)\n",
      "2017-09-29 05:20:29.613944: step 10740, loss = 362.41 (38.7 examples/sec; 3.304 sec/batch)\n",
      "2017-09-29 05:21:03.342826: step 10750, loss = 361.50 (37.9 examples/sec; 3.373 sec/batch)\n",
      "2017-09-29 05:21:37.000162: step 10760, loss = 356.61 (38.0 examples/sec; 3.366 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 10772 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-29 05:22:14.324946: step 10770, loss = 354.30 (34.3 examples/sec; 3.732 sec/batch)\n",
      "2017-09-29 05:22:47.829109: step 10780, loss = 350.93 (38.2 examples/sec; 3.350 sec/batch)\n",
      "2017-09-29 05:23:21.576888: step 10790, loss = 348.14 (37.9 examples/sec; 3.375 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.299903\n",
      "2017-09-29 05:23:55.647446: step 10800, loss = 347.64 (37.6 examples/sec; 3.407 sec/batch)\n",
      "2017-09-29 05:24:29.193014: step 10810, loss = 342.65 (38.2 examples/sec; 3.355 sec/batch)\n",
      "2017-09-29 05:25:02.718666: step 10820, loss = 341.06 (38.2 examples/sec; 3.353 sec/batch)\n",
      "2017-09-29 05:25:36.540305: step 10830, loss = 337.18 (37.8 examples/sec; 3.382 sec/batch)\n",
      "2017-09-29 05:26:10.118311: step 10840, loss = 334.74 (38.1 examples/sec; 3.358 sec/batch)\n",
      "2017-09-29 05:26:43.627501: step 10850, loss = 337.03 (38.2 examples/sec; 3.351 sec/batch)\n",
      "2017-09-29 05:27:17.166822: step 10860, loss = 329.21 (38.2 examples/sec; 3.354 sec/batch)\n",
      "2017-09-29 05:27:50.665313: step 10870, loss = 327.84 (38.2 examples/sec; 3.350 sec/batch)\n",
      "2017-09-29 05:28:24.373827: step 10880, loss = 323.96 (38.0 examples/sec; 3.371 sec/batch)\n",
      "2017-09-29 05:28:57.924202: step 10890, loss = 322.02 (38.2 examples/sec; 3.355 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.297436\n",
      "2017-09-29 05:29:31.855050: step 10900, loss = 320.00 (37.7 examples/sec; 3.393 sec/batch)\n",
      "2017-09-29 05:30:05.545345: step 10910, loss = 316.31 (38.0 examples/sec; 3.369 sec/batch)\n",
      "2017-09-29 05:30:39.027494: step 10920, loss = 316.25 (38.2 examples/sec; 3.348 sec/batch)\n",
      "2017-09-29 05:31:12.604163: step 10930, loss = 311.28 (38.1 examples/sec; 3.358 sec/batch)\n",
      "2017-09-29 05:31:46.087187: step 10940, loss = 309.20 (38.2 examples/sec; 3.348 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 10950 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-29 05:32:23.520057: step 10950, loss = 306.31 (34.2 examples/sec; 3.743 sec/batch)\n",
      "2017-09-29 05:32:57.250726: step 10960, loss = 304.06 (37.9 examples/sec; 3.373 sec/batch)\n",
      "2017-09-29 05:33:30.630861: step 10970, loss = 305.67 (38.3 examples/sec; 3.338 sec/batch)\n",
      "2017-09-29 05:34:04.006870: step 10980, loss = 299.13 (38.4 examples/sec; 3.338 sec/batch)\n",
      "2017-09-29 05:34:37.459557: step 10990, loss = 297.11 (38.3 examples/sec; 3.345 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.29453\n",
      "2017-09-29 05:35:11.377924: step 11000, loss = 294.29 (37.7 examples/sec; 3.392 sec/batch)\n",
      "2017-09-29 05:35:45.210359: step 11010, loss = 292.60 (37.8 examples/sec; 3.383 sec/batch)\n",
      "2017-09-29 05:36:18.840547: step 11020, loss = 293.35 (38.1 examples/sec; 3.363 sec/batch)\n",
      "2017-09-29 05:36:52.384495: step 11030, loss = 287.36 (38.2 examples/sec; 3.354 sec/batch)\n",
      "2017-09-29 05:37:26.142010: step 11040, loss = 286.11 (37.9 examples/sec; 3.376 sec/batch)\n",
      "2017-09-29 05:37:59.881703: step 11050, loss = 282.75 (37.9 examples/sec; 3.374 sec/batch)\n",
      "2017-09-29 05:38:33.562982: step 11060, loss = 281.82 (38.0 examples/sec; 3.368 sec/batch)\n",
      "2017-09-29 05:39:07.159767: step 11070, loss = 278.31 (38.1 examples/sec; 3.360 sec/batch)\n",
      "2017-09-29 05:39:40.446620: step 11080, loss = 276.34 (38.5 examples/sec; 3.329 sec/batch)\n",
      "2017-09-29 05:40:14.128019: step 11090, loss = 278.16 (38.0 examples/sec; 3.368 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.297016\n",
      "2017-09-29 05:40:48.060525: step 11100, loss = 271.77 (37.7 examples/sec; 3.393 sec/batch)\n",
      "2017-09-29 05:41:21.539176: step 11110, loss = 270.67 (38.2 examples/sec; 3.348 sec/batch)\n",
      "2017-09-29 05:41:55.192478: step 11120, loss = 267.35 (38.0 examples/sec; 3.365 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 11128 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-29 05:42:32.592759: step 11130, loss = 265.48 (34.2 examples/sec; 3.740 sec/batch)\n",
      "2017-09-29 05:43:06.235218: step 11140, loss = 269.59 (38.0 examples/sec; 3.364 sec/batch)\n",
      "2017-09-29 05:43:39.941078: step 11150, loss = 261.08 (38.0 examples/sec; 3.371 sec/batch)\n",
      "2017-09-29 05:44:13.566738: step 11160, loss = 260.78 (38.1 examples/sec; 3.363 sec/batch)\n",
      "2017-09-29 05:44:47.262560: step 11170, loss = 256.92 (38.0 examples/sec; 3.370 sec/batch)\n",
      "2017-09-29 05:45:20.792317: step 11180, loss = 256.19 (38.2 examples/sec; 3.353 sec/batch)\n",
      "2017-09-29 05:45:54.387407: step 11190, loss = 252.84 (38.1 examples/sec; 3.360 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.293779\n",
      "2017-09-29 05:46:28.452637: step 11200, loss = 251.05 (37.6 examples/sec; 3.407 sec/batch)\n",
      "2017-09-29 05:47:02.000930: step 11210, loss = 253.32 (38.2 examples/sec; 3.355 sec/batch)\n",
      "2017-09-29 05:47:35.773676: step 11220, loss = 247.03 (37.9 examples/sec; 3.377 sec/batch)\n",
      "2017-09-29 05:48:09.319579: step 11230, loss = 246.89 (38.2 examples/sec; 3.355 sec/batch)\n",
      "2017-09-29 05:48:42.839318: step 11240, loss = 242.99 (38.2 examples/sec; 3.352 sec/batch)\n",
      "2017-09-29 05:49:16.566041: step 11250, loss = 241.74 (38.0 examples/sec; 3.373 sec/batch)\n",
      "2017-09-29 05:49:50.024412: step 11260, loss = 243.30 (38.3 examples/sec; 3.346 sec/batch)\n",
      "2017-09-29 05:50:23.595906: step 11270, loss = 237.15 (38.1 examples/sec; 3.357 sec/batch)\n",
      "2017-09-29 05:50:57.178850: step 11280, loss = 237.60 (38.1 examples/sec; 3.358 sec/batch)\n",
      "2017-09-29 05:51:30.644692: step 11290, loss = 233.49 (38.2 examples/sec; 3.347 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.297441\n",
      "2017-09-29 05:52:04.653609: step 11300, loss = 232.36 (37.6 examples/sec; 3.401 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 11306 into /tmp/phd08_train/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-09-29 05:52:41.848818: step 11310, loss = 230.25 (34.4 examples/sec; 3.720 sec/batch)\n",
      "2017-09-29 05:53:15.314069: step 11320, loss = 227.96 (38.2 examples/sec; 3.347 sec/batch)\n",
      "2017-09-29 05:53:49.032773: step 11330, loss = 228.95 (38.0 examples/sec; 3.372 sec/batch)\n",
      "2017-09-29 05:54:22.459625: step 11340, loss = 224.30 (38.3 examples/sec; 3.343 sec/batch)\n",
      "2017-09-29 05:54:56.308173: step 11350, loss = 223.59 (37.8 examples/sec; 3.385 sec/batch)\n",
      "2017-09-29 05:55:29.776710: step 11360, loss = 220.68 (38.2 examples/sec; 3.347 sec/batch)\n",
      "2017-09-29 05:56:03.482626: step 11370, loss = 219.41 (38.0 examples/sec; 3.371 sec/batch)\n",
      "2017-09-29 05:56:37.194003: step 11380, loss = 221.69 (38.0 examples/sec; 3.371 sec/batch)\n",
      "2017-09-29 05:57:10.718598: step 11390, loss = 215.44 (38.2 examples/sec; 3.352 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.294009\n",
      "2017-09-29 05:57:44.779970: step 11400, loss = 215.54 (37.6 examples/sec; 3.406 sec/batch)\n",
      "2017-09-29 05:58:18.385998: step 11410, loss = 212.04 (38.1 examples/sec; 3.361 sec/batch)\n",
      "2017-09-29 05:58:52.031743: step 11420, loss = 211.42 (38.0 examples/sec; 3.365 sec/batch)\n",
      "2017-09-29 05:59:25.651624: step 11430, loss = 212.59 (38.1 examples/sec; 3.362 sec/batch)\n",
      "2017-09-29 05:59:59.142223: step 11440, loss = 207.27 (38.2 examples/sec; 3.349 sec/batch)\n",
      "2017-09-29 06:00:32.636985: step 11450, loss = 207.88 (38.2 examples/sec; 3.349 sec/batch)\n",
      "2017-09-29 06:01:06.364134: step 11460, loss = 203.78 (38.0 examples/sec; 3.373 sec/batch)\n",
      "2017-09-29 06:01:39.749296: step 11470, loss = 203.25 (38.3 examples/sec; 3.339 sec/batch)\n",
      "2017-09-29 06:02:13.378792: step 11480, loss = 200.49 (38.1 examples/sec; 3.363 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 11484 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-29 06:02:50.767954: step 11490, loss = 199.41 (34.2 examples/sec; 3.739 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.294429\n",
      "2017-09-29 06:03:24.421187: step 11500, loss = 201.46 (38.0 examples/sec; 3.365 sec/batch)\n",
      "2017-09-29 06:03:57.916584: step 11510, loss = 195.84 (38.2 examples/sec; 3.350 sec/batch)\n",
      "2017-09-29 06:04:31.424651: step 11520, loss = 196.22 (38.2 examples/sec; 3.351 sec/batch)\n",
      "2017-09-29 06:05:04.917748: step 11530, loss = 192.64 (38.2 examples/sec; 3.349 sec/batch)\n",
      "2017-09-29 06:05:38.658507: step 11540, loss = 191.80 (37.9 examples/sec; 3.374 sec/batch)\n",
      "2017-09-29 06:06:12.387393: step 11550, loss = 195.24 (37.9 examples/sec; 3.373 sec/batch)\n",
      "2017-09-29 06:06:45.858069: step 11560, loss = 188.44 (38.2 examples/sec; 3.347 sec/batch)\n",
      "2017-09-29 06:07:19.475486: step 11570, loss = 189.58 (38.1 examples/sec; 3.362 sec/batch)\n",
      "2017-09-29 06:07:53.147821: step 11580, loss = 185.16 (38.0 examples/sec; 3.367 sec/batch)\n",
      "2017-09-29 06:08:26.864542: step 11590, loss = 185.26 (38.0 examples/sec; 3.372 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.297488\n",
      "2017-09-29 06:09:00.568344: step 11600, loss = 182.20 (38.0 examples/sec; 3.370 sec/batch)\n",
      "2017-09-29 06:09:34.084794: step 11610, loss = 180.96 (38.2 examples/sec; 3.352 sec/batch)\n",
      "2017-09-29 06:10:07.599869: step 11620, loss = 183.33 (38.2 examples/sec; 3.352 sec/batch)\n",
      "2017-09-29 06:10:40.904852: step 11630, loss = 178.52 (38.4 examples/sec; 3.330 sec/batch)\n",
      "2017-09-29 06:11:14.605385: step 11640, loss = 178.93 (38.0 examples/sec; 3.370 sec/batch)\n",
      "2017-09-29 06:11:48.425737: step 11650, loss = 175.66 (37.8 examples/sec; 3.382 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 11662 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-29 06:12:25.397123: step 11660, loss = 176.24 (34.6 examples/sec; 3.697 sec/batch)\n",
      "2017-09-29 06:12:59.153782: step 11670, loss = 177.14 (37.9 examples/sec; 3.376 sec/batch)\n",
      "2017-09-29 06:13:32.945797: step 11680, loss = 171.24 (37.9 examples/sec; 3.379 sec/batch)\n",
      "2017-09-29 06:14:06.459671: step 11690, loss = 172.56 (38.2 examples/sec; 3.351 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.294339\n",
      "2017-09-29 06:14:40.312513: step 11700, loss = 169.19 (37.8 examples/sec; 3.385 sec/batch)\n",
      "2017-09-29 06:15:14.122011: step 11710, loss = 168.28 (37.9 examples/sec; 3.381 sec/batch)\n",
      "2017-09-29 06:15:47.776307: step 11720, loss = 165.80 (38.0 examples/sec; 3.365 sec/batch)\n",
      "2017-09-29 06:16:21.356263: step 11730, loss = 165.13 (38.1 examples/sec; 3.358 sec/batch)\n",
      "2017-09-29 06:16:54.890882: step 11740, loss = 167.24 (38.2 examples/sec; 3.353 sec/batch)\n",
      "2017-09-29 06:17:28.753369: step 11750, loss = 162.30 (37.8 examples/sec; 3.386 sec/batch)\n",
      "2017-09-29 06:18:02.530072: step 11760, loss = 162.06 (37.9 examples/sec; 3.378 sec/batch)\n",
      "2017-09-29 06:18:35.982946: step 11770, loss = 159.07 (38.3 examples/sec; 3.345 sec/batch)\n",
      "2017-09-29 06:19:09.424236: step 11780, loss = 157.87 (38.3 examples/sec; 3.344 sec/batch)\n",
      "2017-09-29 06:19:43.075572: step 11790, loss = 160.47 (38.0 examples/sec; 3.365 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.296982\n",
      "2017-09-29 06:20:17.036351: step 11800, loss = 155.26 (37.7 examples/sec; 3.396 sec/batch)\n",
      "2017-09-29 06:20:50.624539: step 11810, loss = 155.14 (38.1 examples/sec; 3.359 sec/batch)\n",
      "2017-09-29 06:21:24.159277: step 11820, loss = 152.78 (38.2 examples/sec; 3.353 sec/batch)\n",
      "2017-09-29 06:21:57.656216: step 11830, loss = 152.75 (38.2 examples/sec; 3.350 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 11840 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-29 06:22:35.140515: step 11840, loss = 153.32 (34.1 examples/sec; 3.748 sec/batch)\n",
      "2017-09-29 06:23:08.934232: step 11850, loss = 149.96 (37.9 examples/sec; 3.379 sec/batch)\n",
      "2017-09-29 06:23:42.410835: step 11860, loss = 150.36 (38.2 examples/sec; 3.348 sec/batch)\n",
      "2017-09-29 06:24:15.947569: step 11870, loss = 146.80 (38.2 examples/sec; 3.354 sec/batch)\n",
      "2017-09-29 06:24:49.414905: step 11880, loss = 146.58 (38.2 examples/sec; 3.347 sec/batch)\n",
      "2017-09-29 06:25:22.982563: step 11890, loss = 144.43 (38.1 examples/sec; 3.357 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.294072\n",
      "2017-09-29 06:25:57.088234: step 11900, loss = 143.61 (37.5 examples/sec; 3.411 sec/batch)\n",
      "2017-09-29 06:26:30.554769: step 11910, loss = 146.34 (38.2 examples/sec; 3.347 sec/batch)\n",
      "2017-09-29 06:27:04.299430: step 11920, loss = 141.17 (37.9 examples/sec; 3.374 sec/batch)\n",
      "2017-09-29 06:27:37.877073: step 11930, loss = 141.84 (38.1 examples/sec; 3.358 sec/batch)\n",
      "2017-09-29 06:28:11.639672: step 11940, loss = 138.80 (37.9 examples/sec; 3.376 sec/batch)\n",
      "2017-09-29 06:28:45.332857: step 11950, loss = 138.88 (38.0 examples/sec; 3.369 sec/batch)\n",
      "2017-09-29 06:29:18.941887: step 11960, loss = 143.04 (38.1 examples/sec; 3.361 sec/batch)\n",
      "2017-09-29 06:29:52.451273: step 11970, loss = 135.82 (38.2 examples/sec; 3.351 sec/batch)\n",
      "2017-09-29 06:30:25.931073: step 11980, loss = 136.93 (38.2 examples/sec; 3.348 sec/batch)\n",
      "2017-09-29 06:30:59.420585: step 11990, loss = 133.42 (38.2 examples/sec; 3.349 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.297295\n",
      "2017-09-29 06:31:33.453469: step 12000, loss = 133.53 (37.6 examples/sec; 3.403 sec/batch)\n",
      "2017-09-29 06:32:07.216790: step 12010, loss = 131.26 (37.9 examples/sec; 3.376 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 12018 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-29 06:32:44.699606: step 12020, loss = 131.50 (34.1 examples/sec; 3.748 sec/batch)\n",
      "2017-09-29 06:33:18.192371: step 12030, loss = 132.94 (38.2 examples/sec; 3.349 sec/batch)\n",
      "2017-09-29 06:33:51.767410: step 12040, loss = 128.94 (38.1 examples/sec; 3.358 sec/batch)\n",
      "2017-09-29 06:34:25.437125: step 12050, loss = 129.73 (38.0 examples/sec; 3.367 sec/batch)\n",
      "2017-09-29 06:34:59.050100: step 12060, loss = 126.33 (38.1 examples/sec; 3.361 sec/batch)\n",
      "2017-09-29 06:35:32.547230: step 12070, loss = 125.59 (38.2 examples/sec; 3.350 sec/batch)\n",
      "2017-09-29 06:36:06.075163: step 12080, loss = 128.54 (38.2 examples/sec; 3.353 sec/batch)\n",
      "2017-09-29 06:36:39.516857: step 12090, loss = 123.13 (38.3 examples/sec; 3.344 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.293987\n",
      "2017-09-29 06:37:13.604701: step 12100, loss = 123.67 (37.6 examples/sec; 3.409 sec/batch)\n",
      "2017-09-29 06:37:47.452133: step 12110, loss = 121.18 (37.8 examples/sec; 3.385 sec/batch)\n",
      "2017-09-29 06:38:21.162555: step 12120, loss = 120.60 (38.0 examples/sec; 3.371 sec/batch)\n",
      "2017-09-29 06:38:54.918078: step 12130, loss = 119.22 (37.9 examples/sec; 3.376 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-09-29 06:39:28.468395: step 12140, loss = 119.14 (38.2 examples/sec; 3.355 sec/batch)\n",
      "2017-09-29 06:40:01.842594: step 12150, loss = 121.21 (38.4 examples/sec; 3.337 sec/batch)\n",
      "2017-09-29 06:40:35.464044: step 12160, loss = 116.64 (38.1 examples/sec; 3.362 sec/batch)\n",
      "2017-09-29 06:41:09.086856: step 12170, loss = 117.57 (38.1 examples/sec; 3.362 sec/batch)\n",
      "2017-09-29 06:41:42.969487: step 12180, loss = 114.62 (37.8 examples/sec; 3.388 sec/batch)\n",
      "2017-09-29 06:42:16.601507: step 12190, loss = 114.49 (38.1 examples/sec; 3.363 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 12196 into /tmp/phd08_train/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.293906\n",
      "2017-09-29 06:42:53.852908: step 12200, loss = 116.94 (34.4 examples/sec; 3.725 sec/batch)\n",
      "2017-09-29 06:43:27.606493: step 12210, loss = 111.89 (37.9 examples/sec; 3.375 sec/batch)\n",
      "2017-09-29 06:44:01.398131: step 12220, loss = 113.07 (37.9 examples/sec; 3.379 sec/batch)\n",
      "2017-09-29 06:44:34.939706: step 12230, loss = 110.10 (38.2 examples/sec; 3.354 sec/batch)\n",
      "2017-09-29 06:45:08.578042: step 12240, loss = 110.45 (38.1 examples/sec; 3.364 sec/batch)\n",
      "2017-09-29 06:45:42.237914: step 12250, loss = 110.84 (38.0 examples/sec; 3.366 sec/batch)\n",
      "2017-09-29 06:46:15.773168: step 12260, loss = 107.75 (38.2 examples/sec; 3.354 sec/batch)\n",
      "2017-09-29 06:46:49.176065: step 12270, loss = 109.46 (38.3 examples/sec; 3.340 sec/batch)\n",
      "2017-09-29 06:47:22.773466: step 12280, loss = 105.77 (38.1 examples/sec; 3.360 sec/batch)\n",
      "2017-09-29 06:47:56.670882: step 12290, loss = 106.16 (37.8 examples/sec; 3.390 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.297076\n",
      "2017-09-29 06:48:30.461477: step 12300, loss = 104.05 (37.9 examples/sec; 3.379 sec/batch)\n",
      "2017-09-29 06:49:04.013395: step 12310, loss = 103.18 (38.1 examples/sec; 3.355 sec/batch)\n",
      "2017-09-29 06:49:34.125772: step 12320, loss = 104.85 (42.5 examples/sec; 3.011 sec/batch)\n",
      "2017-09-29 06:50:03.154898: step 12330, loss = 101.60 (44.1 examples/sec; 2.903 sec/batch)\n",
      "2017-09-29 06:50:34.434797: step 12340, loss = 103.24 (40.9 examples/sec; 3.128 sec/batch)\n",
      "2017-09-29 06:51:08.070549: step 12350, loss = 100.13 (38.1 examples/sec; 3.364 sec/batch)\n",
      "2017-09-29 06:51:41.616288: step 12360, loss = 100.59 (38.2 examples/sec; 3.355 sec/batch)\n",
      "2017-09-29 06:52:15.178306: step 12370, loss = 103.14 (38.1 examples/sec; 3.356 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 12377 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-29 06:52:52.587839: step 12380, loss = 98.96 (34.2 examples/sec; 3.741 sec/batch)\n",
      "2017-09-29 06:53:26.016178: step 12390, loss = 100.45 (38.3 examples/sec; 3.343 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.303446\n",
      "2017-09-29 06:54:00.002089: step 12400, loss = 98.38 (37.7 examples/sec; 3.399 sec/batch)\n",
      "2017-09-29 06:54:33.334170: step 12410, loss = 98.21 (38.4 examples/sec; 3.333 sec/batch)\n",
      "2017-09-29 06:55:06.952863: step 12420, loss = 96.54 (38.1 examples/sec; 3.362 sec/batch)\n",
      "2017-09-29 06:55:40.338446: step 12430, loss = 96.22 (38.3 examples/sec; 3.339 sec/batch)\n",
      "2017-09-29 06:56:13.917287: step 12440, loss = 96.40 (38.1 examples/sec; 3.358 sec/batch)\n",
      "2017-09-29 06:56:47.483111: step 12450, loss = 94.69 (38.1 examples/sec; 3.357 sec/batch)\n",
      "2017-09-29 06:57:21.088783: step 12460, loss = 94.55 (38.1 examples/sec; 3.361 sec/batch)\n",
      "2017-09-29 06:57:53.080693: step 12470, loss = 92.90 (40.0 examples/sec; 3.199 sec/batch)\n",
      "2017-09-29 06:58:28.567676: step 12480, loss = 92.78 (36.1 examples/sec; 3.549 sec/batch)\n",
      "2017-09-29 06:59:02.210034: step 12490, loss = 93.00 (38.0 examples/sec; 3.364 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.297535\n",
      "2017-09-29 06:59:36.098714: step 12500, loss = 91.30 (37.8 examples/sec; 3.389 sec/batch)\n",
      "2017-09-29 07:00:09.778694: step 12510, loss = 91.49 (38.0 examples/sec; 3.368 sec/batch)\n",
      "2017-09-29 07:00:43.078262: step 12520, loss = 89.82 (38.4 examples/sec; 3.330 sec/batch)\n",
      "2017-09-29 07:01:16.746816: step 12530, loss = 89.70 (38.0 examples/sec; 3.367 sec/batch)\n",
      "2017-09-29 07:01:50.382982: step 12540, loss = 88.08 (38.1 examples/sec; 3.364 sec/batch)\n",
      "2017-09-29 07:02:24.176458: step 12550, loss = 87.81 (37.9 examples/sec; 3.379 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 12555 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-29 07:03:01.251813: step 12560, loss = 87.90 (34.5 examples/sec; 3.708 sec/batch)\n",
      "2017-09-29 07:03:34.802998: step 12570, loss = 86.27 (38.2 examples/sec; 3.355 sec/batch)\n",
      "2017-09-29 07:04:08.458607: step 12580, loss = 86.70 (38.0 examples/sec; 3.366 sec/batch)\n",
      "2017-09-29 07:04:41.902687: step 12590, loss = 85.06 (38.3 examples/sec; 3.344 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.294209\n",
      "2017-09-29 07:05:15.990800: step 12600, loss = 84.84 (37.5 examples/sec; 3.409 sec/batch)\n",
      "2017-09-29 07:05:49.522851: step 12610, loss = 84.72 (38.2 examples/sec; 3.353 sec/batch)\n",
      "2017-09-29 07:06:22.921281: step 12620, loss = 83.10 (38.3 examples/sec; 3.340 sec/batch)\n",
      "2017-09-29 07:06:56.479151: step 12630, loss = 84.07 (38.1 examples/sec; 3.356 sec/batch)\n",
      "2017-09-29 07:07:30.086220: step 12640, loss = 82.42 (38.1 examples/sec; 3.361 sec/batch)\n",
      "2017-09-29 07:08:03.744909: step 12650, loss = 80.99 (38.0 examples/sec; 3.366 sec/batch)\n",
      "2017-09-29 07:08:37.170959: step 12660, loss = 80.17 (38.3 examples/sec; 3.343 sec/batch)\n",
      "2017-09-29 07:09:10.787139: step 12670, loss = 79.93 (38.1 examples/sec; 3.362 sec/batch)\n",
      "2017-09-29 07:09:44.265615: step 12680, loss = 80.67 (38.2 examples/sec; 3.348 sec/batch)\n",
      "2017-09-29 07:10:17.799666: step 12690, loss = 79.05 (38.2 examples/sec; 3.353 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.297852\n",
      "2017-09-29 07:10:51.727838: step 12700, loss = 78.33 (37.7 examples/sec; 3.393 sec/batch)\n",
      "2017-09-29 07:11:25.331624: step 12710, loss = 76.85 (38.1 examples/sec; 3.360 sec/batch)\n",
      "2017-09-29 07:11:58.983176: step 12720, loss = 77.02 (38.0 examples/sec; 3.365 sec/batch)\n",
      "2017-09-29 07:12:32.620041: step 12730, loss = 76.94 (38.1 examples/sec; 3.364 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 12733 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-29 07:13:10.232099: step 12740, loss = 75.42 (34.0 examples/sec; 3.761 sec/batch)\n",
      "2017-09-29 07:13:44.094454: step 12750, loss = 75.66 (37.8 examples/sec; 3.386 sec/batch)\n",
      "2017-09-29 07:14:17.814604: step 12760, loss = 74.16 (38.0 examples/sec; 3.372 sec/batch)\n",
      "2017-09-29 07:14:51.228857: step 12770, loss = 74.45 (38.3 examples/sec; 3.341 sec/batch)\n",
      "2017-09-29 07:15:24.946426: step 12780, loss = 74.14 (38.0 examples/sec; 3.372 sec/batch)\n",
      "2017-09-29 07:15:58.460866: step 12790, loss = 73.07 (38.2 examples/sec; 3.351 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.29356\n",
      "2017-09-29 07:16:32.373296: step 12800, loss = 73.06 (37.7 examples/sec; 3.391 sec/batch)\n",
      "2017-09-29 07:17:05.918705: step 12810, loss = 71.55 (38.2 examples/sec; 3.355 sec/batch)\n",
      "2017-09-29 07:17:39.485596: step 12820, loss = 71.52 (38.1 examples/sec; 3.357 sec/batch)\n",
      "2017-09-29 07:18:13.414251: step 12830, loss = 70.08 (37.7 examples/sec; 3.393 sec/batch)\n",
      "2017-09-29 07:18:46.566423: step 12840, loss = 70.48 (38.6 examples/sec; 3.315 sec/batch)\n",
      "2017-09-29 07:19:20.156767: step 12850, loss = 70.25 (38.1 examples/sec; 3.359 sec/batch)\n",
      "2017-09-29 07:19:53.759238: step 12860, loss = 68.77 (38.1 examples/sec; 3.360 sec/batch)\n",
      "2017-09-29 07:20:27.422685: step 12870, loss = 69.15 (38.0 examples/sec; 3.366 sec/batch)\n",
      "2017-09-29 07:21:00.975302: step 12880, loss = 67.68 (38.1 examples/sec; 3.355 sec/batch)\n",
      "2017-09-29 07:21:34.598523: step 12890, loss = 68.47 (38.1 examples/sec; 3.362 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.297549\n",
      "2017-09-29 07:22:08.453258: step 12900, loss = 68.44 (37.8 examples/sec; 3.385 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 12911 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-29 07:22:45.951576: step 12910, loss = 66.92 (34.1 examples/sec; 3.750 sec/batch)\n",
      "2017-09-29 07:23:19.607835: step 12920, loss = 66.65 (38.0 examples/sec; 3.366 sec/batch)\n",
      "2017-09-29 07:23:53.310370: step 12930, loss = 65.20 (38.0 examples/sec; 3.370 sec/batch)\n",
      "2017-09-29 07:24:26.854580: step 12940, loss = 65.94 (38.2 examples/sec; 3.354 sec/batch)\n",
      "2017-09-29 07:25:00.080052: step 12950, loss = 64.47 (38.5 examples/sec; 3.323 sec/batch)\n",
      "2017-09-29 07:25:33.619633: step 12960, loss = 64.28 (38.2 examples/sec; 3.354 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-09-29 07:26:07.134498: step 12970, loss = 64.47 (38.2 examples/sec; 3.351 sec/batch)\n",
      "2017-09-29 07:26:40.464638: step 12980, loss = 63.02 (38.4 examples/sec; 3.333 sec/batch)\n",
      "2017-09-29 07:27:13.935693: step 12990, loss = 62.70 (38.2 examples/sec; 3.347 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.294757\n",
      "2017-09-29 07:27:47.714231: step 13000, loss = 61.35 (37.9 examples/sec; 3.378 sec/batch)\n",
      "2017-09-29 07:28:21.565334: step 13010, loss = 61.69 (37.8 examples/sec; 3.385 sec/batch)\n",
      "2017-09-29 07:28:54.016597: step 13020, loss = 62.10 (39.4 examples/sec; 3.245 sec/batch)\n",
      "2017-09-29 07:29:27.940295: step 13030, loss = 60.65 (37.7 examples/sec; 3.392 sec/batch)\n",
      "2017-09-29 07:30:01.558819: step 13040, loss = 60.34 (38.1 examples/sec; 3.362 sec/batch)\n",
      "2017-09-29 07:30:35.027860: step 13050, loss = 59.01 (38.2 examples/sec; 3.347 sec/batch)\n",
      "2017-09-29 07:31:08.618796: step 13060, loss = 59.28 (38.1 examples/sec; 3.359 sec/batch)\n",
      "2017-09-29 07:31:42.134243: step 13070, loss = 58.31 (38.2 examples/sec; 3.352 sec/batch)\n",
      "2017-09-29 07:32:15.501884: step 13080, loss = 57.93 (38.4 examples/sec; 3.337 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 13089 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-29 07:32:52.524601: step 13090, loss = 58.72 (34.6 examples/sec; 3.702 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.295429\n",
      "2017-09-29 07:33:26.205412: step 13100, loss = 57.30 (38.0 examples/sec; 3.368 sec/batch)\n",
      "2017-09-29 07:33:59.805204: step 13110, loss = 57.06 (38.1 examples/sec; 3.360 sec/batch)\n",
      "2017-09-29 07:34:33.410247: step 13120, loss = 55.76 (38.1 examples/sec; 3.361 sec/batch)\n",
      "2017-09-29 07:35:06.985816: step 13130, loss = 56.68 (38.1 examples/sec; 3.358 sec/batch)\n",
      "2017-09-29 07:35:40.567696: step 13140, loss = 56.87 (38.1 examples/sec; 3.358 sec/batch)\n",
      "2017-09-29 07:36:13.989280: step 13150, loss = 55.45 (38.3 examples/sec; 3.342 sec/batch)\n",
      "2017-09-29 07:36:47.697059: step 13160, loss = 55.58 (38.0 examples/sec; 3.371 sec/batch)\n",
      "2017-09-29 07:37:21.329388: step 13170, loss = 54.21 (38.1 examples/sec; 3.363 sec/batch)\n",
      "2017-09-29 07:37:54.887184: step 13180, loss = 54.26 (38.1 examples/sec; 3.356 sec/batch)\n",
      "2017-09-29 07:38:28.622815: step 13190, loss = 54.42 (37.9 examples/sec; 3.374 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.297318\n",
      "2017-09-29 07:39:02.545452: step 13200, loss = 53.80 (37.7 examples/sec; 3.392 sec/batch)\n",
      "2017-09-29 07:39:36.030628: step 13210, loss = 53.62 (38.2 examples/sec; 3.349 sec/batch)\n",
      "2017-09-29 07:40:09.588931: step 13220, loss = 52.27 (38.1 examples/sec; 3.356 sec/batch)\n",
      "2017-09-29 07:40:44.241943: step 13230, loss = 52.97 (36.9 examples/sec; 3.465 sec/batch)\n",
      "2017-09-29 07:41:18.150774: step 13240, loss = 51.61 (37.7 examples/sec; 3.391 sec/batch)\n",
      "2017-09-29 07:41:51.767399: step 13250, loss = 51.76 (38.1 examples/sec; 3.362 sec/batch)\n",
      "2017-09-29 07:42:25.391921: step 13260, loss = 51.98 (38.1 examples/sec; 3.362 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 13267 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-29 07:43:02.967437: step 13270, loss = 50.61 (34.1 examples/sec; 3.758 sec/batch)\n",
      "2017-09-29 07:43:36.743943: step 13280, loss = 50.93 (37.9 examples/sec; 3.378 sec/batch)\n",
      "2017-09-29 07:44:10.314028: step 13290, loss = 49.60 (38.1 examples/sec; 3.357 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.292622\n",
      "2017-09-29 07:44:44.283750: step 13300, loss = 49.85 (37.7 examples/sec; 3.397 sec/batch)\n",
      "2017-09-29 07:45:17.649595: step 13310, loss = 50.37 (38.4 examples/sec; 3.337 sec/batch)\n",
      "2017-09-29 07:45:51.117460: step 13320, loss = 49.00 (38.2 examples/sec; 3.347 sec/batch)\n",
      "2017-09-29 07:46:24.842752: step 13330, loss = 48.84 (38.0 examples/sec; 3.373 sec/batch)\n",
      "2017-09-29 07:46:58.484820: step 13340, loss = 47.55 (38.0 examples/sec; 3.364 sec/batch)\n",
      "2017-09-29 07:47:31.930368: step 13350, loss = 47.70 (38.3 examples/sec; 3.345 sec/batch)\n",
      "2017-09-29 07:48:05.639150: step 13360, loss = 46.47 (38.0 examples/sec; 3.371 sec/batch)\n",
      "2017-09-29 07:48:39.234116: step 13370, loss = 46.44 (38.1 examples/sec; 3.359 sec/batch)\n",
      "2017-09-29 07:49:12.740155: step 13380, loss = 46.96 (38.2 examples/sec; 3.351 sec/batch)\n",
      "2017-09-29 07:49:46.439929: step 13390, loss = 45.67 (38.0 examples/sec; 3.370 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.297587\n",
      "2017-09-29 07:50:20.326519: step 13400, loss = 45.83 (37.8 examples/sec; 3.389 sec/batch)\n",
      "2017-09-29 07:50:54.005573: step 13410, loss = 43.43 (38.0 examples/sec; 3.368 sec/batch)\n",
      "2017-09-29 07:51:27.596904: step 13420, loss = 44.35 (38.1 examples/sec; 3.359 sec/batch)\n",
      "2017-09-29 07:52:01.461722: step 13430, loss = 46.55 (37.8 examples/sec; 3.386 sec/batch)\n",
      "2017-09-29 07:52:34.867889: step 13440, loss = 41.88 (38.3 examples/sec; 3.341 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 13445 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-29 07:53:12.063991: step 13450, loss = 43.07 (34.4 examples/sec; 3.720 sec/batch)\n",
      "2017-09-29 07:53:45.747799: step 13460, loss = 41.16 (38.0 examples/sec; 3.368 sec/batch)\n",
      "2017-09-29 07:54:19.166319: step 13470, loss = 41.57 (38.3 examples/sec; 3.342 sec/batch)\n",
      "2017-09-29 07:54:52.860730: step 13480, loss = 41.93 (38.0 examples/sec; 3.369 sec/batch)\n",
      "2017-09-29 07:55:26.509756: step 13490, loss = 40.36 (38.0 examples/sec; 3.365 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.293977\n",
      "2017-09-29 07:56:00.489967: step 13500, loss = 42.99 (37.7 examples/sec; 3.398 sec/batch)\n",
      "2017-09-29 07:56:33.865487: step 13510, loss = 39.62 (38.4 examples/sec; 3.338 sec/batch)\n",
      "2017-09-29 07:57:07.589763: step 13520, loss = 40.68 (38.0 examples/sec; 3.372 sec/batch)\n",
      "2017-09-29 07:57:41.297948: step 13530, loss = 38.94 (38.0 examples/sec; 3.371 sec/batch)\n",
      "2017-09-29 07:58:15.122227: step 13540, loss = 40.30 (37.8 examples/sec; 3.382 sec/batch)\n",
      "2017-09-29 07:58:48.429520: step 13550, loss = 42.71 (38.4 examples/sec; 3.331 sec/batch)\n",
      "2017-09-29 07:59:22.000150: step 13560, loss = 38.21 (38.1 examples/sec; 3.357 sec/batch)\n",
      "2017-09-29 07:59:55.715977: step 13570, loss = 40.45 (38.0 examples/sec; 3.372 sec/batch)\n",
      "2017-09-29 08:00:29.304914: step 13580, loss = 37.47 (38.1 examples/sec; 3.359 sec/batch)\n",
      "2017-09-29 08:01:02.780684: step 13590, loss = 38.13 (38.2 examples/sec; 3.348 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.297301\n",
      "2017-09-29 08:01:36.850947: step 13600, loss = 41.44 (37.6 examples/sec; 3.407 sec/batch)\n",
      "2017-09-29 08:02:10.125905: step 13610, loss = 36.86 (38.5 examples/sec; 3.327 sec/batch)\n",
      "2017-09-29 08:02:43.731132: step 13620, loss = 39.41 (38.1 examples/sec; 3.361 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 13623 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-29 08:03:21.428221: step 13630, loss = 36.15 (34.0 examples/sec; 3.770 sec/batch)\n",
      "2017-09-29 08:03:55.064283: step 13640, loss = 37.11 (38.1 examples/sec; 3.364 sec/batch)\n",
      "2017-09-29 08:04:28.609968: step 13650, loss = 35.45 (38.2 examples/sec; 3.355 sec/batch)\n",
      "2017-09-29 08:05:02.165970: step 13660, loss = 35.83 (38.1 examples/sec; 3.356 sec/batch)\n",
      "2017-09-29 08:05:35.766609: step 13670, loss = 37.97 (38.1 examples/sec; 3.360 sec/batch)\n",
      "2017-09-29 08:06:09.575298: step 13680, loss = 34.71 (37.9 examples/sec; 3.381 sec/batch)\n",
      "2017-09-29 08:06:43.173988: step 13690, loss = 37.13 (38.1 examples/sec; 3.360 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.293892\n",
      "2017-09-29 08:07:17.112575: step 13700, loss = 34.18 (37.7 examples/sec; 3.394 sec/batch)\n",
      "2017-09-29 08:07:50.582118: step 13710, loss = 35.54 (38.2 examples/sec; 3.347 sec/batch)\n",
      "2017-09-29 08:08:24.454500: step 13720, loss = 37.94 (37.8 examples/sec; 3.387 sec/batch)\n",
      "2017-09-29 08:08:58.060617: step 13730, loss = 33.33 (38.1 examples/sec; 3.361 sec/batch)\n",
      "2017-09-29 08:09:31.448275: step 13740, loss = 35.46 (38.3 examples/sec; 3.339 sec/batch)\n",
      "2017-09-29 08:10:02.590726: step 13750, loss = 32.71 (41.1 examples/sec; 3.114 sec/batch)\n",
      "2017-09-29 08:10:36.079988: step 13760, loss = 33.55 (38.2 examples/sec; 3.349 sec/batch)\n",
      "2017-09-29 08:11:09.669451: step 13770, loss = 32.18 (38.1 examples/sec; 3.359 sec/batch)\n",
      "2017-09-29 08:11:43.469317: step 13780, loss = 32.02 (37.9 examples/sec; 3.380 sec/batch)\n",
      "2017-09-29 08:12:16.972685: step 13790, loss = 35.44 (38.2 examples/sec; 3.350 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.299732\n",
      "INFO:tensorflow:Saving checkpoints for 13802 into /tmp/phd08_train/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-09-29 08:12:54.270208: step 13800, loss = 31.53 (34.3 examples/sec; 3.730 sec/batch)\n",
      "2017-09-29 08:13:27.955077: step 13810, loss = 33.66 (38.0 examples/sec; 3.368 sec/batch)\n",
      "2017-09-29 08:14:01.656665: step 13820, loss = 31.04 (38.0 examples/sec; 3.370 sec/batch)\n",
      "2017-09-29 08:14:35.261122: step 13830, loss = 31.56 (38.1 examples/sec; 3.360 sec/batch)\n",
      "2017-09-29 08:15:08.733999: step 13840, loss = 36.22 (38.2 examples/sec; 3.347 sec/batch)\n",
      "2017-09-29 08:15:42.333310: step 13850, loss = 31.54 (38.1 examples/sec; 3.360 sec/batch)\n",
      "2017-09-29 08:16:16.092111: step 13860, loss = 32.78 (37.9 examples/sec; 3.376 sec/batch)\n",
      "2017-09-29 08:16:49.718050: step 13870, loss = 30.98 (38.1 examples/sec; 3.363 sec/batch)\n",
      "2017-09-29 08:17:23.302425: step 13880, loss = 32.12 (38.1 examples/sec; 3.358 sec/batch)\n",
      "2017-09-29 08:17:56.913062: step 13890, loss = 31.18 (38.1 examples/sec; 3.361 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.293983\n",
      "2017-09-29 08:18:30.888453: step 13900, loss = 31.59 (37.7 examples/sec; 3.398 sec/batch)\n",
      "2017-09-29 08:19:04.416296: step 13910, loss = 31.57 (38.2 examples/sec; 3.353 sec/batch)\n",
      "2017-09-29 08:19:38.068279: step 13920, loss = 30.45 (38.0 examples/sec; 3.365 sec/batch)\n",
      "2017-09-29 08:20:11.556662: step 13930, loss = 31.38 (38.2 examples/sec; 3.349 sec/batch)\n",
      "2017-09-29 08:20:44.936711: step 13940, loss = 30.21 (38.3 examples/sec; 3.338 sec/batch)\n",
      "2017-09-29 08:21:18.354364: step 13950, loss = 31.12 (38.3 examples/sec; 3.342 sec/batch)\n",
      "2017-09-29 08:21:51.786758: step 13960, loss = 30.99 (38.3 examples/sec; 3.343 sec/batch)\n",
      "2017-09-29 08:22:25.395652: step 13970, loss = 29.80 (38.1 examples/sec; 3.361 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 13980 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-29 08:23:02.805514: step 13980, loss = 30.70 (34.2 examples/sec; 3.741 sec/batch)\n",
      "2017-09-29 08:23:36.343839: step 13990, loss = 29.51 (38.2 examples/sec; 3.354 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.294521\n",
      "2017-09-29 08:24:10.422874: step 14000, loss = 29.89 (37.6 examples/sec; 3.408 sec/batch)\n",
      "2017-09-29 08:24:43.881038: step 14010, loss = 29.59 (38.3 examples/sec; 3.346 sec/batch)\n",
      "2017-09-29 08:25:17.274601: step 14020, loss = 29.18 (38.3 examples/sec; 3.339 sec/batch)\n",
      "2017-09-29 08:25:50.799276: step 14030, loss = 28.73 (38.2 examples/sec; 3.352 sec/batch)\n",
      "2017-09-29 08:26:24.474447: step 14040, loss = 27.67 (38.0 examples/sec; 3.368 sec/batch)\n",
      "2017-09-29 08:26:57.908912: step 14050, loss = 28.20 (38.3 examples/sec; 3.343 sec/batch)\n",
      "2017-09-29 08:27:31.609270: step 14060, loss = 27.16 (38.0 examples/sec; 3.370 sec/batch)\n",
      "2017-09-29 08:28:05.198453: step 14070, loss = 27.64 (38.1 examples/sec; 3.359 sec/batch)\n",
      "2017-09-29 08:28:38.877325: step 14080, loss = 27.96 (38.0 examples/sec; 3.368 sec/batch)\n",
      "2017-09-29 08:29:12.452306: step 14090, loss = 26.85 (38.1 examples/sec; 3.357 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.297677\n",
      "2017-09-29 08:29:46.361971: step 14100, loss = 28.06 (37.7 examples/sec; 3.391 sec/batch)\n",
      "2017-09-29 08:30:19.841962: step 14110, loss = 26.88 (38.2 examples/sec; 3.348 sec/batch)\n",
      "2017-09-29 08:30:53.380479: step 14120, loss = 26.71 (38.2 examples/sec; 3.354 sec/batch)\n",
      "2017-09-29 08:31:27.035114: step 14130, loss = 29.70 (38.0 examples/sec; 3.365 sec/batch)\n",
      "2017-09-29 08:32:00.631903: step 14140, loss = 24.97 (38.1 examples/sec; 3.360 sec/batch)\n",
      "2017-09-29 08:32:34.157244: step 14150, loss = 25.76 (38.2 examples/sec; 3.353 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 14158 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-29 08:33:11.728448: step 14160, loss = 23.56 (34.1 examples/sec; 3.757 sec/batch)\n",
      "2017-09-29 08:33:45.174510: step 14170, loss = 24.82 (38.3 examples/sec; 3.345 sec/batch)\n",
      "2017-09-29 08:34:18.877632: step 14180, loss = 23.24 (38.0 examples/sec; 3.370 sec/batch)\n",
      "2017-09-29 08:34:52.407182: step 14190, loss = 23.46 (38.2 examples/sec; 3.353 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.294083\n",
      "2017-09-29 08:35:26.407309: step 14200, loss = 26.95 (37.6 examples/sec; 3.400 sec/batch)\n",
      "2017-09-29 08:36:00.012581: step 14210, loss = 22.90 (38.1 examples/sec; 3.361 sec/batch)\n",
      "2017-09-29 08:36:33.617097: step 14220, loss = 24.75 (38.1 examples/sec; 3.360 sec/batch)\n",
      "2017-09-29 08:37:07.342011: step 14230, loss = 22.57 (38.0 examples/sec; 3.372 sec/batch)\n",
      "2017-09-29 08:37:40.899786: step 14240, loss = 23.90 (38.1 examples/sec; 3.356 sec/batch)\n",
      "2017-09-29 08:38:14.573564: step 14250, loss = 27.77 (38.0 examples/sec; 3.367 sec/batch)\n",
      "2017-09-29 08:38:48.184976: step 14260, loss = 23.48 (38.1 examples/sec; 3.361 sec/batch)\n",
      "2017-09-29 08:39:21.856935: step 14270, loss = 25.27 (38.0 examples/sec; 3.367 sec/batch)\n",
      "2017-09-29 08:39:55.512790: step 14280, loss = 22.21 (38.0 examples/sec; 3.366 sec/batch)\n",
      "2017-09-29 08:40:29.082200: step 14290, loss = 23.42 (38.1 examples/sec; 3.357 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.297173\n",
      "2017-09-29 08:41:02.909255: step 14300, loss = 21.67 (37.8 examples/sec; 3.383 sec/batch)\n",
      "2017-09-29 08:41:36.535043: step 14310, loss = 22.33 (38.1 examples/sec; 3.363 sec/batch)\n",
      "2017-09-29 08:42:10.221784: step 14320, loss = 25.69 (38.0 examples/sec; 3.369 sec/batch)\n",
      "2017-09-29 08:42:43.768896: step 14330, loss = 22.01 (38.2 examples/sec; 3.355 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 14336 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-29 08:43:20.855749: step 14340, loss = 23.65 (34.5 examples/sec; 3.709 sec/batch)\n",
      "2017-09-29 08:43:54.436159: step 14350, loss = 20.93 (38.1 examples/sec; 3.358 sec/batch)\n",
      "2017-09-29 08:44:28.414877: step 14360, loss = 21.16 (37.7 examples/sec; 3.398 sec/batch)\n",
      "2017-09-29 08:45:02.288373: step 14370, loss = 24.23 (37.8 examples/sec; 3.387 sec/batch)\n",
      "2017-09-29 08:45:35.870965: step 14380, loss = 20.12 (38.1 examples/sec; 3.358 sec/batch)\n",
      "2017-09-29 08:46:09.811129: step 14390, loss = 22.25 (37.7 examples/sec; 3.394 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.293452\n",
      "2017-09-29 08:46:43.681912: step 14400, loss = 19.83 (37.8 examples/sec; 3.387 sec/batch)\n",
      "2017-09-29 08:47:17.555552: step 14410, loss = 20.42 (37.8 examples/sec; 3.387 sec/batch)\n",
      "2017-09-29 08:47:51.444245: step 14420, loss = 22.64 (37.8 examples/sec; 3.389 sec/batch)\n",
      "2017-09-29 08:48:25.526301: step 14430, loss = 20.30 (37.6 examples/sec; 3.408 sec/batch)\n",
      "2017-09-29 08:48:59.521954: step 14440, loss = 21.87 (37.7 examples/sec; 3.400 sec/batch)\n",
      "2017-09-29 08:49:33.313511: step 14450, loss = 19.02 (37.9 examples/sec; 3.379 sec/batch)\n",
      "2017-09-29 08:50:07.078387: step 14460, loss = 20.74 (37.9 examples/sec; 3.376 sec/batch)\n",
      "2017-09-29 08:50:40.810298: step 14470, loss = 18.49 (37.9 examples/sec; 3.373 sec/batch)\n",
      "2017-09-29 08:51:14.543778: step 14480, loss = 19.41 (37.9 examples/sec; 3.373 sec/batch)\n",
      "2017-09-29 08:51:48.047415: step 14490, loss = 21.95 (38.2 examples/sec; 3.350 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.295547\n",
      "2017-09-29 08:52:22.038351: step 14500, loss = 18.56 (37.7 examples/sec; 3.399 sec/batch)\n",
      "2017-09-29 08:52:55.641314: step 14510, loss = 20.20 (38.1 examples/sec; 3.360 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 14513 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-29 08:53:33.307808: step 14520, loss = 17.88 (34.0 examples/sec; 3.767 sec/batch)\n",
      "2017-09-29 08:54:06.743565: step 14530, loss = 19.43 (38.3 examples/sec; 3.344 sec/batch)\n",
      "2017-09-29 08:54:41.392064: step 14540, loss = 22.18 (36.9 examples/sec; 3.465 sec/batch)\n",
      "2017-09-29 08:55:16.391804: step 14550, loss = 18.57 (36.6 examples/sec; 3.500 sec/batch)\n",
      "2017-09-29 08:55:49.506472: step 14560, loss = 20.62 (38.7 examples/sec; 3.311 sec/batch)\n",
      "2017-09-29 08:56:22.426859: step 14570, loss = 18.18 (38.9 examples/sec; 3.292 sec/batch)\n",
      "2017-09-29 08:56:55.737376: step 14580, loss = 18.54 (38.4 examples/sec; 3.331 sec/batch)\n",
      "2017-09-29 08:57:28.124902: step 14590, loss = 16.86 (39.5 examples/sec; 3.239 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.29305\n",
      "2017-09-29 08:58:03.281149: step 14600, loss = 18.46 (36.4 examples/sec; 3.516 sec/batch)\n",
      "2017-09-29 08:58:38.433681: step 14610, loss = 19.58 (36.4 examples/sec; 3.515 sec/batch)\n",
      "2017-09-29 08:59:12.151823: step 14620, loss = 16.56 (38.0 examples/sec; 3.372 sec/batch)\n",
      "2017-09-29 08:59:45.861458: step 14630, loss = 18.05 (38.0 examples/sec; 3.371 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-09-29 09:00:19.615304: step 14640, loss = 16.17 (37.9 examples/sec; 3.375 sec/batch)\n",
      "2017-09-29 09:00:53.231383: step 14650, loss = 17.28 (38.1 examples/sec; 3.362 sec/batch)\n",
      "2017-09-29 09:01:26.670540: step 14660, loss = 21.92 (38.3 examples/sec; 3.344 sec/batch)\n",
      "2017-09-29 09:02:00.179158: step 14670, loss = 16.18 (38.2 examples/sec; 3.351 sec/batch)\n",
      "2017-09-29 09:02:33.768096: step 14680, loss = 17.80 (38.1 examples/sec; 3.359 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 14690 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-29 09:03:11.200765: step 14690, loss = 15.63 (34.2 examples/sec; 3.743 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.292526\n",
      "2017-09-29 09:03:45.128438: step 14700, loss = 17.57 (37.7 examples/sec; 3.393 sec/batch)\n",
      "2017-09-29 09:04:18.709153: step 14710, loss = 15.28 (38.1 examples/sec; 3.358 sec/batch)\n",
      "2017-09-29 09:04:52.229050: step 14720, loss = 15.32 (38.2 examples/sec; 3.352 sec/batch)\n",
      "2017-09-29 09:05:25.909379: step 14730, loss = 17.68 (38.0 examples/sec; 3.368 sec/batch)\n",
      "2017-09-29 09:05:59.441808: step 14740, loss = 14.96 (38.2 examples/sec; 3.353 sec/batch)\n",
      "2017-09-29 09:06:33.098081: step 14750, loss = 15.58 (38.0 examples/sec; 3.366 sec/batch)\n",
      "2017-09-29 09:07:06.869811: step 14760, loss = 14.63 (37.9 examples/sec; 3.377 sec/batch)\n",
      "2017-09-29 09:07:40.410690: step 14770, loss = 16.22 (38.2 examples/sec; 3.354 sec/batch)\n",
      "2017-09-29 09:08:14.198405: step 14780, loss = 19.42 (37.9 examples/sec; 3.379 sec/batch)\n",
      "2017-09-29 09:08:48.040818: step 14790, loss = 15.39 (37.8 examples/sec; 3.384 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.296886\n",
      "2017-09-29 09:09:21.961331: step 14800, loss = 17.38 (37.7 examples/sec; 3.392 sec/batch)\n",
      "2017-09-29 09:09:55.515745: step 14810, loss = 14.69 (38.1 examples/sec; 3.355 sec/batch)\n",
      "2017-09-29 09:10:29.467986: step 14820, loss = 15.81 (37.7 examples/sec; 3.395 sec/batch)\n",
      "2017-09-29 09:11:03.709020: step 14830, loss = 16.05 (37.4 examples/sec; 3.424 sec/batch)\n",
      "2017-09-29 09:11:38.092336: step 14840, loss = 14.78 (37.2 examples/sec; 3.438 sec/batch)\n",
      "2017-09-29 09:12:12.797474: step 14850, loss = 16.37 (36.9 examples/sec; 3.471 sec/batch)\n",
      "2017-09-29 09:12:47.306360: step 14860, loss = 13.72 (37.1 examples/sec; 3.451 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 14866 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-29 09:13:25.679132: step 14870, loss = 15.22 (33.4 examples/sec; 3.837 sec/batch)\n",
      "2017-09-29 09:13:59.881488: step 14880, loss = 13.31 (37.4 examples/sec; 3.420 sec/batch)\n",
      "2017-09-29 09:14:33.627006: step 14890, loss = 13.97 (37.9 examples/sec; 3.375 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.289137\n",
      "2017-09-29 09:15:07.815125: step 14900, loss = 17.14 (37.4 examples/sec; 3.419 sec/batch)\n",
      "2017-09-29 09:15:41.727336: step 14910, loss = 13.12 (37.7 examples/sec; 3.391 sec/batch)\n",
      "2017-09-29 09:16:15.444952: step 14920, loss = 15.06 (38.0 examples/sec; 3.372 sec/batch)\n",
      "2017-09-29 09:16:49.061276: step 14930, loss = 12.85 (38.1 examples/sec; 3.362 sec/batch)\n",
      "2017-09-29 09:17:22.849687: step 14940, loss = 14.14 (37.9 examples/sec; 3.379 sec/batch)\n",
      "2017-09-29 09:17:56.055210: step 14950, loss = 18.06 (38.5 examples/sec; 3.321 sec/batch)\n",
      "2017-09-29 09:18:29.133205: step 14960, loss = 13.29 (38.7 examples/sec; 3.308 sec/batch)\n",
      "2017-09-29 09:19:02.691472: step 14970, loss = 14.96 (38.1 examples/sec; 3.356 sec/batch)\n",
      "2017-09-29 09:19:36.452112: step 14980, loss = 12.75 (37.9 examples/sec; 3.376 sec/batch)\n",
      "2017-09-29 09:20:10.126552: step 14990, loss = 14.82 (38.0 examples/sec; 3.367 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.297293\n",
      "2017-09-29 09:20:44.181674: step 15000, loss = 12.49 (37.6 examples/sec; 3.406 sec/batch)\n",
      "2017-09-29 09:21:17.621180: step 15010, loss = 13.98 (38.3 examples/sec; 3.344 sec/batch)\n",
      "2017-09-29 09:21:51.181491: step 15020, loss = 16.28 (38.1 examples/sec; 3.356 sec/batch)\n",
      "2017-09-29 09:22:24.843571: step 15030, loss = 12.37 (38.0 examples/sec; 3.366 sec/batch)\n",
      "2017-09-29 09:22:58.573700: step 15040, loss = 11.99 (37.9 examples/sec; 3.373 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 15043 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-29 09:23:35.947064: step 15050, loss = 11.57 (34.2 examples/sec; 3.737 sec/batch)\n",
      "2017-09-29 09:24:09.520560: step 15060, loss = 13.10 (38.1 examples/sec; 3.357 sec/batch)\n",
      "2017-09-29 09:24:42.973848: step 15070, loss = 15.64 (38.3 examples/sec; 3.345 sec/batch)\n",
      "2017-09-29 09:25:16.492502: step 15080, loss = 11.49 (38.2 examples/sec; 3.352 sec/batch)\n",
      "2017-09-29 09:25:50.068850: step 15090, loss = 14.39 (38.1 examples/sec; 3.358 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.294196\n",
      "2017-09-29 09:26:24.092356: step 15100, loss = 11.83 (37.6 examples/sec; 3.402 sec/batch)\n",
      "2017-09-29 09:26:57.686667: step 15110, loss = 13.45 (38.1 examples/sec; 3.359 sec/batch)\n",
      "2017-09-29 09:27:31.170005: step 15120, loss = 11.62 (38.2 examples/sec; 3.348 sec/batch)\n",
      "2017-09-29 09:28:04.623349: step 15130, loss = 12.77 (38.3 examples/sec; 3.345 sec/batch)\n",
      "2017-09-29 09:28:38.422577: step 15140, loss = 14.58 (37.9 examples/sec; 3.380 sec/batch)\n",
      "2017-09-29 09:29:12.092413: step 15150, loss = 13.96 (38.0 examples/sec; 3.367 sec/batch)\n",
      "2017-09-29 09:29:45.821001: step 15160, loss = 14.42 (38.0 examples/sec; 3.373 sec/batch)\n",
      "2017-09-29 09:30:19.185840: step 15170, loss = 13.48 (38.4 examples/sec; 3.336 sec/batch)\n",
      "2017-09-29 09:30:52.435818: step 15180, loss = 14.39 (38.5 examples/sec; 3.325 sec/batch)\n",
      "2017-09-29 09:31:25.655280: step 15190, loss = 15.09 (38.5 examples/sec; 3.322 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.298085\n",
      "2017-09-29 09:31:59.558891: step 15200, loss = 14.01 (37.8 examples/sec; 3.390 sec/batch)\n",
      "2017-09-29 09:32:33.136794: step 15210, loss = 14.63 (38.1 examples/sec; 3.358 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 15221 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-29 09:33:10.453783: step 15220, loss = 13.59 (34.3 examples/sec; 3.732 sec/batch)\n",
      "2017-09-29 09:33:43.861051: step 15230, loss = 13.67 (38.3 examples/sec; 3.341 sec/batch)\n",
      "2017-09-29 09:34:17.540539: step 15240, loss = 13.45 (38.0 examples/sec; 3.368 sec/batch)\n",
      "2017-09-29 09:34:51.072651: step 15250, loss = 13.75 (38.2 examples/sec; 3.353 sec/batch)\n",
      "2017-09-29 09:35:24.828003: step 15260, loss = 14.34 (37.9 examples/sec; 3.376 sec/batch)\n",
      "2017-09-29 09:35:58.363844: step 15270, loss = 13.29 (38.2 examples/sec; 3.354 sec/batch)\n",
      "2017-09-29 09:36:31.824143: step 15280, loss = 13.70 (38.3 examples/sec; 3.346 sec/batch)\n",
      "2017-09-29 09:37:05.147077: step 15290, loss = 12.71 (38.4 examples/sec; 3.332 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.294662\n",
      "2017-09-29 09:37:38.930293: step 15300, loss = 13.71 (37.9 examples/sec; 3.378 sec/batch)\n",
      "2017-09-29 09:38:12.632508: step 15310, loss = 14.34 (38.0 examples/sec; 3.370 sec/batch)\n",
      "2017-09-29 09:38:46.220295: step 15320, loss = 13.26 (38.1 examples/sec; 3.359 sec/batch)\n",
      "2017-09-29 09:39:19.602402: step 15330, loss = 13.72 (38.3 examples/sec; 3.338 sec/batch)\n",
      "2017-09-29 09:39:53.071136: step 15340, loss = 12.68 (38.2 examples/sec; 3.347 sec/batch)\n",
      "2017-09-29 09:40:26.676042: step 15350, loss = 13.52 (38.1 examples/sec; 3.360 sec/batch)\n",
      "2017-09-29 09:41:00.459684: step 15360, loss = 13.47 (37.9 examples/sec; 3.378 sec/batch)\n",
      "2017-09-29 09:41:38.236937: step 15370, loss = 12.77 (33.9 examples/sec; 3.778 sec/batch)\n",
      "2017-09-29 09:42:17.062068: step 15380, loss = 13.66 (33.0 examples/sec; 3.883 sec/batch)\n",
      "2017-09-29 09:42:54.050859: step 15390, loss = 12.60 (34.6 examples/sec; 3.699 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 15395 into /tmp/phd08_train/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.281323\n",
      "2017-09-29 09:43:34.394857: step 15400, loss = 12.50 (31.7 examples/sec; 4.034 sec/batch)\n",
      "2017-09-29 09:44:10.718149: step 15410, loss = 11.56 (35.2 examples/sec; 3.632 sec/batch)\n",
      "2017-09-29 09:44:49.441076: step 15420, loss = 12.30 (33.1 examples/sec; 3.872 sec/batch)\n",
      "2017-09-29 09:45:27.813687: step 15430, loss = 12.47 (33.4 examples/sec; 3.837 sec/batch)\n",
      "2017-09-29 09:46:04.666372: step 15440, loss = 11.49 (34.7 examples/sec; 3.685 sec/batch)\n",
      "2017-09-29 09:46:42.325984: step 15450, loss = 12.01 (34.0 examples/sec; 3.766 sec/batch)\n",
      "2017-09-29 09:47:26.753020: step 15460, loss = 11.08 (28.8 examples/sec; 4.443 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-09-29 09:48:04.529582: step 15470, loss = 12.33 (33.9 examples/sec; 3.778 sec/batch)\n",
      "2017-09-29 09:48:51.521492: step 15480, loss = 13.35 (27.2 examples/sec; 4.699 sec/batch)\n",
      "2017-09-29 09:49:29.137735: step 15490, loss = 12.26 (34.0 examples/sec; 3.762 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.255137\n",
      "2017-09-29 09:50:06.344970: step 15500, loss = 12.10 (34.4 examples/sec; 3.721 sec/batch)\n",
      "2017-09-29 09:50:43.166769: step 15510, loss = 11.10 (34.8 examples/sec; 3.682 sec/batch)\n",
      "2017-09-29 09:51:20.537908: step 15520, loss = 11.65 (34.3 examples/sec; 3.737 sec/batch)\n",
      "2017-09-29 09:51:58.269255: step 15530, loss = 10.70 (33.9 examples/sec; 3.773 sec/batch)\n",
      "2017-09-29 09:52:35.221546: step 15540, loss = 11.43 (34.6 examples/sec; 3.695 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 15550 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-29 09:53:17.740604: step 15550, loss = 12.24 (30.1 examples/sec; 4.252 sec/batch)\n",
      "2017-09-29 09:53:57.007851: step 15560, loss = 11.19 (32.6 examples/sec; 3.927 sec/batch)\n",
      "2017-09-29 09:54:32.891154: step 15570, loss = 11.82 (35.7 examples/sec; 3.588 sec/batch)\n",
      "2017-09-29 09:55:10.007746: step 15580, loss = 10.81 (34.5 examples/sec; 3.712 sec/batch)\n",
      "2017-09-29 09:55:46.565982: step 15590, loss = 11.68 (35.0 examples/sec; 3.656 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.266145\n",
      "2017-09-29 09:56:22.076608: step 15600, loss = 12.05 (36.0 examples/sec; 3.551 sec/batch)\n",
      "2017-09-29 09:57:03.582788: step 15610, loss = 11.01 (30.8 examples/sec; 4.151 sec/batch)\n",
      "2017-09-29 09:57:44.981636: step 15620, loss = 12.00 (30.9 examples/sec; 4.140 sec/batch)\n",
      "2017-09-29 09:58:21.446586: step 15630, loss = 10.95 (35.1 examples/sec; 3.646 sec/batch)\n",
      "2017-09-29 09:59:06.985422: step 15640, loss = 11.22 (28.1 examples/sec; 4.554 sec/batch)\n",
      "2017-09-29 09:59:43.677207: step 15650, loss = 10.59 (34.9 examples/sec; 3.669 sec/batch)\n",
      "2017-09-29 10:00:19.551805: step 15660, loss = 10.54 (35.7 examples/sec; 3.587 sec/batch)\n",
      "2017-09-29 10:00:55.407270: step 15670, loss = 11.32 (35.7 examples/sec; 3.586 sec/batch)\n",
      "2017-09-29 10:01:31.313833: step 15680, loss = 10.30 (35.6 examples/sec; 3.591 sec/batch)\n",
      "2017-09-29 10:02:05.967765: step 15690, loss = 11.01 (36.9 examples/sec; 3.465 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.264494\n",
      "2017-09-29 10:02:40.160162: step 15700, loss = 10.01 (37.4 examples/sec; 3.419 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 15710 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-29 10:03:18.383445: step 15710, loss = 10.68 (33.5 examples/sec; 3.822 sec/batch)\n",
      "2017-09-29 10:03:52.424004: step 15720, loss = 10.57 (37.6 examples/sec; 3.404 sec/batch)\n",
      "2017-09-29 10:04:33.955606: step 15730, loss = 9.61 (30.8 examples/sec; 4.153 sec/batch)\n",
      "2017-09-29 10:05:08.735704: step 15740, loss = 10.33 (36.8 examples/sec; 3.478 sec/batch)\n",
      "2017-09-29 10:05:45.540596: step 15750, loss = 9.37 (34.8 examples/sec; 3.680 sec/batch)\n",
      "2017-09-29 10:06:20.404407: step 15760, loss = 10.19 (36.7 examples/sec; 3.486 sec/batch)\n",
      "2017-09-29 10:06:55.415487: step 15770, loss = 10.15 (36.6 examples/sec; 3.501 sec/batch)\n",
      "2017-09-29 10:07:30.313835: step 15780, loss = 9.60 (36.7 examples/sec; 3.490 sec/batch)\n",
      "2017-09-29 10:08:05.963957: step 15790, loss = 10.37 (35.9 examples/sec; 3.565 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.277096\n",
      "2017-09-29 10:08:41.044179: step 15800, loss = 9.37 (36.5 examples/sec; 3.508 sec/batch)\n",
      "2017-09-29 10:09:16.693655: step 15810, loss = 10.34 (35.9 examples/sec; 3.565 sec/batch)\n",
      "2017-09-29 10:10:01.620194: step 15820, loss = 9.33 (28.5 examples/sec; 4.493 sec/batch)\n",
      "2017-09-29 10:10:37.281423: step 15830, loss = 9.93 (35.9 examples/sec; 3.566 sec/batch)\n",
      "2017-09-29 10:11:13.142231: step 15840, loss = 10.19 (35.7 examples/sec; 3.586 sec/batch)\n",
      "2017-09-29 10:11:49.712297: step 15850, loss = 9.18 (35.0 examples/sec; 3.657 sec/batch)\n",
      "2017-09-29 10:12:24.880956: step 15860, loss = 10.16 (36.4 examples/sec; 3.517 sec/batch)\n",
      "2017-09-29 10:13:00.748109: step 15870, loss = 9.15 (35.7 examples/sec; 3.587 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 15874 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-29 10:13:41.637552: step 15880, loss = 9.68 (31.3 examples/sec; 4.089 sec/batch)\n",
      "2017-09-29 10:14:15.770744: step 15890, loss = 9.91 (37.5 examples/sec; 3.413 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.27038\n",
      "2017-09-29 10:14:50.893297: step 15900, loss = 8.91 (36.4 examples/sec; 3.512 sec/batch)\n",
      "2017-09-29 10:15:25.702770: step 15910, loss = 9.78 (36.8 examples/sec; 3.481 sec/batch)\n",
      "2017-09-29 10:16:00.169312: step 15920, loss = 8.78 (37.1 examples/sec; 3.447 sec/batch)\n",
      "2017-09-29 10:16:34.745901: step 15930, loss = 9.82 (37.0 examples/sec; 3.458 sec/batch)\n",
      "2017-09-29 10:17:09.889993: step 15940, loss = 8.81 (36.4 examples/sec; 3.514 sec/batch)\n",
      "2017-09-29 10:17:44.750917: step 15950, loss = 9.25 (36.7 examples/sec; 3.486 sec/batch)\n",
      "2017-09-29 10:18:20.010642: step 15960, loss = 9.63 (36.3 examples/sec; 3.526 sec/batch)\n",
      "2017-09-29 10:18:55.943023: step 15970, loss = 8.63 (35.6 examples/sec; 3.593 sec/batch)\n",
      "2017-09-29 10:19:33.889689: step 15980, loss = 9.89 (33.7 examples/sec; 3.795 sec/batch)\n",
      "2017-09-29 10:20:09.515872: step 15990, loss = 8.86 (35.9 examples/sec; 3.563 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.282314\n",
      "2017-09-29 10:20:45.108737: step 16000, loss = 8.91 (36.0 examples/sec; 3.559 sec/batch)\n",
      "2017-09-29 10:21:18.679070: step 16010, loss = 9.85 (38.1 examples/sec; 3.357 sec/batch)\n",
      "2017-09-29 10:21:54.079651: step 16020, loss = 8.81 (36.2 examples/sec; 3.540 sec/batch)\n",
      "2017-09-29 10:22:32.071658: step 16030, loss = 9.65 (33.7 examples/sec; 3.799 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 16042 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-29 10:23:14.753482: step 16040, loss = 8.62 (30.0 examples/sec; 4.268 sec/batch)\n",
      "2017-09-29 10:23:51.537426: step 16050, loss = 8.85 (34.8 examples/sec; 3.678 sec/batch)\n",
      "2017-09-29 10:24:27.813995: step 16060, loss = 8.10 (35.3 examples/sec; 3.628 sec/batch)\n",
      "2017-09-29 10:25:05.945285: step 16070, loss = 7.94 (33.6 examples/sec; 3.813 sec/batch)\n",
      "2017-09-29 10:25:42.864518: step 16080, loss = 8.22 (34.7 examples/sec; 3.692 sec/batch)\n",
      "2017-09-29 10:26:17.962640: step 16090, loss = 7.34 (36.5 examples/sec; 3.510 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.271394\n",
      "2017-09-29 10:26:53.576692: step 16100, loss = 8.18 (35.9 examples/sec; 3.561 sec/batch)\n",
      "2017-09-29 10:27:30.194515: step 16110, loss = 7.27 (35.0 examples/sec; 3.662 sec/batch)\n",
      "2017-09-29 10:28:06.533428: step 16120, loss = 8.52 (35.2 examples/sec; 3.634 sec/batch)\n",
      "2017-09-29 10:28:44.062488: step 16130, loss = 8.77 (34.1 examples/sec; 3.753 sec/batch)\n",
      "2017-09-29 10:29:18.096304: step 16140, loss = 7.77 (37.6 examples/sec; 3.403 sec/batch)\n",
      "2017-09-29 10:29:53.456522: step 16150, loss = 8.78 (36.2 examples/sec; 3.536 sec/batch)\n",
      "2017-09-29 10:30:28.700840: step 16160, loss = 7.77 (36.3 examples/sec; 3.524 sec/batch)\n",
      "2017-09-29 10:31:04.897657: step 16170, loss = 7.82 (35.4 examples/sec; 3.620 sec/batch)\n",
      "2017-09-29 10:31:39.659961: step 16180, loss = 8.35 (36.8 examples/sec; 3.476 sec/batch)\n",
      "2017-09-29 10:32:15.255055: step 16190, loss = 8.20 (36.0 examples/sec; 3.560 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.279469\n",
      "2017-09-29 10:32:51.399406: step 16200, loss = 8.77 (35.4 examples/sec; 3.614 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 16208 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-29 10:33:32.434144: step 16210, loss = 7.75 (31.2 examples/sec; 4.103 sec/batch)\n",
      "2017-09-29 10:34:06.992141: step 16220, loss = 8.47 (37.0 examples/sec; 3.456 sec/batch)\n",
      "2017-09-29 10:34:41.165097: step 16230, loss = 7.47 (37.5 examples/sec; 3.417 sec/batch)\n",
      "2017-09-29 10:35:16.093378: step 16240, loss = 8.02 (36.6 examples/sec; 3.493 sec/batch)\n",
      "2017-09-29 10:35:50.614641: step 16250, loss = 8.72 (37.1 examples/sec; 3.452 sec/batch)\n",
      "2017-09-29 10:36:25.276794: step 16260, loss = 7.69 (36.9 examples/sec; 3.466 sec/batch)\n",
      "2017-09-29 10:36:59.630732: step 16270, loss = 8.11 (37.3 examples/sec; 3.435 sec/batch)\n",
      "2017-09-29 10:37:31.935595: step 16280, loss = 7.14 (39.6 examples/sec; 3.230 sec/batch)\n",
      "2017-09-29 10:38:07.579377: step 16290, loss = 7.94 (35.9 examples/sec; 3.564 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.284053\n",
      "2017-09-29 10:38:43.446618: step 16300, loss = 8.48 (35.7 examples/sec; 3.587 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-09-29 10:39:18.595304: step 16310, loss = 7.46 (36.4 examples/sec; 3.515 sec/batch)\n",
      "2017-09-29 10:39:54.204955: step 16320, loss = 7.86 (35.9 examples/sec; 3.561 sec/batch)\n",
      "2017-09-29 10:40:30.615761: step 16330, loss = 6.90 (35.2 examples/sec; 3.641 sec/batch)\n",
      "2017-09-29 10:41:08.124858: step 16340, loss = 8.00 (34.1 examples/sec; 3.751 sec/batch)\n",
      "2017-09-29 10:41:44.848378: step 16350, loss = 7.01 (34.9 examples/sec; 3.672 sec/batch)\n",
      "2017-09-29 10:42:22.196347: step 16360, loss = 7.61 (34.3 examples/sec; 3.735 sec/batch)\n",
      "2017-09-29 10:43:00.361895: step 16370, loss = 8.06 (33.5 examples/sec; 3.817 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 16376 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-29 10:43:41.165565: step 16380, loss = 7.06 (31.4 examples/sec; 4.080 sec/batch)\n",
      "2017-09-29 10:44:17.130023: step 16390, loss = 7.88 (35.6 examples/sec; 3.596 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.269671\n",
      "2017-09-29 10:44:54.267705: step 16400, loss = 6.89 (34.5 examples/sec; 3.714 sec/batch)\n",
      "2017-09-29 10:45:30.907279: step 16410, loss = 6.04 (34.9 examples/sec; 3.664 sec/batch)\n",
      "2017-09-29 10:46:06.610408: step 16420, loss = 7.18 (35.9 examples/sec; 3.570 sec/batch)\n",
      "2017-09-29 10:46:41.555326: step 16430, loss = 6.22 (36.6 examples/sec; 3.494 sec/batch)\n",
      "2017-09-29 10:47:16.788897: step 16440, loss = 7.24 (36.3 examples/sec; 3.523 sec/batch)\n",
      "2017-09-29 10:47:51.111249: step 16450, loss = 6.27 (37.3 examples/sec; 3.432 sec/batch)\n",
      "2017-09-29 10:48:25.660209: step 16460, loss = 7.32 (37.0 examples/sec; 3.455 sec/batch)\n",
      "2017-09-29 10:48:59.999443: step 16470, loss = 6.56 (37.3 examples/sec; 3.434 sec/batch)\n",
      "2017-09-29 10:49:34.775067: step 16480, loss = 6.82 (36.8 examples/sec; 3.478 sec/batch)\n",
      "2017-09-29 10:50:09.120804: step 16490, loss = 7.42 (37.3 examples/sec; 3.435 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.286354\n",
      "2017-09-29 10:50:43.486098: step 16500, loss = 6.43 (37.2 examples/sec; 3.437 sec/batch)\n",
      "2017-09-29 10:51:16.729061: step 16510, loss = 6.85 (38.5 examples/sec; 3.324 sec/batch)\n",
      "2017-09-29 10:51:50.825593: step 16520, loss = 5.93 (37.5 examples/sec; 3.410 sec/batch)\n",
      "2017-09-29 10:52:25.851515: step 16530, loss = 6.92 (36.5 examples/sec; 3.503 sec/batch)\n",
      "2017-09-29 10:53:00.462773: step 16540, loss = 7.70 (37.0 examples/sec; 3.461 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 16547 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-29 10:53:38.669681: step 16550, loss = 6.68 (33.5 examples/sec; 3.821 sec/batch)\n",
      "2017-09-29 10:54:13.196537: step 16560, loss = 6.99 (37.1 examples/sec; 3.453 sec/batch)\n",
      "2017-09-29 10:54:47.264485: step 16570, loss = 6.04 (37.6 examples/sec; 3.407 sec/batch)\n",
      "2017-09-29 10:55:21.580160: step 16580, loss = 6.49 (37.3 examples/sec; 3.432 sec/batch)\n",
      "2017-09-29 10:55:55.796852: step 16590, loss = 6.65 (37.4 examples/sec; 3.422 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.288134\n",
      "2017-09-29 10:56:30.544311: step 16600, loss = 6.51 (36.8 examples/sec; 3.475 sec/batch)\n",
      "2017-09-29 10:57:04.649941: step 16610, loss = 7.39 (37.5 examples/sec; 3.411 sec/batch)\n",
      "2017-09-29 10:57:35.007553: step 16620, loss = 6.37 (42.2 examples/sec; 3.036 sec/batch)\n",
      "2017-09-29 10:58:12.029924: step 16630, loss = 6.70 (34.6 examples/sec; 3.702 sec/batch)\n",
      "2017-09-29 10:58:48.180684: step 16640, loss = 5.76 (35.4 examples/sec; 3.615 sec/batch)\n",
      "2017-09-29 10:59:22.525827: step 16650, loss = 6.80 (37.3 examples/sec; 3.435 sec/batch)\n",
      "2017-09-29 10:59:57.197967: step 16660, loss = 7.54 (36.9 examples/sec; 3.467 sec/batch)\n",
      "2017-09-29 11:00:31.579642: step 16670, loss = 6.51 (37.2 examples/sec; 3.438 sec/batch)\n",
      "2017-09-29 11:01:05.644819: step 16680, loss = 7.21 (37.6 examples/sec; 3.407 sec/batch)\n",
      "2017-09-29 11:01:40.111362: step 16690, loss = 6.20 (37.1 examples/sec; 3.447 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.290639\n",
      "2017-09-29 11:02:14.613759: step 16700, loss = 6.81 (37.1 examples/sec; 3.450 sec/batch)\n",
      "2017-09-29 11:02:48.835348: step 16710, loss = 7.37 (37.4 examples/sec; 3.422 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 16721 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-29 11:03:26.491313: step 16720, loss = 6.43 (34.0 examples/sec; 3.766 sec/batch)\n",
      "2017-09-29 11:04:01.149157: step 16730, loss = 7.03 (36.9 examples/sec; 3.466 sec/batch)\n",
      "2017-09-29 11:04:36.611082: step 16740, loss = 6.03 (36.1 examples/sec; 3.546 sec/batch)\n",
      "2017-09-29 11:05:10.405628: step 16750, loss = 6.01 (37.9 examples/sec; 3.379 sec/batch)\n",
      "2017-09-29 11:05:44.784291: step 16760, loss = 5.13 (37.2 examples/sec; 3.438 sec/batch)\n",
      "2017-09-29 11:06:19.793240: step 16770, loss = 5.65 (36.6 examples/sec; 3.501 sec/batch)\n",
      "2017-09-29 11:06:54.390875: step 16780, loss = 6.32 (37.0 examples/sec; 3.460 sec/batch)\n",
      "2017-09-29 11:07:28.383941: step 16790, loss = 5.37 (37.7 examples/sec; 3.399 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.286844\n",
      "2017-09-29 11:08:03.238159: step 16800, loss = 5.74 (36.7 examples/sec; 3.485 sec/batch)\n",
      "2017-09-29 11:08:37.518657: step 16810, loss = 4.88 (37.3 examples/sec; 3.428 sec/batch)\n",
      "2017-09-29 11:09:13.812777: step 16820, loss = 6.20 (35.3 examples/sec; 3.629 sec/batch)\n",
      "2017-09-29 11:09:47.742906: step 16830, loss = 6.48 (37.7 examples/sec; 3.393 sec/batch)\n",
      "2017-09-29 11:10:26.984139: step 16840, loss = 5.49 (32.6 examples/sec; 3.924 sec/batch)\n",
      "2017-09-29 11:11:05.765203: step 16850, loss = 6.54 (33.0 examples/sec; 3.878 sec/batch)\n",
      "2017-09-29 11:11:46.883485: step 16860, loss = 5.55 (31.1 examples/sec; 4.112 sec/batch)\n",
      "2017-09-29 11:12:25.566124: step 16870, loss = 6.26 (33.1 examples/sec; 3.868 sec/batch)\n",
      "2017-09-29 11:13:06.134787: step 16880, loss = 5.40 (31.6 examples/sec; 4.057 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 16886 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-29 11:14:00.996818: step 16890, loss = 5.55 (23.3 examples/sec; 5.486 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.24654\n",
      "2017-09-29 11:14:48.865685: step 16900, loss = 6.53 (26.7 examples/sec; 4.787 sec/batch)\n",
      "2017-09-29 11:15:28.201525: step 16910, loss = 5.53 (32.5 examples/sec; 3.934 sec/batch)\n",
      "2017-09-29 11:16:05.503359: step 16920, loss = 6.33 (34.3 examples/sec; 3.730 sec/batch)\n",
      "2017-09-29 11:16:39.619235: step 16930, loss = 5.35 (37.5 examples/sec; 3.412 sec/batch)\n",
      "2017-09-29 11:17:13.838642: step 16940, loss = 5.70 (37.4 examples/sec; 3.422 sec/batch)\n",
      "2017-09-29 11:17:50.532100: step 16950, loss = 6.39 (34.9 examples/sec; 3.669 sec/batch)\n",
      "2017-09-29 11:18:27.713465: step 16960, loss = 5.40 (34.4 examples/sec; 3.718 sec/batch)\n",
      "2017-09-29 11:19:04.861378: step 16970, loss = 5.92 (34.5 examples/sec; 3.715 sec/batch)\n",
      "2017-09-29 11:19:43.386081: step 16980, loss = 4.97 (33.2 examples/sec; 3.852 sec/batch)\n",
      "2017-09-29 11:20:24.166756: step 16990, loss = 5.78 (31.4 examples/sec; 4.078 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.262797\n",
      "2017-09-29 11:21:09.405772: step 17000, loss = 5.81 (28.3 examples/sec; 4.524 sec/batch)\n",
      "2017-09-29 11:21:48.257747: step 17010, loss = 5.82 (32.9 examples/sec; 3.885 sec/batch)\n",
      "2017-09-29 11:22:30.059526: step 17020, loss = 6.29 (30.6 examples/sec; 4.180 sec/batch)\n",
      "2017-09-29 11:23:11.566102: step 17030, loss = 5.30 (30.8 examples/sec; 4.151 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 17035 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-29 11:23:56.772661: step 17040, loss = 5.97 (28.3 examples/sec; 4.521 sec/batch)\n",
      "2017-09-29 11:24:36.783162: step 17050, loss = 5.01 (32.0 examples/sec; 4.001 sec/batch)\n",
      "2017-09-29 11:25:17.698953: step 17060, loss = 5.82 (31.3 examples/sec; 4.092 sec/batch)\n",
      "2017-09-29 11:25:58.669698: step 17070, loss = 6.48 (31.2 examples/sec; 4.097 sec/batch)\n",
      "2017-09-29 11:26:37.457760: step 17080, loss = 5.46 (33.0 examples/sec; 3.879 sec/batch)\n",
      "2017-09-29 11:27:15.838293: step 17090, loss = 4.93 (33.4 examples/sec; 3.838 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.246496\n",
      "2017-09-29 11:27:55.058890: step 17100, loss = 4.12 (32.6 examples/sec; 3.922 sec/batch)\n",
      "2017-09-29 11:28:33.185599: step 17110, loss = 5.40 (33.6 examples/sec; 3.813 sec/batch)\n",
      "2017-09-29 11:29:11.069539: step 17120, loss = 5.70 (33.8 examples/sec; 3.788 sec/batch)\n",
      "2017-09-29 11:29:50.050308: step 17130, loss = 4.88 (32.8 examples/sec; 3.898 sec/batch)\n",
      "2017-09-29 11:30:32.175948: step 17140, loss = 5.36 (30.4 examples/sec; 4.213 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-09-29 11:31:20.511258: step 17150, loss = 4.44 (26.5 examples/sec; 4.834 sec/batch)\n",
      "2017-09-29 11:32:05.606350: step 17160, loss = 5.07 (28.4 examples/sec; 4.510 sec/batch)\n",
      "2017-09-29 11:32:46.548521: step 17170, loss = 4.19 (31.3 examples/sec; 4.094 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 17182 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-29 11:33:31.392135: step 17180, loss = 5.23 (28.5 examples/sec; 4.484 sec/batch)\n",
      "2017-09-29 11:34:11.736399: step 17190, loss = 5.65 (31.7 examples/sec; 4.034 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.235173\n",
      "2017-09-29 11:35:00.277066: step 17200, loss = 4.68 (26.4 examples/sec; 4.854 sec/batch)\n",
      "2017-09-29 11:35:40.928931: step 17210, loss = 5.22 (31.5 examples/sec; 4.065 sec/batch)\n",
      "2017-09-29 11:36:19.901695: step 17220, loss = 4.30 (32.8 examples/sec; 3.897 sec/batch)\n",
      "2017-09-29 11:36:57.240695: step 17230, loss = 5.50 (34.3 examples/sec; 3.734 sec/batch)\n",
      "2017-09-29 11:37:34.444420: step 17240, loss = 5.96 (34.4 examples/sec; 3.720 sec/batch)\n",
      "2017-09-29 11:38:13.014092: step 17250, loss = 4.96 (33.2 examples/sec; 3.857 sec/batch)\n",
      "2017-09-29 11:38:52.163295: step 17260, loss = 5.84 (32.7 examples/sec; 3.915 sec/batch)\n",
      "2017-09-29 11:39:30.758856: step 17270, loss = 4.85 (33.2 examples/sec; 3.860 sec/batch)\n",
      "2017-09-29 11:40:08.883028: step 17280, loss = 5.59 (33.6 examples/sec; 3.812 sec/batch)\n",
      "2017-09-29 11:40:48.504747: step 17290, loss = 4.66 (32.3 examples/sec; 3.962 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.257887\n",
      "2017-09-29 11:41:28.046205: step 17300, loss = 4.95 (32.4 examples/sec; 3.954 sec/batch)\n",
      "2017-09-29 11:42:06.042138: step 17310, loss = 5.77 (33.7 examples/sec; 3.800 sec/batch)\n",
      "2017-09-29 11:42:44.558300: step 17320, loss = 4.78 (33.2 examples/sec; 3.852 sec/batch)\n",
      "2017-09-29 11:43:23.206796: step 17330, loss = 5.56 (33.1 examples/sec; 3.865 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 17333 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-29 11:44:05.961865: step 17340, loss = 4.59 (29.9 examples/sec; 4.276 sec/batch)\n",
      "2017-09-29 11:44:44.086920: step 17350, loss = 4.90 (33.6 examples/sec; 3.813 sec/batch)\n",
      "2017-09-29 11:45:22.965569: step 17360, loss = 6.00 (32.9 examples/sec; 3.888 sec/batch)\n",
      "2017-09-29 11:46:02.219589: step 17370, loss = 4.99 (32.6 examples/sec; 3.925 sec/batch)\n",
      "2017-09-29 11:46:40.290870: step 17380, loss = 5.29 (33.6 examples/sec; 3.807 sec/batch)\n",
      "2017-09-29 11:47:19.267625: step 17390, loss = 4.33 (32.8 examples/sec; 3.898 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.256373\n",
      "2017-09-29 11:47:58.106241: step 17400, loss = 5.37 (33.0 examples/sec; 3.884 sec/batch)\n",
      "2017-09-29 11:48:38.785122: step 17410, loss = 4.96 (31.5 examples/sec; 4.068 sec/batch)\n",
      "2017-09-29 11:49:20.113009: step 17420, loss = 4.77 (31.0 examples/sec; 4.133 sec/batch)\n",
      "2017-09-29 11:50:00.760304: step 17430, loss = 4.13 (31.5 examples/sec; 4.065 sec/batch)\n",
      "2017-09-29 11:50:42.392932: step 17440, loss = 3.37 (30.7 examples/sec; 4.163 sec/batch)\n",
      "2017-09-29 11:51:30.720170: step 17450, loss = 4.60 (26.5 examples/sec; 4.833 sec/batch)\n",
      "2017-09-29 11:52:28.226777: step 17460, loss = 3.70 (22.3 examples/sec; 5.751 sec/batch)\n",
      "2017-09-29 11:53:12.944268: step 17470, loss = 4.55 (28.6 examples/sec; 4.472 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 17476 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-29 11:53:55.535596: step 17480, loss = 5.05 (30.1 examples/sec; 4.259 sec/batch)\n",
      "2017-09-29 11:54:34.823505: step 17490, loss = 4.09 (32.6 examples/sec; 3.929 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.228823\n",
      "2017-09-29 11:55:15.123452: step 17500, loss = 5.27 (31.8 examples/sec; 4.030 sec/batch)\n",
      "2017-09-29 11:55:53.898334: step 17510, loss = 4.28 (33.0 examples/sec; 3.877 sec/batch)\n",
      "2017-09-29 11:56:32.131202: step 17520, loss = 4.27 (33.5 examples/sec; 3.823 sec/batch)\n",
      "2017-09-29 11:57:13.320300: step 17530, loss = 5.25 (31.1 examples/sec; 4.119 sec/batch)\n",
      "2017-09-29 11:57:52.062083: step 17540, loss = 4.62 (33.0 examples/sec; 3.874 sec/batch)\n",
      "2017-09-29 11:58:29.776381: step 17550, loss = 4.57 (33.9 examples/sec; 3.771 sec/batch)\n",
      "2017-09-29 11:59:08.342777: step 17560, loss = 3.67 (33.2 examples/sec; 3.857 sec/batch)\n",
      "2017-09-29 11:59:48.775225: step 17570, loss = 4.99 (31.7 examples/sec; 4.043 sec/batch)\n",
      "2017-09-29 12:00:28.646036: step 17580, loss = 4.03 (32.1 examples/sec; 3.987 sec/batch)\n",
      "2017-09-29 12:01:08.512095: step 17590, loss = 4.81 (32.1 examples/sec; 3.987 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.253752\n",
      "2017-09-29 12:01:49.207385: step 17600, loss = 5.07 (31.5 examples/sec; 4.070 sec/batch)\n",
      "2017-09-29 12:02:28.252367: step 17610, loss = 4.10 (32.8 examples/sec; 3.904 sec/batch)\n",
      "2017-09-29 12:03:06.712706: step 17620, loss = 4.76 (33.3 examples/sec; 3.846 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 17628 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-29 12:03:52.114802: step 17630, loss = 3.82 (28.2 examples/sec; 4.540 sec/batch)\n",
      "2017-09-29 12:04:33.191401: step 17640, loss = 4.82 (31.2 examples/sec; 4.108 sec/batch)\n",
      "2017-09-29 12:05:14.707793: step 17650, loss = 5.33 (30.8 examples/sec; 4.152 sec/batch)\n",
      "2017-09-29 12:05:56.999988: step 17660, loss = 4.33 (30.3 examples/sec; 4.229 sec/batch)\n",
      "2017-09-29 12:06:36.705288: step 17670, loss = 5.27 (32.2 examples/sec; 3.971 sec/batch)\n",
      "2017-09-29 12:07:18.272745: step 17680, loss = 4.28 (30.8 examples/sec; 4.157 sec/batch)\n",
      "2017-09-29 12:07:55.485570: step 17690, loss = 5.07 (34.4 examples/sec; 3.721 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.249434\n",
      "2017-09-29 12:08:30.115667: step 17700, loss = 4.10 (37.0 examples/sec; 3.463 sec/batch)\n",
      "2017-09-29 12:09:04.230025: step 17710, loss = 4.56 (37.5 examples/sec; 3.411 sec/batch)\n",
      "2017-09-29 12:09:38.626728: step 17720, loss = 5.26 (37.2 examples/sec; 3.440 sec/batch)\n",
      "2017-09-29 12:10:15.516089: step 17730, loss = 4.27 (34.7 examples/sec; 3.689 sec/batch)\n",
      "2017-09-29 12:10:52.797587: step 17740, loss = 4.98 (34.3 examples/sec; 3.728 sec/batch)\n",
      "2017-09-29 12:11:30.283497: step 17750, loss = 4.01 (34.1 examples/sec; 3.749 sec/batch)\n",
      "2017-09-29 12:12:04.829532: step 17760, loss = 4.78 (37.1 examples/sec; 3.455 sec/batch)\n",
      "2017-09-29 12:12:40.916699: step 17770, loss = 4.86 (35.5 examples/sec; 3.609 sec/batch)\n",
      "2017-09-29 12:13:20.085094: step 17780, loss = 3.92 (32.7 examples/sec; 3.917 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 17784 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-29 12:14:23.504107: step 17790, loss = 4.46 (20.2 examples/sec; 6.342 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.243309\n",
      "2017-09-29 12:15:21.137247: step 17800, loss = 3.54 (22.2 examples/sec; 5.763 sec/batch)\n",
      "2017-09-29 12:16:13.408877: step 17810, loss = 4.21 (24.5 examples/sec; 5.227 sec/batch)\n",
      "2017-09-29 12:17:05.542216: step 17820, loss = 3.71 (24.6 examples/sec; 5.213 sec/batch)\n",
      "2017-09-29 12:17:57.478552: step 17830, loss = 3.53 (24.6 examples/sec; 5.194 sec/batch)\n",
      "2017-09-29 12:18:49.321172: step 17840, loss = 4.78 (24.7 examples/sec; 5.184 sec/batch)\n",
      "2017-09-29 12:19:41.281648: step 17850, loss = 3.80 (24.6 examples/sec; 5.196 sec/batch)\n",
      "2017-09-29 12:20:33.163786: step 17860, loss = 4.35 (24.7 examples/sec; 5.188 sec/batch)\n",
      "2017-09-29 12:21:25.576140: step 17870, loss = 3.43 (24.4 examples/sec; 5.241 sec/batch)\n",
      "2017-09-29 12:22:17.572535: step 17880, loss = 4.40 (24.6 examples/sec; 5.200 sec/batch)\n",
      "2017-09-29 12:23:09.467793: step 17890, loss = 4.88 (24.7 examples/sec; 5.190 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 17896 into /tmp/phd08_train/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.188328\n",
      "2017-09-29 12:24:12.102818: step 17900, loss = 3.90 (20.4 examples/sec; 6.264 sec/batch)\n",
      "2017-09-29 12:25:03.992488: step 17910, loss = 4.53 (24.7 examples/sec; 5.189 sec/batch)\n",
      "2017-09-29 12:25:56.029700: step 17920, loss = 3.58 (24.6 examples/sec; 5.204 sec/batch)\n",
      "2017-09-29 12:26:48.189709: step 17930, loss = 4.20 (24.5 examples/sec; 5.216 sec/batch)\n",
      "2017-09-29 12:27:40.554295: step 17940, loss = 4.77 (24.4 examples/sec; 5.236 sec/batch)\n",
      "2017-09-29 12:28:32.004386: step 17950, loss = 4.23 (24.9 examples/sec; 5.145 sec/batch)\n",
      "2017-09-29 12:29:23.642142: step 17960, loss = 4.98 (24.8 examples/sec; 5.164 sec/batch)\n",
      "2017-09-29 12:30:14.576539: step 17970, loss = 3.99 (25.1 examples/sec; 5.093 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-09-29 12:31:06.570847: step 17980, loss = 4.35 (24.6 examples/sec; 5.199 sec/batch)\n",
      "2017-09-29 12:31:59.014567: step 17990, loss = 3.42 (24.4 examples/sec; 5.244 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.192538\n",
      "2017-09-29 12:32:51.502051: step 18000, loss = 3.94 (24.4 examples/sec; 5.249 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 18010 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-29 12:33:51.659454: step 18010, loss = 5.07 (21.3 examples/sec; 6.016 sec/batch)\n",
      "2017-09-29 12:34:44.201043: step 18020, loss = 4.07 (24.4 examples/sec; 5.254 sec/batch)\n",
      "2017-09-29 12:35:36.319482: step 18030, loss = 4.47 (24.6 examples/sec; 5.212 sec/batch)\n",
      "2017-09-29 12:36:28.411704: step 18040, loss = 3.52 (24.6 examples/sec; 5.209 sec/batch)\n",
      "2017-09-29 12:37:19.901206: step 18050, loss = 4.28 (24.9 examples/sec; 5.149 sec/batch)\n",
      "2017-09-29 12:38:12.275758: step 18060, loss = 5.04 (24.4 examples/sec; 5.237 sec/batch)\n",
      "2017-09-29 12:39:04.258293: step 18070, loss = 4.04 (24.6 examples/sec; 5.198 sec/batch)\n",
      "2017-09-29 12:39:55.760146: step 18080, loss = 4.57 (24.9 examples/sec; 5.150 sec/batch)\n",
      "2017-09-29 12:40:47.385448: step 18090, loss = 3.61 (24.8 examples/sec; 5.163 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.189359\n",
      "2017-09-29 12:41:39.618753: step 18100, loss = 4.68 (24.5 examples/sec; 5.223 sec/batch)\n",
      "2017-09-29 12:42:31.731640: step 18110, loss = 3.71 (24.6 examples/sec; 5.211 sec/batch)\n",
      "2017-09-29 12:43:24.465954: step 18120, loss = 3.76 (24.3 examples/sec; 5.273 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 18124 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-29 12:44:25.489544: step 18130, loss = 4.40 (21.0 examples/sec; 6.102 sec/batch)\n",
      "2017-09-29 12:45:17.510905: step 18140, loss = 3.45 (24.6 examples/sec; 5.202 sec/batch)\n",
      "2017-09-29 12:46:09.503562: step 18150, loss = 3.79 (24.6 examples/sec; 5.199 sec/batch)\n",
      "2017-09-29 12:47:01.323108: step 18160, loss = 2.93 (24.7 examples/sec; 5.182 sec/batch)\n",
      "2017-09-29 12:47:53.379923: step 18170, loss = 3.79 (24.6 examples/sec; 5.206 sec/batch)\n",
      "2017-09-29 12:48:45.370635: step 18180, loss = 4.84 (24.6 examples/sec; 5.199 sec/batch)\n",
      "2017-09-29 12:49:37.260829: step 18190, loss = 3.83 (24.7 examples/sec; 5.189 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.18852\n",
      "2017-09-29 12:50:30.028897: step 18200, loss = 4.00 (24.3 examples/sec; 5.277 sec/batch)\n",
      "2017-09-29 12:51:22.524774: step 18210, loss = 3.09 (24.4 examples/sec; 5.250 sec/batch)\n",
      "2017-09-29 12:52:14.706438: step 18220, loss = 4.00 (24.5 examples/sec; 5.218 sec/batch)\n",
      "2017-09-29 12:53:06.905210: step 18230, loss = 3.47 (24.5 examples/sec; 5.220 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 18238 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-29 12:54:11.611833: step 18240, loss = 3.45 (19.8 examples/sec; 6.471 sec/batch)\n",
      "2017-09-29 12:55:07.860299: step 18250, loss = 4.84 (22.8 examples/sec; 5.625 sec/batch)\n",
      "2017-09-29 12:56:03.295382: step 18260, loss = 3.83 (23.1 examples/sec; 5.544 sec/batch)\n",
      "2017-09-29 12:56:56.116907: step 18270, loss = 4.24 (24.2 examples/sec; 5.282 sec/batch)\n",
      "2017-09-29 12:57:49.039012: step 18280, loss = 3.29 (24.2 examples/sec; 5.292 sec/batch)\n",
      "2017-09-29 12:58:43.677135: step 18290, loss = 4.05 (23.4 examples/sec; 5.464 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.182388\n",
      "2017-09-29 12:59:38.338829: step 18300, loss = 4.64 (23.4 examples/sec; 5.466 sec/batch)\n",
      "2017-09-29 13:00:30.839025: step 18310, loss = 3.66 (24.4 examples/sec; 5.250 sec/batch)\n",
      "2017-09-29 13:01:23.348579: step 18320, loss = 4.51 (24.4 examples/sec; 5.251 sec/batch)\n",
      "2017-09-29 13:02:15.918041: step 18330, loss = 3.53 (24.3 examples/sec; 5.257 sec/batch)\n",
      "2017-09-29 13:03:09.620967: step 18340, loss = 3.81 (23.8 examples/sec; 5.370 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 18348 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-29 13:04:11.637528: step 18350, loss = 4.10 (20.6 examples/sec; 6.202 sec/batch)\n",
      "2017-09-29 13:05:05.124047: step 18360, loss = 3.64 (23.9 examples/sec; 5.349 sec/batch)\n",
      "2017-09-29 13:05:58.197424: step 18370, loss = 4.24 (24.1 examples/sec; 5.307 sec/batch)\n",
      "2017-09-29 13:06:50.300124: step 18380, loss = 3.29 (24.6 examples/sec; 5.210 sec/batch)\n",
      "2017-09-29 13:07:42.474748: step 18390, loss = 4.07 (24.5 examples/sec; 5.217 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.18647\n",
      "2017-09-29 13:08:34.622629: step 18400, loss = 3.13 (24.5 examples/sec; 5.215 sec/batch)\n",
      "2017-09-29 13:09:26.739268: step 18410, loss = 3.93 (24.6 examples/sec; 5.212 sec/batch)\n",
      "2017-09-29 13:10:19.153211: step 18420, loss = 4.88 (24.4 examples/sec; 5.241 sec/batch)\n",
      "2017-09-29 13:11:11.705056: step 18430, loss = 3.87 (24.4 examples/sec; 5.255 sec/batch)\n",
      "2017-09-29 13:12:03.386020: step 18440, loss = 4.56 (24.8 examples/sec; 5.168 sec/batch)\n",
      "2017-09-29 13:12:55.108169: step 18450, loss = 3.58 (24.7 examples/sec; 5.172 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 18461 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-29 13:13:56.279470: step 18460, loss = 3.01 (20.9 examples/sec; 6.117 sec/batch)\n",
      "2017-09-29 13:14:49.086267: step 18470, loss = 4.56 (24.2 examples/sec; 5.281 sec/batch)\n",
      "2017-09-29 13:15:49.324525: step 18480, loss = 3.55 (21.2 examples/sec; 6.024 sec/batch)\n",
      "2017-09-29 13:16:39.931519: step 18490, loss = 3.35 (25.3 examples/sec; 5.061 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.185199\n",
      "2017-09-29 13:17:34.583184: step 18500, loss = 2.52 (23.4 examples/sec; 5.465 sec/batch)\n",
      "2017-09-29 13:18:26.754537: step 18510, loss = 3.87 (24.5 examples/sec; 5.217 sec/batch)\n",
      "2017-09-29 13:19:19.146226: step 18520, loss = 2.94 (24.4 examples/sec; 5.239 sec/batch)\n",
      "2017-09-29 13:20:11.498942: step 18530, loss = 3.09 (24.4 examples/sec; 5.235 sec/batch)\n",
      "2017-09-29 13:21:03.740378: step 18540, loss = 3.87 (24.5 examples/sec; 5.224 sec/batch)\n",
      "2017-09-29 13:21:56.449605: step 18550, loss = 2.93 (24.3 examples/sec; 5.271 sec/batch)\n",
      "2017-09-29 13:22:49.315921: step 18560, loss = 3.62 (24.2 examples/sec; 5.287 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 18572 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-29 13:23:50.926256: step 18570, loss = 2.72 (20.8 examples/sec; 6.161 sec/batch)\n",
      "2017-09-29 13:24:41.797987: step 18580, loss = 3.77 (25.2 examples/sec; 5.087 sec/batch)\n",
      "2017-09-29 13:25:34.367250: step 18590, loss = 4.69 (24.3 examples/sec; 5.257 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.187255\n",
      "2017-09-29 13:26:28.591731: step 18600, loss = 3.67 (23.6 examples/sec; 5.422 sec/batch)\n",
      "2017-09-29 13:27:21.257474: step 18610, loss = 4.37 (24.3 examples/sec; 5.267 sec/batch)\n",
      "2017-09-29 13:28:13.534378: step 18620, loss = 3.39 (24.5 examples/sec; 5.228 sec/batch)\n",
      "2017-09-29 13:29:05.843074: step 18630, loss = 4.17 (24.5 examples/sec; 5.231 sec/batch)\n",
      "2017-09-29 13:29:57.454802: step 18640, loss = 3.52 (24.8 examples/sec; 5.161 sec/batch)\n",
      "2017-09-29 13:30:49.467697: step 18650, loss = 3.59 (24.6 examples/sec; 5.201 sec/batch)\n",
      "2017-09-29 13:31:42.186225: step 18660, loss = 4.40 (24.3 examples/sec; 5.272 sec/batch)\n",
      "2017-09-29 13:32:39.926460: step 18670, loss = 3.42 (22.2 examples/sec; 5.774 sec/batch)\n",
      "2017-09-29 13:33:35.044259: step 18680, loss = 4.05 (23.2 examples/sec; 5.512 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 18684 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-29 13:34:35.824728: step 18690, loss = 3.11 (21.1 examples/sec; 6.078 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.18638\n",
      "2017-09-29 13:35:25.148212: step 18700, loss = 3.90 (26.0 examples/sec; 4.932 sec/batch)\n",
      "2017-09-29 13:36:23.293844: step 18710, loss = 4.26 (22.0 examples/sec; 5.815 sec/batch)\n",
      "2017-09-29 13:37:15.591019: step 18720, loss = 3.29 (24.5 examples/sec; 5.230 sec/batch)\n",
      "2017-09-29 13:38:07.898047: step 18730, loss = 4.23 (24.5 examples/sec; 5.231 sec/batch)\n",
      "2017-09-29 13:39:00.109984: step 18740, loss = 3.26 (24.5 examples/sec; 5.221 sec/batch)\n",
      "2017-09-29 13:39:52.456790: step 18750, loss = 3.95 (24.5 examples/sec; 5.235 sec/batch)\n",
      "2017-09-29 13:40:45.752393: step 18760, loss = 4.18 (24.0 examples/sec; 5.330 sec/batch)\n",
      "2017-09-29 13:41:38.894409: step 18770, loss = 3.86 (24.1 examples/sec; 5.314 sec/batch)\n",
      "2017-09-29 13:42:31.903004: step 18780, loss = 4.33 (24.1 examples/sec; 5.301 sec/batch)\n",
      "2017-09-29 13:43:25.943701: step 18790, loss = 3.35 (23.7 examples/sec; 5.404 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 18796 into /tmp/phd08_train/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.183334\n",
      "2017-09-29 13:44:30.584353: step 18800, loss = 3.57 (19.8 examples/sec; 6.464 sec/batch)\n",
      "2017-09-29 13:45:24.739300: step 18810, loss = 2.68 (23.6 examples/sec; 5.415 sec/batch)\n",
      "2017-09-29 13:46:19.884432: step 18820, loss = 3.05 (23.2 examples/sec; 5.515 sec/batch)\n",
      "2017-09-29 13:47:12.569247: step 18830, loss = 4.04 (24.3 examples/sec; 5.268 sec/batch)\n",
      "2017-09-29 13:48:04.736419: step 18840, loss = 3.08 (24.5 examples/sec; 5.217 sec/batch)\n",
      "2017-09-29 13:48:56.587131: step 18850, loss = 3.27 (24.7 examples/sec; 5.185 sec/batch)\n",
      "2017-09-29 13:49:48.990342: step 18860, loss = 2.43 (24.4 examples/sec; 5.240 sec/batch)\n",
      "2017-09-29 13:50:42.375351: step 18870, loss = 3.17 (24.0 examples/sec; 5.339 sec/batch)\n",
      "2017-09-29 13:51:35.057827: step 18880, loss = 4.36 (24.3 examples/sec; 5.268 sec/batch)\n",
      "2017-09-29 13:52:27.734714: step 18890, loss = 3.35 (24.3 examples/sec; 5.268 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.187505\n",
      "2017-09-29 13:53:23.913249: step 18900, loss = 3.67 (22.8 examples/sec; 5.618 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 18907 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-29 13:54:25.651089: step 18910, loss = 2.74 (20.7 examples/sec; 6.174 sec/batch)\n",
      "2017-09-29 13:55:18.158442: step 18920, loss = 4.05 (24.4 examples/sec; 5.251 sec/batch)\n",
      "2017-09-29 13:56:14.945384: step 18930, loss = 3.08 (22.5 examples/sec; 5.679 sec/batch)\n",
      "2017-09-29 13:57:07.341337: step 18940, loss = 3.41 (24.4 examples/sec; 5.240 sec/batch)\n",
      "2017-09-29 13:57:59.651284: step 18950, loss = 4.04 (24.5 examples/sec; 5.231 sec/batch)\n",
      "2017-09-29 13:58:51.882850: step 18960, loss = 3.08 (24.5 examples/sec; 5.223 sec/batch)\n",
      "2017-09-29 13:59:44.637774: step 18970, loss = 4.12 (24.3 examples/sec; 5.275 sec/batch)\n",
      "2017-09-29 14:00:36.611916: step 18980, loss = 3.15 (24.6 examples/sec; 5.197 sec/batch)\n",
      "2017-09-29 14:01:28.589659: step 18990, loss = 3.72 (24.6 examples/sec; 5.198 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.186233\n",
      "2017-09-29 14:02:20.889689: step 19000, loss = 4.58 (24.5 examples/sec; 5.230 sec/batch)\n",
      "2017-09-29 14:03:12.971877: step 19010, loss = 3.58 (24.6 examples/sec; 5.208 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 19020 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-29 14:04:15.568524: step 19020, loss = 3.80 (20.4 examples/sec; 6.260 sec/batch)\n",
      "2017-09-29 14:05:06.330032: step 19030, loss = 2.87 (25.2 examples/sec; 5.076 sec/batch)\n",
      "2017-09-29 14:06:01.277031: step 19040, loss = 3.92 (23.3 examples/sec; 5.495 sec/batch)\n",
      "2017-09-29 14:06:55.048467: step 19050, loss = 3.25 (23.8 examples/sec; 5.377 sec/batch)\n",
      "2017-09-29 14:07:48.355247: step 19060, loss = 3.61 (24.0 examples/sec; 5.331 sec/batch)\n",
      "2017-09-29 14:08:40.440449: step 19070, loss = 4.17 (24.6 examples/sec; 5.209 sec/batch)\n",
      "2017-09-29 14:09:32.659732: step 19080, loss = 3.19 (24.5 examples/sec; 5.222 sec/batch)\n",
      "2017-09-29 14:10:24.639355: step 19090, loss = 3.68 (24.6 examples/sec; 5.198 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.186289\n",
      "2017-09-29 14:11:17.681075: step 19100, loss = 2.76 (24.1 examples/sec; 5.304 sec/batch)\n",
      "2017-09-29 14:12:09.442435: step 19110, loss = 3.77 (24.7 examples/sec; 5.176 sec/batch)\n",
      "2017-09-29 14:13:01.467004: step 19120, loss = 4.49 (24.6 examples/sec; 5.202 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 19132 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-29 14:14:03.940298: step 19130, loss = 3.49 (20.5 examples/sec; 6.247 sec/batch)\n",
      "2017-09-29 14:14:55.883341: step 19140, loss = 3.54 (24.6 examples/sec; 5.194 sec/batch)\n",
      "2017-09-29 14:15:55.826952: step 19150, loss = 2.63 (21.4 examples/sec; 5.994 sec/batch)\n",
      "2017-09-29 14:16:47.764693: step 19160, loss = 3.45 (24.6 examples/sec; 5.194 sec/batch)\n",
      "2017-09-29 14:17:39.999218: step 19170, loss = 3.40 (24.5 examples/sec; 5.223 sec/batch)\n",
      "2017-09-29 14:18:32.237975: step 19180, loss = 3.09 (24.5 examples/sec; 5.224 sec/batch)\n",
      "2017-09-29 14:19:23.590848: step 19190, loss = 3.84 (24.9 examples/sec; 5.135 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.185796\n",
      "2017-09-29 14:20:15.913356: step 19200, loss = 2.89 (24.5 examples/sec; 5.232 sec/batch)\n",
      "2017-09-29 14:21:07.985647: step 19210, loss = 3.72 (24.6 examples/sec; 5.207 sec/batch)\n",
      "2017-09-29 14:22:00.085495: step 19220, loss = 2.78 (24.6 examples/sec; 5.210 sec/batch)\n",
      "2017-09-29 14:22:51.917209: step 19230, loss = 3.36 (24.7 examples/sec; 5.183 sec/batch)\n",
      "2017-09-29 14:23:43.934126: step 19240, loss = 3.72 (24.6 examples/sec; 5.202 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 19245 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-29 14:24:44.399825: step 19250, loss = 2.78 (21.2 examples/sec; 6.047 sec/batch)\n",
      "2017-09-29 14:25:36.439259: step 19260, loss = 0.49 (24.6 examples/sec; 5.204 sec/batch)\n",
      "2017-09-29 14:26:26.025101: step 19270, loss = 0.49 (25.8 examples/sec; 4.959 sec/batch)\n",
      "2017-09-29 14:27:15.930445: step 19280, loss = 0.48 (25.6 examples/sec; 4.991 sec/batch)\n",
      "2017-09-29 14:28:07.579501: step 19290, loss = 256.74 (24.8 examples/sec; 5.165 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.19058\n",
      "2017-09-29 14:29:00.599772: step 19300, loss = 6.35 (24.1 examples/sec; 5.302 sec/batch)\n",
      "2017-09-29 14:29:52.433823: step 19310, loss = 6.96 (24.7 examples/sec; 5.183 sec/batch)\n",
      "2017-09-29 14:30:44.242894: step 19320, loss = 6.02 (24.7 examples/sec; 5.181 sec/batch)\n",
      "2017-09-29 14:31:36.368054: step 19330, loss = 7.15 (24.6 examples/sec; 5.213 sec/batch)\n",
      "2017-09-29 14:32:28.415031: step 19340, loss = 6.17 (24.6 examples/sec; 5.205 sec/batch)\n",
      "2017-09-29 14:33:20.573378: step 19350, loss = 6.72 (24.5 examples/sec; 5.216 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 19360 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-29 14:34:21.164961: step 19360, loss = 7.41 (21.1 examples/sec; 6.059 sec/batch)\n",
      "2017-09-29 14:35:13.379277: step 19370, loss = 6.41 (24.5 examples/sec; 5.221 sec/batch)\n",
      "2017-09-29 14:36:05.581263: step 19380, loss = 7.14 (24.5 examples/sec; 5.220 sec/batch)\n",
      "2017-09-29 14:36:57.855691: step 19390, loss = 6.16 (24.5 examples/sec; 5.227 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.19052\n",
      "2017-09-29 14:37:45.470513: step 19400, loss = 6.79 (26.9 examples/sec; 4.761 sec/batch)\n",
      "2017-09-29 14:38:21.391962: step 19410, loss = 7.34 (35.6 examples/sec; 3.592 sec/batch)\n",
      "2017-09-29 14:38:57.898647: step 19420, loss = 6.33 (35.1 examples/sec; 3.651 sec/batch)\n",
      "2017-09-29 14:39:31.719872: step 19430, loss = 7.42 (37.8 examples/sec; 3.382 sec/batch)\n",
      "2017-09-29 14:40:05.568022: step 19440, loss = 6.40 (37.8 examples/sec; 3.385 sec/batch)\n",
      "2017-09-29 14:40:39.862080: step 19450, loss = 6.86 (37.3 examples/sec; 3.429 sec/batch)\n",
      "2017-09-29 14:41:14.421756: step 19460, loss = 6.04 (37.0 examples/sec; 3.456 sec/batch)\n",
      "2017-09-29 14:41:48.441039: step 19470, loss = 6.25 (37.6 examples/sec; 3.402 sec/batch)\n",
      "2017-09-29 14:42:22.267999: step 19480, loss = 6.17 (37.8 examples/sec; 3.383 sec/batch)\n",
      "2017-09-29 14:42:55.906074: step 19490, loss = 5.28 (38.1 examples/sec; 3.364 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.29017\n",
      "2017-09-29 14:43:30.096453: step 19500, loss = 6.57 (37.4 examples/sec; 3.419 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 19512 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-29 14:44:07.791731: step 19510, loss = 5.61 (34.0 examples/sec; 3.770 sec/batch)\n",
      "2017-09-29 14:44:41.366033: step 19520, loss = 6.24 (38.1 examples/sec; 3.357 sec/batch)\n",
      "2017-09-29 14:45:14.792935: step 19530, loss = 6.58 (38.3 examples/sec; 3.343 sec/batch)\n",
      "2017-09-29 14:45:48.542131: step 19540, loss = 5.61 (37.9 examples/sec; 3.375 sec/batch)\n",
      "2017-09-29 14:46:22.260940: step 19550, loss = 6.62 (38.0 examples/sec; 3.372 sec/batch)\n",
      "2017-09-29 14:46:55.867129: step 19560, loss = 5.64 (38.1 examples/sec; 3.361 sec/batch)\n",
      "2017-09-29 14:47:29.562367: step 19570, loss = 5.83 (38.0 examples/sec; 3.370 sec/batch)\n",
      "2017-09-29 14:48:03.189497: step 19580, loss = 5.69 (38.1 examples/sec; 3.363 sec/batch)\n",
      "2017-09-29 14:48:37.655242: step 19590, loss = 5.46 (37.1 examples/sec; 3.447 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.292236\n",
      "2017-09-29 14:49:12.297926: step 19600, loss = 6.48 (36.9 examples/sec; 3.464 sec/batch)\n",
      "2017-09-29 14:49:49.158662: step 19610, loss = 5.49 (34.7 examples/sec; 3.686 sec/batch)\n",
      "2017-09-29 14:50:26.759840: step 19620, loss = 6.38 (34.0 examples/sec; 3.760 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-09-29 14:51:00.478855: step 19630, loss = 5.40 (38.0 examples/sec; 3.372 sec/batch)\n",
      "2017-09-29 14:51:34.252279: step 19640, loss = 5.47 (37.9 examples/sec; 3.377 sec/batch)\n",
      "2017-09-29 14:52:07.777421: step 19650, loss = 6.49 (38.2 examples/sec; 3.353 sec/batch)\n",
      "2017-09-29 14:52:41.649675: step 19660, loss = 5.50 (37.8 examples/sec; 3.387 sec/batch)\n",
      "2017-09-29 14:53:15.439755: step 19670, loss = 6.32 (37.9 examples/sec; 3.379 sec/batch)\n",
      "2017-09-29 14:53:49.277095: step 19680, loss = 5.34 (37.8 examples/sec; 3.384 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 19687 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-29 14:54:26.716475: step 19690, loss = 5.82 (34.2 examples/sec; 3.744 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.286925\n",
      "2017-09-29 14:55:00.809162: step 19700, loss = 7.09 (37.5 examples/sec; 3.409 sec/batch)\n",
      "2017-09-29 14:55:34.509825: step 19710, loss = 6.25 (38.0 examples/sec; 3.370 sec/batch)\n",
      "2017-09-29 14:56:08.332469: step 19720, loss = 6.57 (37.8 examples/sec; 3.382 sec/batch)\n",
      "2017-09-29 14:56:42.114627: step 19730, loss = 5.57 (37.9 examples/sec; 3.378 sec/batch)\n",
      "2017-09-29 14:57:15.750318: step 19740, loss = 6.44 (38.1 examples/sec; 3.364 sec/batch)\n",
      "2017-09-29 14:57:49.345248: step 19750, loss = 5.45 (38.1 examples/sec; 3.359 sec/batch)\n",
      "2017-09-29 14:58:26.524679: step 19760, loss = 5.66 (34.4 examples/sec; 3.718 sec/batch)\n",
      "2017-09-29 14:59:03.666433: step 19770, loss = 6.47 (34.5 examples/sec; 3.714 sec/batch)\n",
      "2017-09-29 14:59:37.531986: step 19780, loss = 5.47 (37.8 examples/sec; 3.387 sec/batch)\n",
      "2017-09-29 15:00:11.148901: step 19790, loss = 6.22 (38.1 examples/sec; 3.362 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.290508\n",
      "2017-09-29 15:00:45.033225: step 19800, loss = 5.24 (37.8 examples/sec; 3.388 sec/batch)\n",
      "2017-09-29 15:01:18.846850: step 19810, loss = 5.98 (37.9 examples/sec; 3.381 sec/batch)\n",
      "2017-09-29 15:01:52.722980: step 19820, loss = 5.50 (37.8 examples/sec; 3.388 sec/batch)\n",
      "2017-09-29 15:02:26.531181: step 19830, loss = 4.60 (37.9 examples/sec; 3.381 sec/batch)\n",
      "2017-09-29 15:03:00.272773: step 19840, loss = 5.58 (37.9 examples/sec; 3.374 sec/batch)\n",
      "2017-09-29 15:03:34.894061: step 19850, loss = 4.65 (37.0 examples/sec; 3.462 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 19862 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-29 15:04:12.058164: step 19860, loss = 5.40 (34.4 examples/sec; 3.716 sec/batch)\n",
      "2017-09-29 15:04:45.615263: step 19870, loss = 4.57 (38.1 examples/sec; 3.356 sec/batch)\n",
      "2017-09-29 15:05:19.369578: step 19880, loss = 4.98 (37.9 examples/sec; 3.375 sec/batch)\n",
      "2017-09-29 15:05:53.213759: step 19890, loss = 5.39 (37.8 examples/sec; 3.384 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.29139\n",
      "2017-09-29 15:06:28.216877: step 19900, loss = 4.47 (36.6 examples/sec; 3.500 sec/batch)\n",
      "2017-09-29 15:07:02.057909: step 19910, loss = 5.50 (37.8 examples/sec; 3.384 sec/batch)\n",
      "2017-09-29 15:07:35.905755: step 19920, loss = 4.55 (37.8 examples/sec; 3.385 sec/batch)\n",
      "2017-09-29 15:08:09.916174: step 19930, loss = 5.12 (37.6 examples/sec; 3.401 sec/batch)\n",
      "2017-09-29 15:08:43.892900: step 19940, loss = 6.22 (37.7 examples/sec; 3.398 sec/batch)\n",
      "2017-09-29 15:09:17.641958: step 19950, loss = 5.20 (37.9 examples/sec; 3.375 sec/batch)\n",
      "2017-09-29 15:09:54.897000: step 19960, loss = 5.95 (34.4 examples/sec; 3.726 sec/batch)\n",
      "2017-09-29 15:10:31.167217: step 19970, loss = 4.95 (35.3 examples/sec; 3.627 sec/batch)\n",
      "2017-09-29 15:11:06.882675: step 19980, loss = 5.65 (35.8 examples/sec; 3.572 sec/batch)\n",
      "2017-09-29 15:11:43.938873: step 19990, loss = 5.37 (34.5 examples/sec; 3.706 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.282191\n",
      "2017-09-29 15:12:22.596673: step 20000, loss = 5.24 (33.1 examples/sec; 3.866 sec/batch)\n",
      "2017-09-29 15:12:59.000758: step 20010, loss = 5.86 (35.2 examples/sec; 3.640 sec/batch)\n",
      "2017-09-29 15:13:34.917991: step 20020, loss = 4.87 (35.6 examples/sec; 3.592 sec/batch)\n",
      "2017-09-29 15:14:08.200440: step 20030, loss = 5.38 (38.5 examples/sec; 3.328 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 20033 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-29 15:14:44.677499: step 20040, loss = 4.44 (35.1 examples/sec; 3.648 sec/batch)\n",
      "2017-09-29 15:15:21.655604: step 20050, loss = 4.92 (34.6 examples/sec; 3.698 sec/batch)\n",
      "2017-09-29 15:15:57.350808: step 20060, loss = 6.15 (35.9 examples/sec; 3.570 sec/batch)\n",
      "2017-09-29 15:16:39.770098: step 20070, loss = 5.13 (30.2 examples/sec; 4.242 sec/batch)\n",
      "2017-09-29 15:17:18.057265: step 20080, loss = 5.65 (33.4 examples/sec; 3.829 sec/batch)\n",
      "2017-09-29 15:17:57.314858: step 20090, loss = 4.68 (32.6 examples/sec; 3.926 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.269796\n",
      "2017-09-29 15:18:33.245465: step 20100, loss = 5.26 (35.6 examples/sec; 3.593 sec/batch)\n",
      "2017-09-29 15:19:08.466159: step 20110, loss = 5.80 (36.3 examples/sec; 3.522 sec/batch)\n",
      "2017-09-29 15:19:43.136841: step 20120, loss = 5.06 (36.9 examples/sec; 3.467 sec/batch)\n",
      "2017-09-29 15:20:18.681932: step 20130, loss = 5.47 (36.0 examples/sec; 3.555 sec/batch)\n",
      "2017-09-29 15:20:55.449019: step 20140, loss = 4.50 (34.8 examples/sec; 3.677 sec/batch)\n",
      "2017-09-29 15:21:32.692353: step 20150, loss = 5.24 (34.4 examples/sec; 3.724 sec/batch)\n",
      "2017-09-29 15:22:07.569640: step 20160, loss = 4.30 (36.7 examples/sec; 3.488 sec/batch)\n",
      "2017-09-29 15:22:42.456348: step 20170, loss = 4.38 (36.7 examples/sec; 3.489 sec/batch)\n",
      "2017-09-29 15:23:17.211967: step 20180, loss = 4.34 (36.8 examples/sec; 3.476 sec/batch)\n",
      "2017-09-29 15:23:51.837351: step 20190, loss = 3.54 (37.0 examples/sec; 3.463 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 20198 into /tmp/phd08_train/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.280073\n",
      "2017-09-29 15:24:30.286984: step 20200, loss = 5.15 (33.3 examples/sec; 3.845 sec/batch)\n",
      "2017-09-29 15:25:05.390313: step 20210, loss = 4.17 (36.5 examples/sec; 3.510 sec/batch)\n",
      "2017-09-29 15:25:40.582361: step 20220, loss = 4.41 (36.4 examples/sec; 3.519 sec/batch)\n",
      "2017-09-29 15:26:15.816438: step 20230, loss = 5.56 (36.3 examples/sec; 3.523 sec/batch)\n",
      "2017-09-29 15:26:50.412562: step 20240, loss = 4.54 (37.0 examples/sec; 3.460 sec/batch)\n",
      "2017-09-29 15:27:25.664935: step 20250, loss = 4.90 (36.3 examples/sec; 3.525 sec/batch)\n",
      "2017-09-29 15:28:00.907714: step 20260, loss = 3.97 (36.3 examples/sec; 3.524 sec/batch)\n",
      "2017-09-29 15:28:36.031909: step 20270, loss = 4.84 (36.4 examples/sec; 3.512 sec/batch)\n",
      "2017-09-29 15:29:13.397652: step 20280, loss = 3.91 (34.3 examples/sec; 3.737 sec/batch)\n",
      "2017-09-29 15:29:49.003746: step 20290, loss = 4.86 (35.9 examples/sec; 3.561 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.282501\n",
      "2017-09-29 15:30:24.274035: step 20300, loss = 5.17 (36.3 examples/sec; 3.527 sec/batch)\n",
      "2017-09-29 15:30:58.514392: step 20310, loss = 4.20 (37.4 examples/sec; 3.424 sec/batch)\n",
      "2017-09-29 15:31:33.510656: step 20320, loss = 4.74 (36.6 examples/sec; 3.500 sec/batch)\n",
      "2017-09-29 15:32:08.467837: step 20330, loss = 3.82 (36.6 examples/sec; 3.496 sec/batch)\n",
      "2017-09-29 15:32:42.177185: step 20340, loss = 4.86 (38.0 examples/sec; 3.371 sec/batch)\n",
      "2017-09-29 15:33:15.871317: step 20350, loss = 5.68 (38.0 examples/sec; 3.369 sec/batch)\n",
      "2017-09-29 15:33:49.710759: step 20360, loss = 4.66 (37.8 examples/sec; 3.384 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 20369 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-29 15:34:26.089508: step 20370, loss = 5.04 (35.2 examples/sec; 3.638 sec/batch)\n",
      "2017-09-29 15:34:58.162608: step 20380, loss = 4.08 (39.9 examples/sec; 3.207 sec/batch)\n",
      "2017-09-29 15:35:31.869878: step 20390, loss = 5.09 (38.0 examples/sec; 3.371 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.292915\n",
      "2017-09-29 15:36:05.662836: step 20400, loss = 4.69 (37.9 examples/sec; 3.379 sec/batch)\n",
      "2017-09-29 15:36:39.490009: step 20410, loss = 4.64 (37.8 examples/sec; 3.383 sec/batch)\n",
      "2017-09-29 15:37:13.008597: step 20420, loss = 5.04 (38.2 examples/sec; 3.352 sec/batch)\n",
      "2017-09-29 15:37:46.441354: step 20430, loss = 4.07 (38.3 examples/sec; 3.343 sec/batch)\n",
      "2017-09-29 15:38:19.940039: step 20440, loss = 5.10 (38.2 examples/sec; 3.350 sec/batch)\n",
      "2017-09-29 15:38:53.465665: step 20450, loss = 4.12 (38.2 examples/sec; 3.353 sec/batch)\n",
      "2017-09-29 15:39:27.207841: step 20460, loss = 4.75 (37.9 examples/sec; 3.374 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-09-29 15:40:00.760887: step 20470, loss = 5.54 (38.1 examples/sec; 3.355 sec/batch)\n",
      "2017-09-29 15:40:35.431866: step 20480, loss = 4.54 (36.9 examples/sec; 3.467 sec/batch)\n",
      "2017-09-29 15:41:07.802121: step 20490, loss = 4.78 (39.5 examples/sec; 3.237 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.29739\n",
      "2017-09-29 15:41:41.922390: step 20500, loss = 3.84 (37.5 examples/sec; 3.412 sec/batch)\n",
      "2017-09-29 15:42:15.599660: step 20510, loss = 3.06 (38.0 examples/sec; 3.368 sec/batch)\n",
      "2017-09-29 15:42:48.990005: step 20520, loss = 4.07 (38.3 examples/sec; 3.339 sec/batch)\n",
      "2017-09-29 15:43:22.626579: step 20530, loss = 3.53 (38.1 examples/sec; 3.364 sec/batch)\n",
      "2017-09-29 15:43:56.364944: step 20540, loss = 4.93 (37.9 examples/sec; 3.374 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 20548 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-29 15:44:33.254040: step 20550, loss = 3.92 (34.7 examples/sec; 3.689 sec/batch)\n",
      "2017-09-29 15:45:06.754688: step 20560, loss = 4.55 (38.2 examples/sec; 3.350 sec/batch)\n",
      "2017-09-29 15:45:40.439968: step 20570, loss = 3.60 (38.0 examples/sec; 3.369 sec/batch)\n",
      "2017-09-29 15:46:13.799842: step 20580, loss = 4.33 (38.4 examples/sec; 3.336 sec/batch)\n",
      "2017-09-29 15:46:47.351464: step 20590, loss = 5.14 (38.2 examples/sec; 3.355 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.294596\n",
      "2017-09-29 15:47:21.368907: step 20600, loss = 4.14 (37.6 examples/sec; 3.402 sec/batch)\n",
      "2017-09-29 15:47:54.985522: step 20610, loss = 4.21 (38.1 examples/sec; 3.362 sec/batch)\n",
      "2017-09-29 15:48:28.451807: step 20620, loss = 3.32 (38.2 examples/sec; 3.347 sec/batch)\n",
      "2017-09-29 15:49:02.141690: step 20630, loss = 4.19 (38.0 examples/sec; 3.369 sec/batch)\n",
      "2017-09-29 15:49:35.913044: step 20640, loss = 4.89 (37.9 examples/sec; 3.377 sec/batch)\n",
      "2017-09-29 15:50:09.438462: step 20650, loss = 3.90 (38.2 examples/sec; 3.353 sec/batch)\n",
      "2017-09-29 15:50:42.817378: step 20660, loss = 4.88 (38.3 examples/sec; 3.338 sec/batch)\n",
      "2017-09-29 15:51:16.404037: step 20670, loss = 3.89 (38.1 examples/sec; 3.359 sec/batch)\n",
      "2017-09-29 15:51:50.381695: step 20680, loss = 4.50 (37.7 examples/sec; 3.398 sec/batch)\n",
      "2017-09-29 15:52:23.851018: step 20690, loss = 3.56 (38.2 examples/sec; 3.347 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.297234\n",
      "2017-09-29 15:52:57.805188: step 20700, loss = 4.00 (37.7 examples/sec; 3.395 sec/batch)\n",
      "2017-09-29 15:53:31.379670: step 20710, loss = 4.87 (38.1 examples/sec; 3.357 sec/batch)\n",
      "2017-09-29 15:54:05.309160: step 20720, loss = 3.89 (37.7 examples/sec; 3.393 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 20726 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-29 15:54:42.029742: step 20730, loss = 4.85 (34.9 examples/sec; 3.672 sec/batch)\n",
      "2017-09-29 15:55:15.604071: step 20740, loss = 3.87 (38.1 examples/sec; 3.357 sec/batch)\n",
      "2017-09-29 15:55:48.638719: step 20750, loss = 4.34 (38.7 examples/sec; 3.303 sec/batch)\n",
      "2017-09-29 15:56:22.288590: step 20760, loss = 5.04 (38.0 examples/sec; 3.365 sec/batch)\n",
      "2017-09-29 15:56:56.068298: step 20770, loss = 4.05 (37.9 examples/sec; 3.378 sec/batch)\n",
      "2017-09-29 15:57:30.028151: step 20780, loss = 4.86 (37.7 examples/sec; 3.396 sec/batch)\n",
      "2017-09-29 15:58:03.741603: step 20790, loss = 3.88 (38.0 examples/sec; 3.371 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.294068\n",
      "2017-09-29 15:58:37.862428: step 20800, loss = 4.26 (37.5 examples/sec; 3.412 sec/batch)\n",
      "2017-09-29 15:59:11.565883: step 20810, loss = 3.98 (38.0 examples/sec; 3.370 sec/batch)\n",
      "2017-09-29 15:59:44.934467: step 20820, loss = 4.34 (38.4 examples/sec; 3.337 sec/batch)\n",
      "2017-09-29 16:00:18.576711: step 20830, loss = 4.92 (38.0 examples/sec; 3.364 sec/batch)\n",
      "2017-09-29 16:00:52.128729: step 20840, loss = 3.93 (38.1 examples/sec; 3.355 sec/batch)\n",
      "2017-09-29 16:01:25.784729: step 20850, loss = 3.27 (38.0 examples/sec; 3.366 sec/batch)\n",
      "2017-09-29 16:02:00.294347: step 20860, loss = 2.54 (37.1 examples/sec; 3.451 sec/batch)\n",
      "2017-09-29 16:02:34.527126: step 20870, loss = 3.74 (37.4 examples/sec; 3.423 sec/batch)\n",
      "2017-09-29 16:03:09.039034: step 20880, loss = 4.70 (37.1 examples/sec; 3.451 sec/batch)\n",
      "2017-09-29 16:03:43.531190: step 20890, loss = 3.71 (37.1 examples/sec; 3.449 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.293762\n",
      "2017-09-29 16:04:18.277582: step 20900, loss = 4.03 (36.8 examples/sec; 3.475 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 20903 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-29 16:04:56.931028: step 20910, loss = 3.12 (33.1 examples/sec; 3.865 sec/batch)\n",
      "2017-09-29 16:05:30.710329: step 20920, loss = 4.22 (37.9 examples/sec; 3.378 sec/batch)\n",
      "2017-09-29 16:06:04.986177: step 20930, loss = 4.28 (37.3 examples/sec; 3.428 sec/batch)\n",
      "2017-09-29 16:06:38.692010: step 20940, loss = 3.69 (38.0 examples/sec; 3.371 sec/batch)\n",
      "2017-09-29 16:07:12.533505: step 20950, loss = 4.19 (37.8 examples/sec; 3.384 sec/batch)\n",
      "2017-09-29 16:07:46.385940: step 20960, loss = 3.26 (37.8 examples/sec; 3.385 sec/batch)\n",
      "2017-09-29 16:08:20.105118: step 20970, loss = 3.70 (38.0 examples/sec; 3.372 sec/batch)\n",
      "2017-09-29 16:08:53.808617: step 20980, loss = 2.84 (38.0 examples/sec; 3.370 sec/batch)\n",
      "2017-09-29 16:09:27.403705: step 20990, loss = 4.13 (38.1 examples/sec; 3.360 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.291542\n",
      "2017-09-29 16:10:01.287558: step 21000, loss = 4.61 (37.8 examples/sec; 3.388 sec/batch)\n",
      "2017-09-29 16:10:34.699891: step 21010, loss = 3.62 (38.3 examples/sec; 3.341 sec/batch)\n",
      "2017-09-29 16:11:07.168996: step 21020, loss = 4.12 (39.4 examples/sec; 3.247 sec/batch)\n",
      "2017-09-29 16:11:40.787709: step 21030, loss = 3.19 (38.1 examples/sec; 3.362 sec/batch)\n",
      "2017-09-29 16:12:13.803024: step 21040, loss = 3.99 (38.8 examples/sec; 3.302 sec/batch)\n",
      "2017-09-29 16:12:47.056096: step 21050, loss = 4.62 (38.5 examples/sec; 3.325 sec/batch)\n",
      "2017-09-29 16:13:20.627043: step 21060, loss = 41.65 (38.1 examples/sec; 3.357 sec/batch)\n",
      "2017-09-29 16:13:54.134837: step 21070, loss = 4.19 (38.2 examples/sec; 3.351 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 21081 into /tmp/phd08_train/model.ckpt.\n",
      "2017-09-29 16:14:31.080298: step 21080, loss = 3.25 (34.6 examples/sec; 3.695 sec/batch)\n",
      "2017-09-29 16:15:04.580043: step 21090, loss = 4.30 (38.2 examples/sec; 3.350 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.296617\n",
      "2017-09-29 16:15:38.413392: step 21100, loss = 3.34 (37.8 examples/sec; 3.383 sec/batch)\n",
      "2017-09-29 16:16:12.035074: step 21110, loss = 4.13 (38.1 examples/sec; 3.362 sec/batch)\n",
      "2017-09-29 16:16:52.930182: step 21120, loss = 4.72 (31.3 examples/sec; 4.090 sec/batch)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "TOWER_NAME = 'tower'\n",
    "NUM_CLASSES = len(label_idx)\n",
    "\n",
    "\n",
    "def _activation_summary(x):\n",
    "    \"\"\"Helper to create summaries for activations.\n",
    "\n",
    "    Creates a summary that provides a histogram of activations.\n",
    "    Creates a summary that measures the sparsity of activations.\n",
    "\n",
    "    Args:\n",
    "      x: Tensor\n",
    "    Returns:\n",
    "      nothing\n",
    "    \"\"\"\n",
    "    # Remove 'tower_[0-9]/' from the name in case this is a multi-GPU training\n",
    "    # session. This helps the clarity of presentation on tensorboard.\n",
    "    tensor_name = re.sub('%s_[0-9]*/' % TOWER_NAME, '', x.op.name)\n",
    "    tf.summary.histogram(tensor_name + '/activations', x)\n",
    "    tf.summary.scalar(tensor_name + '/sparsity',\n",
    "                      tf.nn.zero_fraction(x))\n",
    "\n",
    "\n",
    "def _variable_on_cpu(name, shape, initializer):\n",
    "    \"\"\"Helper to create a Variable stored on CPU memory.\n",
    "\n",
    "    Args:\n",
    "      name: name of the variable\n",
    "      shape: list of ints\n",
    "      initializer: initializer for Variable\n",
    "\n",
    "    Returns:\n",
    "      Variable Tensor\n",
    "    \"\"\"\n",
    "    with tf.device('/cpu:0'):\n",
    "        dtype = tf.float32\n",
    "        var = tf.get_variable(name, shape, initializer=initializer, dtype=dtype)\n",
    "    return var\n",
    "\n",
    "\n",
    "def _variable_with_weight_decay(name, shape, stddev, wd):\n",
    "    \"\"\"Helper to create an initialized Variable with weight decay.\n",
    "\n",
    "    Note that the Variable is initialized with a truncated normal distribution.\n",
    "    A weight decay is added only if one is specified.\n",
    "\n",
    "    Args:\n",
    "      name: name of the variable\n",
    "      shape: list of ints\n",
    "      stddev: standard deviation of a truncated Gaussian\n",
    "      wd: add L2Loss weight decay multiplied by this float. If None, weight\n",
    "          decay is not added for this Variable.\n",
    "\n",
    "    Returns:\n",
    "      Variable Tensor\n",
    "    \"\"\"\n",
    "    dtype = tf.float32\n",
    "    var = _variable_on_cpu(\n",
    "        name,\n",
    "        shape,\n",
    "        tf.truncated_normal_initializer(stddev=stddev, dtype=dtype))\n",
    "    if wd is not None:\n",
    "        weight_decay = tf.multiply(tf.nn.l2_loss(var), wd, name='weight_loss')\n",
    "        tf.add_to_collection('losses', weight_decay)\n",
    "    return var\n",
    "\n",
    "\n",
    "NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN = 50000\n",
    "NUM_EXAMPLES_PER_EPOCH_FOR_EVAL = 10000\n",
    "\n",
    "# Constants describing the training process.\n",
    "MOVING_AVERAGE_DECAY = 0.9999     # The decay to use for the moving average.\n",
    "NUM_EPOCHS_PER_DECAY = 350.0      # Epochs after which learning rate decays.\n",
    "LEARNING_RATE_DECAY_FACTOR = 0.1  # Learning rate decay factor.\n",
    "INITIAL_LEARNING_RATE = 0.1       # Initial learning rate.\n",
    "\n",
    "def _add_loss_summaries(total_loss):\n",
    "    \"\"\"Add summaries for losses in CIFAR-10 model.\n",
    "\n",
    "    Generates moving average for all losses and associated summaries for\n",
    "    visualizing the performance of the network.\n",
    "\n",
    "    Args:\n",
    "        total_loss: Total loss from loss().\n",
    "    Returns:\n",
    "        loss_averages_op: op for generating moving averages of losses.\n",
    "    \"\"\"\n",
    "    # Compute the moving average of all individual losses and the total loss.\n",
    "    loss_averages = tf.train.ExponentialMovingAverage(0.9, name='avg')\n",
    "    losses = tf.get_collection('losses')\n",
    "    loss_averages_op = loss_averages.apply(losses + [total_loss])\n",
    "\n",
    "    # Attach a scalar summary to all individual losses and the total loss; do the\n",
    "    # same for the averaged version of the losses.\n",
    "    for l in losses + [total_loss]:\n",
    "        # Name each loss as '(raw)' and name the moving average version of the loss\n",
    "        # as the original loss name.\n",
    "        tf.summary.scalar(l.op.name + ' (raw)', l)\n",
    "        tf.summary.scalar(l.op.name, loss_averages.average(l))\n",
    "\n",
    "    return loss_averages_op\n",
    "\n",
    "def _train(total_loss, global_step):\n",
    "    \"\"\"Train CIFAR-10 model.\n",
    "\n",
    "    Create an optimizer and apply to all trainable variables. Add moving\n",
    "    average for all trainable variables.\n",
    "\n",
    "    Args:\n",
    "    total_loss: Total loss from loss().\n",
    "    global_step: Integer Variable counting the number of training steps\n",
    "      processed.\n",
    "    Returns:\n",
    "    train_op: op for training.\n",
    "    \"\"\"\n",
    "    # Variables that affect learning rate.\n",
    "    num_batches_per_epoch = NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN / FLAGS.batch_size\n",
    "    decay_steps = int(num_batches_per_epoch * NUM_EPOCHS_PER_DECAY)\n",
    "\n",
    "    # Decay the learning rate exponentially based on the number of steps.\n",
    "    lr = tf.train.exponential_decay(INITIAL_LEARNING_RATE,\n",
    "                                  global_step,\n",
    "                                  decay_steps,\n",
    "                                  LEARNING_RATE_DECAY_FACTOR,\n",
    "                                  staircase=True)\n",
    "    tf.summary.scalar('learning_rate', lr)\n",
    "\n",
    "    # Generate moving averages of all losses and associated summaries.\n",
    "    loss_averages_op = _add_loss_summaries(total_loss)\n",
    "\n",
    "    # Compute gradients.\n",
    "    with tf.control_dependencies([loss_averages_op]):\n",
    "        opt = tf.train.GradientDescentOptimizer(lr)\n",
    "        grads = opt.compute_gradients(total_loss)\n",
    "\n",
    "    # Apply gradients.\n",
    "    apply_gradient_op = opt.apply_gradients(grads, global_step=global_step)\n",
    "\n",
    "    # Add histograms for trainable variables.\n",
    "    for var in tf.trainable_variables():\n",
    "        tf.summary.histogram(var.op.name, var)\n",
    "\n",
    "    # Add histograms for gradients.\n",
    "    for grad, var in grads:\n",
    "        if grad is not None:\n",
    "            tf.summary.histogram(var.op.name + '/gradients', grad)\n",
    "\n",
    "    # Track the moving averages of all trainable variables.\n",
    "    variable_averages = tf.train.ExponentialMovingAverage(\n",
    "      MOVING_AVERAGE_DECAY, global_step)\n",
    "    variables_averages_op = variable_averages.apply(tf.trainable_variables())\n",
    "\n",
    "    with tf.control_dependencies([apply_gradient_op, variables_averages_op]):\n",
    "        train_op = tf.no_op(name='train')\n",
    "\n",
    "    return train_op\n",
    "\n",
    "def inference(images):\n",
    "    \"\"\"Build the CIFAR-10 model.\n",
    "\n",
    "    Args:\n",
    "      images: Images returned from distorted_inputs() or inputs().\n",
    "\n",
    "    Returns:\n",
    "      Logits.\n",
    "    \"\"\"\n",
    "    # We instantiate all variables using tf.get_variable() instead of\n",
    "    # tf.Variable() in order to share variables across multiple GPU training runs.\n",
    "    # If we only ran this model on a single GPU, we could simplify this function\n",
    "    # by replacing all instances of tf.get_variable() with tf.Variable().\n",
    "    #\n",
    "    # conv1\n",
    "    with tf.variable_scope('conv1') as scope:\n",
    "        kernel = _variable_with_weight_decay('weights',\n",
    "                                             shape=[3, 3, 3, 64],\n",
    "                                             stddev=5e-2,\n",
    "                                             wd=0.0)\n",
    "        conv = tf.nn.conv2d(images, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "        biases = _variable_on_cpu('biases', [64], tf.constant_initializer(0.0))\n",
    "        pre_activation = tf.nn.bias_add(conv, biases)\n",
    "        conv1 = tf.nn.relu(pre_activation, name=scope.name)\n",
    "        _activation_summary(conv1)\n",
    "        \n",
    "    # conv1-1\n",
    "    with tf.variable_scope('conv1-1') as scope:\n",
    "        kernel = _variable_with_weight_decay('weights',\n",
    "                                             shape=[3, 3, 64, 64],\n",
    "                                             stddev=5e-2,\n",
    "                                             wd=0.0)\n",
    "        conv = tf.nn.conv2d(conv1, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "        biases = _variable_on_cpu('biases', [64], tf.constant_initializer(0.0))\n",
    "        pre_activation = tf.nn.bias_add(conv, biases)\n",
    "        conv1_1 = tf.nn.relu(pre_activation, name=scope.name)\n",
    "        _activation_summary(conv1_1)\n",
    "\n",
    "    # conv1-2\n",
    "    with tf.variable_scope('conv1-2') as scope:\n",
    "        kernel = _variable_with_weight_decay('weights',\n",
    "                                             shape=[3, 3, 64, 64],\n",
    "                                             stddev=5e-2,\n",
    "                                             wd=0.0)\n",
    "        conv = tf.nn.conv2d(conv1_1, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "        biases = _variable_on_cpu('biases', [64], tf.constant_initializer(0.0))\n",
    "        pre_activation = tf.nn.bias_add(conv, biases)\n",
    "        conv1_2 = tf.nn.relu(pre_activation, name=scope.name)\n",
    "        _activation_summary(conv1_2)\n",
    "    \n",
    "    \n",
    "    # pool1\n",
    "    pool1 = tf.nn.max_pool(conv1_2, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1],\n",
    "                           padding='SAME', name='pool1')\n",
    "    # norm1\n",
    "    norm1 = tf.nn.lrn(pool1, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75,\n",
    "                      name='norm1')\n",
    "\n",
    "    # conv2\n",
    "    with tf.variable_scope('conv2') as scope:\n",
    "        kernel = _variable_with_weight_decay('weights',\n",
    "                                             shape=[3, 3, 64, 64],\n",
    "                                             stddev=5e-2,\n",
    "                                             wd=0.0)\n",
    "        conv = tf.nn.conv2d(norm1, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "        biases = _variable_on_cpu('biases', [64], tf.constant_initializer(0.1))\n",
    "        pre_activation = tf.nn.bias_add(conv, biases)\n",
    "        conv2 = tf.nn.relu(pre_activation, name=scope.name)\n",
    "        _activation_summary(conv2)\n",
    "\n",
    "    # conv2-1\n",
    "    with tf.variable_scope('conv2-1') as scope:\n",
    "        kernel = _variable_with_weight_decay('weights',\n",
    "                                             shape=[3, 3, 64, 64],\n",
    "                                             stddev=5e-2,\n",
    "                                             wd=0.0)\n",
    "        conv = tf.nn.conv2d(conv2, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "        biases = _variable_on_cpu('biases', [64], tf.constant_initializer(0.1))\n",
    "        pre_activation = tf.nn.bias_add(conv, biases)\n",
    "        conv2_1 = tf.nn.relu(pre_activation, name=scope.name)\n",
    "        _activation_summary(conv2_1)\n",
    "\n",
    "    # conv2-2\n",
    "    with tf.variable_scope('conv2-2') as scope:\n",
    "        kernel = _variable_with_weight_decay('weights',\n",
    "                                             shape=[3, 3, 64, 64],\n",
    "                                             stddev=5e-2,\n",
    "                                             wd=0.0)\n",
    "        conv = tf.nn.conv2d(conv2_1, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "        biases = _variable_on_cpu('biases', [64], tf.constant_initializer(0.1))\n",
    "        pre_activation = tf.nn.bias_add(conv, biases)\n",
    "        conv2_2 = tf.nn.relu(pre_activation, name=scope.name)\n",
    "        _activation_summary(conv2_2)\n",
    "        \n",
    "    # norm2\n",
    "    norm2 = tf.nn.lrn(conv2_2, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75,\n",
    "                      name='norm2')\n",
    "    # pool2\n",
    "    pool2 = tf.nn.max_pool(norm2, ksize=[1, 3, 3, 1],\n",
    "                           strides=[1, 2, 2, 1], padding='SAME', name='pool2')\n",
    "\n",
    "    # local3\n",
    "    with tf.variable_scope('local3') as scope:\n",
    "        # Move everything into depth so we can perform a single matrix multiply.\n",
    "        reshape = tf.reshape(pool2, [FLAGS.batch_size, -1])\n",
    "        dim = reshape.get_shape()[1].value\n",
    "        weights = _variable_with_weight_decay('weights', shape=[dim, 384],\n",
    "                                              stddev=0.04, wd=0.004)\n",
    "        biases = _variable_on_cpu('biases', [384], tf.constant_initializer(0.1))\n",
    "        local3 = tf.nn.relu(tf.matmul(reshape, weights) + biases, name=scope.name)\n",
    "        _activation_summary(local3)\n",
    "\n",
    "    # local4\n",
    "    with tf.variable_scope('local4') as scope:\n",
    "        weights = _variable_with_weight_decay('weights', shape=[384, 192],\n",
    "                                              stddev=0.04, wd=0.004)\n",
    "        biases = _variable_on_cpu('biases', [192], tf.constant_initializer(0.1))\n",
    "        local4 = tf.nn.relu(tf.matmul(local3, weights) + biases, name=scope.name)\n",
    "        _activation_summary(local4)\n",
    "    print('local3', local3)\n",
    "    print('local4', local4)\n",
    "\n",
    "    # linear layer(WX + b),\n",
    "    # We don't apply softmax here because\n",
    "    # tf.nn.sparse_softmax_cross_entropy_with_logits accepts the unscaled logits\n",
    "    # and performs the softmax internally for efficiency.\n",
    "    with tf.variable_scope('softmax_linear') as scope:\n",
    "        weights = _variable_with_weight_decay('weights', [192, NUM_CLASSES],\n",
    "                                              stddev=1 / 192.0, wd=0.0)\n",
    "        biases = _variable_on_cpu('biases', [NUM_CLASSES],\n",
    "                                  tf.constant_initializer(0.0))\n",
    "        \n",
    "        print('weights', weights)\n",
    "        print('biases', biases)\n",
    "        softmax_linear = tf.add(tf.matmul(local4, weights), biases, name=scope.name)\n",
    "        \n",
    "        print('softmax_linear', softmax_linear)\n",
    "        _activation_summary(softmax_linear)\n",
    "\n",
    "    return softmax_linear\n",
    "\n",
    "def _loss(logits, labels):\n",
    "    \"\"\"Add L2Loss to all the trainable variables.\n",
    "\n",
    "    Add summary for \"Loss\" and \"Loss/avg\".\n",
    "    Args:\n",
    "      logits: Logits from inference().\n",
    "      labels: Labels from distorted_inputs or inputs(). 1-D tensor\n",
    "              of shape [batch_size]\n",
    "\n",
    "    Returns:\n",
    "      Loss tensor of type float.\n",
    "    \"\"\"\n",
    "    # Calculate the average cross entropy loss across the batch.\n",
    "    labels = tf.to_int64(labels)\n",
    "    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "        labels=labels, logits=logits, name='cross_entropy_per_example')\n",
    "    cross_entropy_mean = tf.reduce_mean(cross_entropy, name='cross_entropy')\n",
    "    tf.add_to_collection('losses', cross_entropy_mean)\n",
    "\n",
    "    # The total loss is defined as the cross entropy loss plus all of the weight\n",
    "    # decay terms (L2 loss).\n",
    "    return tf.add_n(tf.get_collection('losses'), name='total_loss')\n",
    "\n",
    "\n",
    "def train():\n",
    "    \"\"\"Train CIFAR-10 for a number of steps.\"\"\"\n",
    "    with tf.Graph().as_default():\n",
    "        images, labels = get_inputs()\n",
    "        \n",
    "        print('labels.get_shape()', labels.get_shape())\n",
    "        global_step = tf.contrib.framework.get_or_create_global_step()\n",
    "        \n",
    "        # Build a Graph that computes the logits predictions from the\n",
    "        # inference model.\n",
    "        logits = inference(images)\n",
    "        \n",
    "        print('images, logits, labels', images, logits, labels)\n",
    "\n",
    "        # Calculate loss.\n",
    "        loss = _loss(logits, labels)\n",
    "\n",
    "        # Build a Graph that trains the model with one batch of examples and\n",
    "        # updates the model parameters.\n",
    "        train_op = _train(loss, global_step)\n",
    "\n",
    "        class _LoggerHook(tf.train.SessionRunHook):\n",
    "            \"\"\"Logs loss and runtime.\"\"\"\n",
    "\n",
    "            def begin(self):\n",
    "                self._step = -1\n",
    "                self._start_time = time.time()\n",
    "\n",
    "            def before_run(self, run_context):\n",
    "                self._step += 1\n",
    "                return tf.train.SessionRunArgs(loss)  # Asks for loss value.\n",
    "\n",
    "            def after_run(self, run_context, run_values):\n",
    "                if self._step % FLAGS.log_frequency == 0:\n",
    "                    current_time = time.time()\n",
    "                    duration = current_time - self._start_time\n",
    "                    self._start_time = current_time\n",
    "\n",
    "                    loss_value = run_values.results\n",
    "                    examples_per_sec = FLAGS.log_frequency * FLAGS.batch_size / duration\n",
    "                    sec_per_batch = float(duration / FLAGS.log_frequency)\n",
    "\n",
    "                    format_str = ('%s: step %d, loss = %.2f (%.1f examples/sec; %.3f '\n",
    "                                  'sec/batch)')\n",
    "                    print(format_str % (datetime.now(), self._step, loss_value,\n",
    "                                        examples_per_sec, sec_per_batch))\n",
    "\n",
    "        with tf.train.MonitoredTrainingSession(\n",
    "                checkpoint_dir=FLAGS.train_dir,\n",
    "                hooks=[tf.train.StopAtStepHook(last_step=FLAGS.max_steps),\n",
    "                       tf.train.NanTensorHook(loss),\n",
    "                       _LoggerHook()],\n",
    "                config=tf.ConfigProto(\n",
    "                    log_device_placement=FLAGS.log_device_placement)) as mon_sess:\n",
    "            while not mon_sess.should_stop():\n",
    "                mon_sess.run(train_op)\n",
    "\n",
    "train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
